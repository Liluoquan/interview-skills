# 数据库

## 基本概念

三大数据模型：

- 关系模型：表的形式组织数据
- 层次模型：树的形式组织数据
- 网状模型：图的形式组织数据



![](https://s1.328888.xyz/2022/05/08/4YThR.png)



![4c1AQ.png](https://s1.328888.xyz/2022/05/08/4c1AQ.png)



![dx3xB.jpg](https://s1.328888.xyz/2022/05/23/dx3xB.jpg)

![lQlrM.jpg](https://s1.328888.xyz/2022/05/23/lQlrM.jpg)

--WHERE分组之前过滤数据，不能过滤聚合函数的结果

--having分组后再筛选满足条件的组，可过滤聚合函数的结果
--WHERE 用在group by前，having在group by之后



1. 事务（transaction）：一组 SQL 语句
2. 回退（rollback）：撤销指定 SQL 语句的过程
3. 提交（commit）：将未存储的 SQL 语句结果写入数据库表
4. 保留点（savepoint）：事务处理中设置的临时占位符（placeholder），你可以对它发布回退（与回退整个事务处理不同）



## MySQL 实战45讲

### 基础架构：一条 SQL 查询语句是如何执行的？

![MySQL逻辑架构图](./image/数据库/MySQL逻辑架构图.jpg)

MySQL 可以分为 Server 层和存储引擎层：

- **Server层**包括连接器、查询缓存、分析器、优化器、执行器等，涵盖MySQL的大多数核心服务 功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在 这一层实现，比如存储过程、触发器、视图等。
- **存储引擎层**负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、 Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5版本开始成为了 默认存储引擎。

#### 基本流程

##### 连接器

连接器负责跟客户端建立连 接、获取权限、维持和管理连接。连接命令一般是这么写的：

```shell
mysql -h$ip -P$port -u$user -p
```

连接命令中的mysql是客户端工具，用来跟服务端建立连接。在完成经典的TCP握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。

- 如果用户名或密码不对，你就会收到一个"Access denied for user"的错误，然后客户端程序结束执行。
- 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。

一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。

**客户端如果太长时间没动静，连接器就会自动将它断开。**这个时间是由参数 wait_timeout 控制的，默认值是8小时。



> MySQL 的长连接和短连接如何抉择？

数据库里面，长连接指连接成功后，如果客户端持续有请求，则一直使用同一个连接。

短连接指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。

但是全部使用长连接后，MySQL 占用内存涨得特别快，这是因为 MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是MySQL异常重启了。

两种解决方案：

1. **定期断开长连接**。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。
2. 如果用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证， 但是会将连接恢复到刚刚创建完时的状态。



##### 查询缓存

MySQL 拿到一个查询请求后，会先到查询缓存查找，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个 value 就会被直接返回给客 户端。

如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。如果查询命中缓存，MySQL不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。

**但是，查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。**

并且 MySQL 8.0 版本直接将查询缓存的整块功能删掉了。



##### 分析器

分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。

然后是做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则， 判断你输入的这个SQL语句是否满足MySQL语法。



##### 优化器

经过了分析器，MySQL就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。

优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join） 的时候，决定各个表的连接顺序。

优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。



##### 执行器

MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。

1. 开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误。
2. 如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。



### 日志系统：一条 SQL 更新语句是如何执行的？

MySQL 里经常说到的WAL技术，WAL 的全称是 WriteAhead Logging，它的关键点就是先写日志，再写磁盘。

当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。

InnoDB 的redo log 是固定大小的，比如可以配置为一组4个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录4GB的操作。

![](./image/数据库/redoLog.jpg)

write pos是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。 checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。 write pos和checkpoint之间的是“粉板”上还空着的部分，可以用来记录新的操作。

如果write pos 追上checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。

有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。



> redo log 和 bin log 的区别？

1.  redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。
2. redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。
3. redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件 写到一定大小后会切换到下一个，并不会覆盖以前的日志。



![](./image/数据库/执行指令的日志流程.jpg)

（图中浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的。）

1. 执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然 后再返回。
2. 执行器拿到引擎给的行数据，把这个值加上1，比如原来是N，现在就是N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的binlog，并把 binlog 写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。



> 说一下 prepare 和 commit 的两阶段提交

为了让两份日志之间的逻辑一致。

如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。



### 事务隔离：为什么你改了我还看不见？

事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在MySQL中，事务支持是在引擎层实现的。

MyISAM 引擎不支持事务，而 InnoDB 引擎支持事务。

SQL标准的事务隔离级别包括：读未提交（read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（serializable）。

1. **读未提交**：一个事务还没提交时，它做的变更就能被别的事务看到。
2. **读提交**：一个事务提交后，它做的更改才会被其他事务看到。
3. **可重复读**：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。
4. **串行化**：对于同一条记录，写操作会加写锁，读操作会加读锁。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成才能继续执行。

在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。在**“可重复读”**隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在**“读提交”**隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。这里需要注意的是，**“读未提交”**隔离级别下直接返回记录上的最新值，没有视图概念；而**“串行化”**隔离级别下直接用加锁的方式来避免并行访问。



### 索引

索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。索引的常见模型主要有三种：哈希表、有序数组和搜索树。

- **哈希表**

  ![](./image/数据库/哈希表示意图.jpg)

  哈希的思路很简单，把值放在数组里，用一个哈希函数把key换算成一个确定的位置，然后把value放在数组的这个位置。多个 key 值经过哈希函数换算有可能会出现同一个值的情况，这也叫做哈希冲突。此时可以使用一个链表来储存同一哈希值的 key。

  **哈希表这种结构适用于只有等值查询的场景**

- **有序数组**

  ![](./image/数据库/有序数组示意图.jpg)

  **而有序数组在等值查询和范围查询场景中的性能就都非常优秀。有序数组索引只适用于静态存储引擎**

  如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦 了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。

- **搜索树**

  ![](./image/数据库/BST示意图.jpg)

  为了维持O(log(N))的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更 新的时间复杂度也是O(log(N))。

  以InnoDB的一个整数字段索引为例，这个N差不多是1200。这棵树高是4的时候，就可以存 1200的3次方个值，这已经17亿了。考虑到树根的数据块总是在内存中的，一个10亿行的表上一 个整数字段的索引，查找一个值最多只需要访问3次磁盘。其实，树的第二层也有很大概率在内 存中，那么访问磁盘的平均次数就更少了。



#### InnoDB 的索引模型

在InnoDB中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。InnoDB使用 B+ 树索引模型，所以数据都是存储在 B+ 树中的。

每一个索引在InnoDB里面对应一棵 B+ 树。

根据叶子节点的内容，索引类型分为主键索引和非主键索引。

主键索引的叶子节点存的是**整行数据**。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。

非主键索引的叶子节点内容是**主键的值**。在InnoDB里，非主键索引也被称为二级索引（secondary index）。





### 全局锁和表锁

根据加锁的范围，MySQL里面的锁大致可以分成全局锁、表级锁和行锁三类。

#### 全局锁

全局锁就是对整个数据库实例加锁。MySQL提供了一个加全局读锁的方法，命令是 **Flush tables with read lock (FTWRL)** 。当你需要让整个库处于**只读状态**的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

**全局锁的典型使用场景是，做全库逻辑备份**。也就是把整库每个表都select出来存成文本。



#### 表级锁

MySQL里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。

**表锁的语法是 lock tables …read/write**。与 **FTWRL** 类似，可以用 **unlock tables** 主动释放锁， 也可以在客户端断开的时候自动释放。需要注意，**lock tables** 语法除了会限制别的线程的读写 外，也限定了本线程接下来的操作对象。

另一类表级的锁是 **MDL（metadata lock)**。MDL不需要显式使用，在访问一个表的时候会被自动加上。MDL的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。

当对一个表做增删改查操作的时候，加MDL读锁；当 要对表做结构变更操作的时候，加MDL写锁。

- 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
- 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。



### 如何减少行锁对性能的影响

MySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的， 这也是 MyISAM 被 InnoDB 替代的重要原因之一。

行锁就是针对数据表中行记录的锁。这很好理解，比如事务A更新了一行，而这时候 事务B也要更新同一行，则必须等事务A的操作完成后才能进行更新。

#### 行锁里面出现的死锁

<img src="./image/数据库/死锁模拟（行锁）.jpg" style="zoom:67%;" />

事务A在等待事务B释放id=2的行锁，而事务B在等待事务A释放id=1的行锁。 事务A和事务B在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：

- 直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。
- 发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数innodb_deadlock_detect设置为on，表示开启这个逻辑。

正常情况下采用主动死锁检测，但是死锁检测需要耗费时间去判断是否会因为自己加入而导致死锁。会消耗大量的 CPU 资源。解决这个资源花费问题有两个思路：

1. **临时关闭死锁**；
2. **控制并发度**：对于相同行的更新， 在进入引擎之前排队。这样在 InnoDB 内部就不会有大量的死锁检测工作了。
3. **将一行改成逻辑上的多行来减少锁冲突**：以影院账户为例，可以考虑放在多 条记录上，比如10个记录，影院的账户总额等于这10个记录的值的总和。这样每次要给影院账 户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的1/10，可以减少锁等 待个数，也就减少了死锁检测的CPU消耗。

