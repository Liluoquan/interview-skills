# 计算机网络

## 网络模型

**两种网络模型：OSI和TCP/IP**

<img src="https://s1.328888.xyz/2022/05/04/hIbCP.png" alt="网络模型" style="zoom: 50%;" />

- 应用层：负责向用户提供一组应用程序，比如HTTP、DNS、FTP、SMTP等：
- 传输层：负责端到端的通信，比如TCP、UDP等；
- 网络层：负责网络包的封装、分片、路由、转发，比如IP、ICMP等；
- 网络接口层：负责网络包在物理网络中的传输，比如网络包的封顿、 MAC寻址、差错检测，以及通过网卡传输网络帧等；

**每一层的封装格式：**

<img src="https://s1.328888.xyz/2022/05/04/hIZyA.webp" alt="封装" style="zoom: 50%;" />

- 网络接口层的传输单位是**帧（frame）**
- IP 层的传输单位是**包（packet）**
- TCP 层的传输单位是**段（segment**）
- HTTP 的传输单位则是**消息或报文（message）**。
- 但这些名词并没有什么本质的区分，可以统称为**数据包**。



## TCP



因为 `IP` 层是「不可靠」的，它不保证网络包的交付、不保证网络包的按序交付、也不保证网络包中的数据的完整性。

所以需要由上层（传输层）的 `TCP` 协议来负责数据的可靠传输。

### 基本概念

#### TCP头部格式

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzYuanBn?x-oss-process=image/format,png" alt="TCP 头格式" style="zoom: 40%;" />

**1、序列号**

在建立连接时由计算机生成的随机数作为其初始值，通过 SYN 包传给接收端主机，每发送一次数据，就「累加」一次该「数据字节数」的大小。**用来解决网络包乱序问题。**

**2、确认应答号**

指下一次「期望」收到的数据的序列号，发送端收到这个确认应答以后可以认为在这个序号以前的数据都已经被正常接收。**用来解决丢包的问题。**

**3、控制位**

- *ACK*：该位为 `1` 时，「确认应答」的字段变为有效，TCP 规定除了最初建立连接时的 `SYN` 包之外该位必须设置为 `1` 。
- *RST*：该位为 `1` 时，表示 TCP 连接中出现异常必须强制断开连接。
- *SYN*：该位为 `1` 时，表示希望建立连接，并在其「序列号」的字段进行序列号初始值的设定。
- *FIN*：该位为 `1` 时，表示今后不会再有数据发送，希望断开连接。当通信结束希望断开连接时，通信双方的主机之间就可以相互交换 `FIN` 位为 1 的 TCP 段。



### TCP抓包

常用工具：**tcpdump 和 Wireshark**，用 tcpdump 在 Linux 服务器上抓包，接着把抓包的文件拖出到 Windows 电脑后，用 Wireshark 可视化分析。



为了模拟客户端收不到服务端第二次握手 SYN、ACK 包，我的做法是在客户端**加上防火墙限制**，直接粗暴的把来自服务端的数据都丢弃，防火墙的配置如下：

添加 iptables 限制后， tcpdump 是否能抓到包 ，这要看添加的 iptables 限制条件：

- 如果添加的是 `INPUT` 规则，则可以抓得到包
- 如果添加的是 `OUTPUT` 规则，则抓不到包

网络包进入主机后的顺序如下：

- 进来的顺序 Wire -> NIC -> **tcpdump -> netfilter/iptables**
- 出去的顺序 **iptables -> tcpdump** -> NIC -> Wire









### TCP的半连接队列和全连接队列

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- 半连接队列，也称 SYN 队列；
- 全连接队列，也称 accept 队列；

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/3.jpg" alt="半连接队列与全连接队列" style="zoom: 50%;" />

服务端收到客户端发起的 SYN 请求后，**内核会把该连接存储到半连接队列**，并向客户端响应 SYN+ACK，接着客户端会返回 ACK，服务端收到第三次握手的 ACK 后，**内核会把连接从半连接队列移除，然后创建新的完全的连接，并将其添加到 accept 队列，等待进程调用 accept 函数时把连接取出来。**

不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃（默认行为），或返回 RST 包。

**默认行为的好处：如果服务器上的进程只是短暂的繁忙造成 accept 队列满，那么当 TCP 全连接队列有空位时，再次接收到的请求报文由于含有 ACK，仍然会触发服务器端成功建立连接。不需要重新浪费资源重新发起握手。**

tcp_abort_on_overflow 共有两个值分别是 0 和 1，其分别表示：

- 0 ：如果全连接队列满了，那么 server 扔掉 client 发过来的 ack ；
- 1 ：如果全连接队列满了，server 发送一个 `reset` 包给 client，表示废掉这个握手过程和这个连接；



##### 全连接队列的长度与什么有关？

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/11.jpg" alt="全连接队列溢出" style="zoom:50%;" />

- `somaxconn`，全局参数，表示系统中每一个端口的最大全连接队列长度，是 Linux 内核的参数，默认值是 128，可以通过 `/proc/sys/net/core/somaxconn` 来设置其值；
- `backlog` ，局部参数，表示该端口的最大全连接队列长度，是 `listen(int sockfd, int backlog)` 函数中的 backlog 大小，Nginx 默认值是 511，可以通过修改配置文件设置其长度；



#### 半连接队列的长度与什么有关？

**半连接队列最大值不是单单由 max_syn_backlog 决定，还跟全连接队列长度 （somaxconn 和 backlog ）有关系。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8D%8A%E8%BF%9E%E6%8E%A5%E5%92%8C%E5%85%A8%E8%BF%9E%E6%8E%A5/32.jpg" alt="img" style="zoom:50%;" />

- 当 max_syn_backlog > min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = min(somaxconn, backlog) * 2;
- 当 max_syn_backlog < min(somaxconn, backlog) 时， 半连接队列最大值 max_qlen_log = max_syn_backlog * 2;



### 如何理解 TCP 是面向字节流的协议

#### 字节流指的是什么

之所以会说 TCP 是面向字节流的协议，UDP 是面向报文的协议，是因为操作系统对 TCP 和 UDP 协议的**发送方的机制不同**，也就是问题原因在发送方。

**1、UDP是面向报文的协议**

当用户消息通过 UDP 协议传输时，**操作系统不会对消息进行拆分**，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是**每个 UDP 报文就是一个用户消息的边界**，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。

![图片](https://img-blog.csdnimg.cn/img_convert/a9116c5b375d356048df033dcb53582e.png)

操作系统在收到 UDP 报文后，会将其插入到队列里，**队列里的每一个元素就是一个 UDP 报文**，这样当用户调用 recvfrom() 系统调用读数据的时候，就会从队列里取出一个数据，然后从内核里拷贝给用户缓冲区。



**2、TCP是面向字节流的协议**

当用户消息通过 TCP 协议传输时，**消息可能会被操作系统分组成多个的 TCP 报文**，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。

这时，接收方的程序如果不知道发送方发送的消息的长度，也就是不知道消息的边界时，是无法读出一个有效的用户消息的，因为用户消息被拆分成多个 TCP 报文后，并不能像 UDP 那样，一个 UDP 报文就能代表一个完整的用户消息。

当两个消息的某个部分内容被分到同一个 TCP 报文时，就是我们常说的 **TCP 粘包问题**，这时接收方不知道消息的边界的话，是无法读出有效的消息。

要解决这个问题，要交给**应用程序**。



#### 如何解决粘包问题？

粘包的问题出现是因为不知道一个用户消息的边界在哪，如果知道了边界在哪，接收方就可以通过边界来划分出有效的用户消息。

一般有三种方式分包的方式：

- 固定长度的消息（灵活性不大）；

- 特殊字符作为边界（HTTP）；

- **自定义消息结构**

  我们可以自定义一个消息结构，由包头和数据组成，其中包头包是固定大小的，而且包头里有一个字段来说明紧随其后的数据有多大。

  ```c++
  struct { 
      u_int32_t message_length; 
      char message_data[]; 
  } message;
  ```

  比如这个消息结构体，首先 4 个字节大小的变量来表示数据长度，真正的数据则在后面。

  当接收方接收到包头的大小（比如 4 个字节）后，就解析包头的内容，于是就可以知道数据的长度，然后接下来就继续读取数据，直到读满数据的长度，就可以组装成一个完整到用户消息来处理了。





## IP

### 基本概念

IP 在 TCP/IP 参考模型中处于第三层，也就是**网络层**。

网络层的主要作用是：**实现主机与主机之间的通信，也叫点对点（end to end）通信。**



#### IP 地址的基础知识

##### IP 地址的位数

在 TCP/IP 网络通信时，为了保证能正常通信，每个设备都需要配置正确的 IP 地址，否则无法实现正常的通信。

IP 地址（IPv4 地址）由 `32` 位正整数来表示，IP 地址在计算机是以二进制的方式处理的。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/4.jpg" alt="点分十进制" style="zoom:50%;" />



##### IP 地址的分类

IP 地址分类成了 5 种类型，分别是 A 类、B 类、C 类、D 类、E 类。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/7.jpg" alt="IP 地址分类" style="zoom:50%;" />

> A、B、C 分类地址最大主机个数是如何计算的呢？

最大主机个数，就是要看主机号的位数，如 C 类地址的主机号占 8 位，那么 C 类地址的最大主机个数（需要减去子网广播地址和子网网络地址）：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/9.jpg)

> D、E 类地址是干嘛的？

而 D 类和 E 类地址是没有主机号的，所以不可用于主机 IP，D 类常被用于**多播**，E 类是预留的分类，暂时未使用。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/12.jpg" alt="img" style="zoom: 67%;" />





##### 广播地址

广播地址用于在**同一个链路中相互连接的主机之间发送数据包**。

广播地址可以分为本地广播和直接广播两种。

- **在本网络内广播的叫做本地广播**。例如网络地址为 192.168.0.0/24 的情况下，广播地址是 192.168.0.255 。因为这个**广播地址的 IP 包会被路由器屏蔽**，所以不会到达 192.168.0.0/24 以外的其他链路上。
- **在不同网络之间的广播叫做直接广播**。例如网络地址为 192.168.0.0/24 的主机向 192.168.1.255/24 的目标地址发送 IP 包。收到这个包的路由器，将数据转发给 192.168.1.0/24，从而使得所有 192.168.1.1~192.168.1.254 的主机都能收到这个包（由于直接广播有一定的安全问题，多数情况下会在路由器上设置为不转发） 。



##### 多播地址

多播用于**将包发送给特定组内的所有主机。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/13.jpg" alt="单播、广播、多播通信" style="zoom: 33%;" />

多播使用的 D 类地址，其前四位是 `1110` 就表示是多播地址，而剩下的 28 位是多播的组编号。

从 224.0.0.0 ~ 239.255.255.255 都是多播的可用范围，其划分为以下三类：

- 224.0.0.0 ~ 224.0.0.255 为预留的组播地址，只能在**局域网**中，路由器是不会进行转发的。
- 224.0.1.0 ~ 238.255.255.255 为用户可用的组播地址，可以**用于 Internet 上**。
- 239.0.0.0 ~ 239.255.255.255 为本地管理组播地址，可供**内部网在内部使用**，仅在特定的本地范围内有效。



##### 无分类地址 CIDR

这种方式不再有分类地址的概念，32 比特的 IP 地址被划分为两部分，前面是**网络号**，后面是**主机号**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/15.jpg" alt="img" style="zoom:50%;" />

还有另一种划分网络号与主机号形式，那就是**子网掩码**，掩码的意思就是掩盖掉主机号，剩余的就是网络号。

**将子网掩码和 IP 地址按位计算 AND，就可得到网络号。**

> 为什么要分离网络号和主机号？

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/17.jpg" alt="IP地址的网络号" style="zoom:50%;" />

因为两台计算机要通讯，首先要判断是否处于同一个广播域内，即网络地址是否相同。如果网络地址相同，表明接受方在本网络上，那么可以把数据包直接发送到目标主机。

路由器寻址工作中，也就是通过这样的方式来找到对应的网络号的，进而把数据包转发给对应的网络内。



> 怎么进行子网划分？

**子网划分实际上是将主机地址分为两个部分：子网网络地址和子网主机地址**。形式如下：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/19.jpg" alt="img" style="zoom:50%;" />

假设对 C 类地址进行子网划分，网络地址 192.168.1.0，使用子网掩码 255.255.255.192 对其进行子网划分。

C 类地址中前 24 位是网络号，最后 8 位是主机号，根据子网掩码可知**从 8 位主机号中借用 2 位作为子网号**。

划分后的 4 个子网如下表格：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/21.jpg" alt="img" style="zoom:50%;" />



##### 公有 IP 地址与私有 IP 地址

在 A、B、C 分类地址，实际上又分公有 IP 地址和私有 IP 地址。

公有 IP 地址是不可以重复的，而私有 IP 地址可以重复。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/23.jpg" alt="公有 IP 地址与私有 IP 地址" style="zoom:50%;" />

> 公有 IP 地址由谁管理呢？

私有 IP 地址通常是内部的 IT 人员管理，公有 IP 地址是由 `ICANN` 组织管理，中文叫「互联网名称与数字地址分配机构」。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/24.jpg" alt="img" style="zoom:50%;" />

IANA 是 ICANN 的其中一个机构，它负责分配互联网 IP 地址，是按州的方式层层分配。



##### IP 地址与路由控制

IP地址的**网络地址**这一部分是用于进行路由控制。

路由控制表中记录着网络地址与下一步应该发送至路由器的地址。在主机和路由器上都会有各自的路由器控制表。

在发送 IP 包时，首先要确定 IP 包首部中的目标地址，再从路由控制表中找到与该地址具有**相同网络地址**的记录，根据该记录将 IP 包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择相同位数最多的网络地址，也就是最长匹配。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/25.jpg" alt="IP 地址与路由控制" style="zoom: 50%;" />

例如：

1. 主机 A 要发送一个 IP 包，其源地址是 `10.1.1.30` 和目标地址是 `10.1.2.10`，由于没有在主机 A 的路由表找到与目标地址 `10.1.2.10` 相同的网络地址，于是包被转发到默认路由（路由器 `1` ）
2. 路由器 `1` 收到 IP 包后，也在路由器 `1` 的路由表匹配与目标地址相同的网络地址记录，发现匹配到了，于是就把 IP 数据包转发到了 `10.1.0.2` 这台路由器 `2`
3. 路由器 `2` 收到后，同样对比自身的路由表，发现匹配到了，于是把 IP 包从路由器 `2` 的 `10.1.2.1` 这个接口出去，最终经过交换机把 IP 数据包转发到了目标主机



##### 环路地址

环回地址是在同一台计算机上的程序之间进行网络通信时所使用的一个默认地址。

计算机使用一个特殊的 IP 地址 **127.0.0.1 作为环回地址**。与该地址具有相同意义的是一个叫做 `localhost` 的主机名。使用这个 IP 或主机名时，数据包不会流向网络。



##### IP 分片与重组

这里先思考一个问题：[既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？](#既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？)

每种数据链路的最大传输单元 `MTU` 都是不相同的，如 FDDI 数据链路 MTU 4352、以太网的 MTU 是 1500 字节等。

每种数据链路的 MTU 之所以不同，是因为每个不同类型的数据链路的使用目的不同。使用目的不同，可承载的 MTU 也就不同。

当 IP 数据包大小大于 MTU 时， IP 数据包就会被分片。

经过分片之后的 IP 数据报在被重组的时候，**只能由目标主机进行**，路由器是不会进行重组的。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/26.jpg" alt="分片与重组" style="zoom:50%;" />

在分片传输中，一旦某个分片丢失，则会造成整个 IP 数据报作废，所以 TCP 引入了 `MSS` 也就是在 TCP 层进行分片不由 IP 层分片，那么对于 UDP 我们尽量不要发送一个大于 `MTU` 的数据报文。



#### IPV6

IPv4 的地址是 32 位的，而 IPv6 的地址是 `128` 位的。

> IPv6 的优点

- IPv6 可自动配置，即使没有 DHCP 服务器也可以实现自动分配IP地址，真是**便捷到即插即用**啊。
- IPv6 包头包首部长度采用固定的值 `40` 字节，去掉了包头校验和，简化了首部结构，减轻了路由器负荷，大大**提高了传输的性能**。
- IPv6 有应对伪造 IP 地址的网络安全功能以及防止线路窃听的功能，大大**提升了安全性**。



> IPv6 地址的标识方法

IPv4 地址长度共 32 位，是以每 8 位作为一组，并用点分十进制的表示方式。

IPv6 地址长度是 128 位，是以每 16 位作为一组，每组用冒号 「:」 隔开。

如果出现连续的 0 时还可以将这些 0 省略，并用两个冒号 「::」隔开。但是，一个 IP 地址中只允许出现一次两个连续的冒号。



> IPv6 地址的结构

IPv6 的地址主要有以下类型地址：

- 单播地址，用于一对一的通信
- 组播地址，用于一对多的通信
- 任播地址，用于通信最近的节点，最近的节点是由路由协议决定
- 没有广播地址

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/29.jpg" alt="IPv6地址结构" style="zoom:50%;" />



> IPv6 单播地址类型

对于一对一通信的 IPv6 地址，主要划分了三类单播地址，每类地址的有效范围都不同。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/30.jpg" alt=" IPv6 中的单播通信" style="zoom:50%;" />

- 在同一链路单播通信，不经过路由器，可以使用**链路本地单播地址**，IPv4 没有此类型
- 在内网里单播通信，可以使用**唯一本地地址**，相当于 IPv4 的私有 IP
- 在互联网通信，可以使用**全局单播地址**，相当于 IPv4 的公有 IP



##### IPv4 首部和IPv6 首部

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/31.jpg" alt="IPv4 首部与 IPv6 首部的差异" style="zoom:50%;" />

IPv6 相比 IPv4 的首部改进：

- **取消了首部校验和字段。** 因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。
- **取消了分片/重新组装相关字段。** 分片与重组是耗时的过程，IPv6 不允许在中间路由器进行分片与重组，这种操作只能在源与目标主机，这将大大提高了路由器转发的速度。
- **取消选项字段。** 选项字段不再是标准 IP 首部的一部分了，但它并没有消失，而是可能出现在 IPv6 首部中的「下一个首部」指出的位置上。删除该选项字段使的 IPv6 的首部成为固定长度的 `40` 字节。



### IP 相关技术

#### DNS（域名解析系统）

我们在上网的时候，通常使用的方式是域名，而不是 IP 地址，因为域名方便人类记忆。

根域的 DNS 服务器信息保存在互联网中所有的 DNS 服务器中。这样一来，任何 DNS 服务器就都可以找到并访问根域 DNS 服务器了。

因此，客户端只要能够找到任意一台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然后再一路顺藤摸瓜找到位于下层的某台目标 DNS 服务器。

##### 域名解析的工作流程

浏览器首先看一下自己的缓存里有没有，如果没有就向操作系统的缓存要，还没有就检查本机域名解析文件 `hosts`，如果还是没有，就会 DNS 服务器进行查询，查询的过程如下：

1. 客户端首先会发出一个 DNS 请求，问 www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP/IP 设置中填写的 DNS 服务器地址）。
2. 本地域名服务器收到客户端的请求后，如果缓存里的表格能找到 www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我 www.server.com 的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。
3. 根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：“www.server.com 这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”
4. 本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com 的 IP 地址吗？”
5. 顶级域名服务器说：“我给你负责 www.server.com 区域的权威 DNS 服务器的地址，你去问它应该能问到”。
6. 本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。
7. 权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。
8. 本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。



#### ARP（地址解析协议）

由于主机的路由表中可以找到下一跳的 IP 地址，所以可以通过 **ARP 协议**，求得下一跳的 MAC 地址。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/34.jpg" alt="ARP 广播" style="zoom:50%;" />

ARP 是借助 **ARP 请求与 ARP 响应**两种类型的包确定 MAC 地址的。

- 主机会通过**广播发送 ARP 请求**，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。
- 当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包里的内容，如果 ARP 请求包中的目标 IP 地址与自己的 IP 地址一致，那么这个设备就将自己的 MAC 地址塞入 **ARP 响应包**返回给主机。

**操作系统**通常会把第一次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC 地址。

不过，MAC 地址的缓存是有一定期限的，超过这个期限，缓存的内容将被清除。



##### RARP（反向地址转换协议）

根据 MAC 地址来查询 IP 地址。例如将打印机服务器等小型嵌入式设备接入到网络时就经常会用得到。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/35.jpg" alt="RARP" style="zoom:50%;" />

通常这需要架设一台 `RARP` 服务器，在这个服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接入到网络，接着：

- 该设备会发送一条「我的 MAC 地址是XXXX，请告诉我，我的IP地址应该是什么」的请求信息。
- RARP 服务器接到这个消息后返回「MAC地址为 XXXX 的设备，IP地址为 XXXX」的信息给这个设备。

最后，设备就根据从 RARP 服务器所收到的应答信息设置自己的 IP 地址。



#### DHCP（动态主机配置协议）

电脑通过通过 DHCP 来动态获取 IP 地址，省去了配置 IP 信息的繁琐过程。

DHCP 客户端进程监听的是 68 端口号，DHCP 服务端进程监听的是 67 端口号。

DHCP 交互中，**全程都是使用 UDP 广播通信**。



##### IP 动态分配流程

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/36.jpg" alt="DHCP 工作流程" style="zoom:50%;" />

这 4 个步骤：

- 客户端首先发起 **DHCP 发现报文（DHCP DISCOVER）** 的 IP 数据报，由于客户端没有 IP 地址，也不知道 DHCP 服务器的地址，所以使用的是 **UDP 广播通信**，其使用的广播目的地址是 255.255.255.255（端口 67） 并且使用 0.0.0.0（端口 68） 作为源 IP 地址。DHCP 客户端将该 IP 数据报传递给链路层，链路层然后将帧广播到所有的网络中设备。
- DHCP 服务器收到 DHCP 发现报文时，用 **DHCP 提供报文（DHCP OFFER）** 向客户端做出响应。该报文仍然使用 IP 广播地址 255.255.255.255，该报文信息携带服务器提供可租约的 IP 地址、子网掩码、默认网关、DNS 服务器以及 **IP 地址租用期**。
- 客户端收到一个或多个服务器的 DHCP 提供报文后，从中选择一个服务器，并向选中的服务器发送 **DHCP 请求报文（DHCP REQUEST）**进行响应，回显配置的参数。
- 最后，服务端用 **DHCP ACK 报文**对 DHCP 请求报文进行响应，应答所要求的参数。

一旦客户端收到 DHCP ACK 后，交互便完成了，并且客户端能够在租用期内使用 DHCP 服务器分配的 IP 地址。

如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报文：

- 服务器如果同意继续租用，则用 DHCP ACK 报文进行应答，客户端就会延长租期。
- 服务器如果不同意继续租用，则用 DHCP NACK 报文，客户端就要停止使用租约的 IP 地址。



##### 如果 DHCP 服务器和客户端不在同一局域网怎么办？

因为路由器一般不会转发广播包，所以需要引入 DHCP 中继代理。由中继代理（路由器）对 DHCP 服务器进行单播。

有了 DHCP 中继代理以后，**对不同网段的 IP 地址分配也可以由一个 DHCP 服务器统一进行管理。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/37.jpg" alt=" DHCP 中继代理" style="zoom:50%;" />

- DHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包，而 DHCP 中继代理在收到这个广播包以后，再以**单播**的形式发给 DHCP 服务器。
- 服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包广播给 DHCP 客户端 。



#### NAT（网络地址转换）

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/39.jpg" alt="NAPT" style="zoom: 50%;" />

把 IP 地址 + 端口号一起进行转换。

**两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端口号作为区分。**

于是，生成一个 NAPT 路由器的转换表，就可以正确地转换地址跟端口的组合，令客户端 A、B 能同时与服务器之间进行通信。

这种转换表在 NAT 路由器上自动生成。例如，在 TCP 的情况下，建立 TCP 连接首次握手时的 SYN 包一经发出，就会生成这个表。而后又随着收到关闭连接时发出 FIN 包的确认应答从表中被删除。

##### 缺点及解决办法

> 缺点

由于 NAT/NAPT 都依赖于自己的转换表，因此会有以下的问题：

- 外部无法主动与 NAT 内部服务器建立连接，因为 NAPT 转换表没有转换记录。
- 转换表的生成与转换操作都会产生性能开销。
- 通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。

> 解决办法

解决的方法主要有两种方法。

***第一种就是改用 IPv6***

IPv6 可用范围非常大，以至于每台设备都可以配置一个公有 IP 地址，就不搞那么多花里胡哨的地址转换了，但是 IPv6 普及速度还需要一些时间。

***第二种 NAT 穿透技术***

NAT 穿越技术拥有这样的功能，它能够让网络应用程序主动发现自己位于 NAT 设备之后，并且会主动获得 NAT 设备的公有 IP，并为自己建立端口映射条目，注意这些都是 NAT设备后的应用程序自动完成的。

也就是说，在 NAT 穿透技术中，NAT设备后的应用程序处于主动地位，它已经明确地知道 NAT 设备要修改它外发的数据包，于是它主动配合 NAT 设备的操作，主动地建立好映射，这样就不像以前由 NAT 设备来建立映射了。

说人话，**就是客户端主动从 NAT 设备获取公有 IP 地址，然后自己建立端口映射条目，然后用这个条目对外通信，就不需要 NAT 设备来进行转换了。**



#### ICMP（互联网控制报文协议）

##### ICMP 的功能

`ICMP` 主要的功能包括：**确认 IP 包是否成功送达目标地址、报告发送过程中 IP 包被废弃的原因和改善网络设置等。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/40.jpg" alt="ICMP 目标不可达消息" style="zoom:67%;" />

在 `IP` 通信中如果某个 `IP` 包因为某种原因未能达到目标地址，那么这个具体的原因将**由 ICMP 负责通知**。

ICMP 的这种通知消息会使用 `IP` 进行发送 。

因此，从路由器 `2` 返回的 ICMP 包会按照往常的路由控制先经过路由器 `1` 再转发给主机 `A` 。收到该 ICMP 包的主机 `A` 则分解 ICMP 的首部和数据域以后得知具体发生问题的原因。

#####  ICMP 包头

ICMP 报文是封装在 IP 包里面，它工作在网络层，是 IP 协议的助手。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/5.jpg" alt="ICMP 报文" style="zoom:50%;" />

![ICMP 回送请求和回送应答报文](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/8.jpg)



##### ICMP 类型

**1、ICMP 类型**

ICMP 大致可以分为两大类：

- 一类是用于诊断的查询消息，也就是「**查询报文类型**」
- 另一类是通知出错原因的错误消息，也就是「**差错报文类型**」

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/41.jpg" alt="常见的 ICMP 类型" style="zoom:50%;" />

**2、目标不可达消息 3 的代码号**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/9.jpg" alt="目标不可达类型的常见代码号" style="zoom: 33%;" />

- **网络不可达代码为 `0`**

  IP 地址是分为网络号和主机号的，所以当路由器中的路由器表匹配不到接收方 IP 的网络号，就通过 ICMP 协议以**网络不可达**（`Network Unreachable`）的原因告知主机。

  自从不再有网络分类以后，网络不可达也渐渐不再使用了。

- **主机不可达代码为 `1`**

  当路由表中没有该主机的信息，或者该主机没有连接到网络，那么会通过 ICMP 协议以**主机不可达**（`Host Unreachable`）的原因告知主机。

- **协议不可达代码为 `2`**

  当主机使用 TCP 协议访问对端主机时，能找到对端的主机了，可是对端主机的防火墙已经禁止 TCP 协议访问，那么会通过 ICMP 协议以**协议不可达**的原因告知主机。

- **端口不可达代码为 `3`**

  当主机访问对端主机 8080 端口时，这次能找到对端主机了，防火墙也没有限制，可是发现对端主机没有进程监听 8080 端口，那么会通过 ICMP 协议以**端口不可达**的原因告知主机。

- **需要进行分片但设置了不分片位代码为 `4`**

  发送端主机发送 IP 数据报时，将 IP 首部的**分片禁止标志位**设置为`1`。根据这个标志位，途中的路由器遇到超过 MTU 大小的数据包时，不会进行分片，而是直接抛弃。

  随后，通过一个 ICMP 的不可达消息类型，**代码为 4** 的报文，告知发送端主机。



**3、原点抑制消息 4**

在使用低速广域线路的情况下，连接 WAN 的路由器可能会遇到网络拥堵的问题。

`ICMP` 原点抑制消息的目的就是**为了缓和这种拥堵情况**。

当路由器向低速线路发送数据时，其发送队列的缓存变为零而无法发送出去时，可以向 IP 包的源地址发送一个 ICMP **原点抑制消息**。

收到这个消息的主机借此了解在整个线路的某一处发生了拥堵的情况，从而增大 IP 包的传输间隔，减少网络拥堵的情况。

然而，由于这种 ICMP 可能会引起不公平的网络通信，一般不被使用。



**4、重定向消息 5**

如果路由器发现发送端主机使用了「不是最优」的路径发送数据，那么它会返回一个 ICMP **重定向消息**给这个主机。

在这个消息中包含了**最合适的路由信息和源数据**。这主要发生在路由器持有更好的路由信息的情况下。路由器会通过这样的 ICMP 消息告知发送端，让它下次发给另外一个路由器。



**5、超时消息 11**

IP 包中有一个字段叫做 `TTL` （`Time To Live`，生存周期），它的**值随着每经过一次路由器就会减 1，直到减到 0 时该 IP 包会被丢弃。**

此时，路由器将会发送一个 ICMP **超时消息**给发送端主机，并通知该包已被丢弃。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/11.jpg" alt="ICMP 时间超过消息" style="zoom:50%;" />

设置 IP 包生存周期的主要目的，是为了在路由控制遇到问题发生循环状况时，避免 IP 包无休止地在网络上被转发。

此外，有时可以用 TTL 控制包的到达范围，例如设置一个**较小的 TTL 值**。



#### IGMP（互联网组管理协议）

在前面我们知道了组播地址，也就是 D 类地址，既然是组播，那就说明是只有一组的主机能收到数据包，不在一组的主机不能收到数组包，怎么管理是否是在一组呢？那么，就需要 `IGMP` 协议了。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/42.jpg" alt="组播模型" style="zoom: 50%;" />

- IGMP 报文向路由器申请加入和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除非主机通过 IGMP 加入到组播组，主机申请加入到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转发组播包到对应的主机了。
- IGMP 报文采用 IP 封装，IP 头部的协议号为 2，而且 TTL 字段值通常为 1，因为 IGMP 是工作在主机与连接的路由器之间。

##### 工作机制

##### 常规查询与响应工作机制

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/43.jpg" alt=" IGMP 常规查询与响应工作机制" style="zoom:50%;" />

1. 路由器会周期性发送目的地址为 `224.0.0.1`（表示同一网段内所有主机和路由器） **IGMP 常规查询报文**。
2. 主机1 和 主机 3 收到这个查询，随后会启动「报告延迟计时器」，计时器的时间是随机的，通常是 0~10 秒，计时器超时后主机就会发送 **IGMP 成员关系报告报文**（源 IP 地址为自己主机的 IP 地址，目的 IP 地址为组播地址）。如果在定时器超时之前，收到同一个组内的其他主机发送的成员关系报告报文，则自己不再发送，这样可以减少网络中多余的 IGMP 报文数量。
3. 路由器收到主机的成员关系报文后，就会在 IGMP 路由表中加入该组播组，后续网络中一旦该组播地址的数据到达路由器，它会把数据包转发出去。



##### 离开组播组工作机制

离开组播组的情况一，网段中仍有该组播组：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/44.jpg" alt=" IGMPv2 离开组播组工作机制 情况1" style="zoom:50%;" />

1. 主机 1 要离开组 224.1.1.1，发送 IGMPv2 离组报文，报文的目的地址是 224.0.0.2（表示发向网段内的所有路由器）
2. 路由器 收到该报文后，以 1 秒为间隔连续发送 IGMP 特定组查询报文（共计发送 2 个），以便确认该网络是否还有 224.1.1.1 组的其他成员。
3. 主机 3 仍然是组 224.1.1.1 的成员，因此它立即响应这个特定组查询。路由器知道该网络中仍然存在该组播组的成员，于是继续向该网络转发 224.1.1.1 的组播数据包。

离开组播组的情况二，网段中没有该组播组：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/45.jpg" alt=" IGMPv2 离开组播组工作机制 情况2" style="zoom:50%;" />

1. 主机 1 要离开组播组 224.1.1.1，发送 IGMP 离组报文。
2. 路由器收到该报文后，以 1 秒为间隔连续发送 IGMP 特定组查询报文（共计发送 2 个）。此时在该网段内，组 224.1.1.1 已经没有其他成员了，因此没有主机响应这个查询。
3. 一定时间后，路由器认为该网段中已经没有 224.1.1.1 组播组成员了，将不会再向这个网段转发该组播地址的数据包。



### ping 的工作原理

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/5.jpg" alt="ICMP 报文" style="zoom:50%;" />

![ICMP 回送请求和回送应答报文](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/8.jpg)

![主机 A ping 主机 B 期间发送的事情](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/17.png)

- **发送 ICMP 回送请求消息数据包**

ping 命令执行的时候，源主机首先会构建一个 **ICMP 回送请求消息**数据包。

![主机 A 的 MAC 层数据包](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/15.jpg)

ICMP 数据包内包含多个字段，最重要的是两个：

- 第一个是**类型**，对于回送请求消息而言该字段为 `8`；
- 另外一个是**序号**，主要用于区分连续 ping 的时候发出的多个数据包。

每发出一个请求数据包，序号会自动加 `1`。为了能够计算往返时间 `RTT`，它会在报文的数据部分插入发送时间。

由 ICMP 协议将这个数据包连同地址 192.168.1.2 一起交给 IP 层。IP 层将以 192.168.1.2 作为**目的地址**，本机 IP 地址作为**源地址**，**协议**字段设置为 `1` 表示是 `ICMP` 协议，再加上一些其他控制信息，构建一个 `IP` 数据包。

接下来，需要加入 `MAC` 头。如果在本地 ARP 映射表中查找出 IP 地址 192.168.1.2 所对应的 MAC 地址，则可以直接使用；如果没有，则需要发送 `ARP` 协议查询 MAC 地址，获得 MAC 地址后，由数据链路层构建一个数据帧，目的地址是 IP 层传过来的 MAC 地址，源地址则是本机的 MAC 地址；还要附加上一些控制信息，依据以太网的介质访问规则，将它们传送出去。



- **发送 ICMP 回送响应信息包**

主机 `B` 收到这个数据帧后，先检查它的目的 MAC 地址，并和本机的 MAC 地址对比，如符合，则接收，否则就丢弃。

接收后检查该数据帧，将 IP 数据包从帧中提取出来，交给本机的 IP 层。同样，IP 层检查后，将有用的信息提取后交给 ICMP 协议。

主机 `B` 会构建一个 **ICMP 回送响应消息**数据包，回送响应数据包的**类型**字段为 `0`，**序号**为接收到的请求数据包中的序号，然后再发送出去给主机 A。

![主机 B 的 ICMP 回送响应报文](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/ping/16.jpg)

在规定的时候间内，源主机如果没有接到 ICMP 的应答包，则说明目标主机不可达；如果接收到了 ICMP 回送响应消息，则说明目标主机可达。

此时，源主机会检查，用当前时刻减去该数据包最初从源主机上发出的时刻，就是 ICMP 数据包的时间延迟。







# 常见面试题

## 整体流程常见面试题

### Web页面请求

**1、Web的页面请求流程及涉及到的技术**

【浏览器地址栏输入URL回车后涉及到的流程】

**1.1 查找DNS缓存**

​	**浏览器->OS->路由器->LSP（本地通信服务商）**

1. 先从浏览器查找DNS缓存，看浏览器中是否存在目标域名的IP地址；
2. 如果不在浏览器缓存，则浏览器将对OS发起系统调用，查询OS本地缓存：
3. 如果不在操作系统本地缓存，则浏览器会查询与之相连的路由器缓存：
4. 如果不在路由器缓存，则浏览器会检查LSP缓存：

如果上述四步都查询不到，则发起DNS查询

**1.2 发起DNS查询**

向本地 DNS 发起 DNS 查询：

- 本地 DNS 的缓存中找到，直接返回对应的IP地址
- 找不到，本地 DNS （客户端 TCP/IP 设置中填写的 DNS 服务器地址）从根 DNS 服务器开始递归查询，直到查询到IP地址，将结果加入缓存，然后返回IP地址

<img src="https://s1.328888.xyz/2022/05/04/hIEXF.webp" style="zoom: 33%;" />

【解释：DNS 是分布式域名服务器，每台服务器只维护一部分P地址到网络地址的映射，没有任何一台服务器能够维持全部的映射关系】

**1.3 封装数据包**

拿到IP地址后，根据URL中的端口可知端口号【HTTP：80；HTTPS：443】，一般先会先尝试建立HTTP连接；

1. **封装传输层数据包：**将应用层传递下来的实际数据，在传输层添加TCP首部：
2. **封装网络层数据包：**将传输层传下来的数据在网络层添加IP首部：
3. **封装网络接口层数据包：**将网络层传输下来的数据，在数据链路层添加以太网首部，并在传输介质中进行传输。

**1.4 浏览器与目标服务器建立连接**

经过上述DNS和ARP查询流程后，浏览器会收到目标服务器的IP和MAC地址，然后经过三次握手后建立TCP连接：

此时有两个结果：

1. **使用HTTP协议**

   浏览器发送请求到服务器，如果使用的是HTTP协议，则服务器直接返回结果：

2. **使用HTTPS协议**

​		如果不是HTTP协议，则服务器会返回一个以3开头的重定向消息，告诉浏览器使用的HTTPS,IP没变，只是端口号变成443；完成四次挥手；

​		然后重新建立TCP连接，将端口号修改为443，同时沟通好双方的使用的认证算法、加密和解密算法，在次过程中也会检查对方的CA安全证书，采用SSL加密技术进行传输数据。

**1.5 浏览器发送HTTP/HTTPS请求到web服务器**

主要使用两种请求方式：

1. 浏览器发送get请求，要求目标服务器提供输入的网页；
2. 浏览器发送post请求，表示填写的是表单。

**1.6 服务器处理请求并返回响应**

服务器会从浏览器接受请求并将其传递给请求处理程序并建立响应包；

一般响应包包含：请求的网页以及状态码，压缩类型，如何缓存的页面，设置的cookie：

**1.7 服务器将响应包发送给客户端**

应用层->传输层->网络层->链路层

**1.8  浏览器显示HTML页面**

1. 渲染HTML骨架
2. 检查HTML标记并发送GET请求以获取网页上的其他元素【图像、CSS样式、JS文件等】，该静态文件一般由浏览器缓存，再次访问，不用重新请求：
3. 显示HTML页面

### RPC远程过程调用

客户端可以像调用本地函数一样的调用服务端的函数；本质是提供了一种轻量无感知的跨进程通信的方式。

**RPC调用过程：**

1. 客户端调用函数（函数3个参数：待调用的接口名+函数名，待调用函数的形参和接收结果的指针）
2. 客户端存根收到调用之后将要待调用的接口名+函数名，待调用函数中需要传的参数和执行函数后接收执行结果的指针类型打包序列化成二进制数据
3. 将序列化后的数据通过网络传输到服务端
4. 服务端进行反序列化从客户端传来的数据
5. 根据反序列化后的数据去找到并执行客户端需要调用的函数
6. 将函数执行的结果序列化成二进制数据
7. 客户端反序列化从服务端传来的二进制数据
8. 客户端得到执行结果

**Protobuf的语法：**

message相当于结构体，service像一个接口，里面的数字是按顺序写的，并不是赋值，范围是1-15

```c++
message Test{
    string aaa = 1;
    int32 bbb = 2;
    repeated string ccc = 3;
}
```

RPC的架构：

1. 传输层（TCP传输插件，HTTP传输插件）
2. 协议层（协议插件，序列化插件，解压缩插件）
3. 集群层（服务发现插件，连接管理插件，负载均衡插件，路由插件，容错插件，配置管理插件）
4. 入口层（动态代理插件，链路追踪插件，过滤链插件）

把每个功能都抽象成一个接口，这样便于以后的扩展

### Linux 收发网络包的流程



**接收过程：**

<img src="https://s1.328888.xyz/2022/05/05/hkdqF.png" style="zoom: 80%;" />

1. 网卡收到一个网络包，以DMA的方式把网卡上收到的帧写到内存（Ring Buffer）里，硬中断通知CPU有数据到达。当CPU收到中断请求后，会去调用网络驱动注册的中断处理函数。网卡的中断处理函数并不做过多工作（发出软中断请求，修改CPU的poll_list）然后尽快释放CPU。

   ![](https://s1.328888.xyz/2022/05/05/hklwW.png)

2. ksoftirqd进程检测到有软中断请求到达，关闭硬中断后调用驱动的poll开始轮询收包，poll函数将收到的包送到协议栈注册的ip_rcv函数处理。

   ![](https://s1.328888.xyz/2022/05/05/hktBy.png)

3. 然后，ip_rcv函数再将包送到udp_rcv函数中（对于tcp包就送到tcp_rcv）处理，最后加入用户的接收队列，唤醒用户进程

   ![](https://s1.328888.xyz/2022/05/05/hksz4.png)

**注意：**

- ksoftirqd是专门处理软中断的线程，不只是处理网络软中断，还有定时器软中断等





**发送过程：**

我以为的发送过程：

<img src="https://s1.328888.xyz/2022/05/05/hkYD2.png" style="zoom:80%;" />

实际上的发送过程：

![](https://s1.328888.xyz/2022/05/05/hnhYX.png)

1. 调用`send(fd, buf, size, op)`以后，首先根据fd在内核中将对应socket中找出来，因为socket中记录这各种协议栈的函数地址与网络信息。然后构造一个`struct msghdr`对象，把用户传入的数据，比如 buffer地址、数据长度啥的，统统都装进去。

   ![](https://s1.328888.xyz/2022/05/05/hkKvC.png)

2. 在进入到协议栈 inet_sendmsg 以后，内核接着会找到 socket 上的具体协议发送函数。对于 TCP 协议来说，那就是 tcp_sendmsg（同样也是通过 socket 内核对象找到的）。然后内核申请一段内核态的skb（`struct sk_buff`）内存，将这段内存加入发送队列的尾部，最后将用户待发送的数据放进去。

   ![](https://s1.328888.xyz/2022/05/05/hkn1t.png)

   **注意：**

   - 此时需要判断是否可以发送（窗口大小等），可以才发送，否则就只是拷贝到内核
   - skb中实际上已经包含所有头部的内存，在加入新的头部时，只需要挪动头部指针即可，避免了内存的申请和拷贝，提高效率

   ![](https://s1.328888.xyz/2022/05/05/hk6RA.png)

3. `tcp_write_xmit()`处理了传输层的拥塞控制、滑动窗口相关的工作。满足窗口要求的时候，拷贝一份将要发送的skb，设置一下 TCP 头，然后将 skb 传到更低的网络层进行处理。

   **注意：在传输层又拷贝了一份即将发送的skb，why？**

   - 因为 skb 后续在调用网络层，最后到达网卡发送完成时，这个 skb 会被释放掉。而TCP是支持丢失重传的，因此在收到对方的ACK之前，这个skb不可删除，网络层发送成功时，删除的只是一个副本。

   ![](https://s1.328888.xyz/2022/05/05/hkFDO.png)

4. 网络层里主要处理路由项查找、IP 头设置、netfilter 过滤、skb 切分（大于 MTU 的话）等几项工作，处理完这些工作后会交给更下层的邻居子系统来处理。

   ![](https://s1.328888.xyz/2022/05/05/hkMvS.png)

5. 邻居子系统是位于网络层和数据链路层中间的一个系统，在邻居子系统里主要是查找或者创建邻居项，在创造邻居项的时候，有可能会发出实际的 arp 请求。然后封装一下 MAC 头，将发送过程再传递到更下层的网络设备子系统。

   **注意：邻居项实际上就是arp缓存**

   <img src="https://s1.328888.xyz/2022/05/05/hkSLR.png"  />

6. 进入网络设备子系统，由于现在网卡有多个发送队列（RingBuffer），因此需要先选择一个队列进行发送

   **注意：**这个过程消耗的是用户进程（内核态）的系统时间，当quota（配额）用完，或其他进程需要CPU，就触发软中断进程继续发送

   <img src="https://s1.328888.xyz/2022/05/05/hkB1v.png"  />

7. 如果系统态 CPU 发送网络包不够用的时候，会调用 ` __netif_schedule ` 触发一个软中断。该函数会进入到 `__netif_reschedule`，由它来实际发出 `NET_TX_SOFTIRQ` 类型软中断。在软中断中，获取发送队列，然后同样调用网卡驱动程序进行发送

   **注意：软中断开始的数据发送就不会消耗用户进程（内核态）的系统时间了**

   <img src="https://s1.328888.xyz/2022/05/05/hnidT.png"  />

8. 调用驱动里的发送函数 igb_xmit_frame。在驱动函数里，将 skb 会挂到 RingBuffer上，skb 的所有数据都映射到 DMA 地址后，数据包将真正从网卡发送出去。

   <img src="https://s1.328888.xyz/2022/05/05/hnrK2.png"  />

9. 发送完成后，网卡向CPU发送硬中断，通知CPU清理 RingBuffer 中刚刚发送出去的数据（对于TCP来说，删除的只是副本）

   注意：

   - 这里清理指的是清理 skb，解除 DMA 映射等

   - **从硬中断触发的软中断都是 NET_RX_SOFTIRQ**，与接收触发的软中断一致，在软中断中对发送和接收分别处理

   ![](https://s1.328888.xyz/2022/05/05/hnAA7.png)

**一些问题：**

**1、在监控内核发送数据消耗的 CPU 时，是应该看 sy 还是 si ？**

​	需要综合考虑，因为在网络包的发送过程中，用户进程（在内核态）完成了绝大部分的工作，甚至连调用驱动的事情都干了。只有当内核态进程被切走前才会发起软中断。发送过程中，绝大部分（90%）以上的开销都是在用户进程内核态消耗掉的。

**2、在服务器上查看 /proc/softirqs，为什么 NET_RX 要比 NET_TX 大的多的多？**

1. 当数据发送完成以后，通过硬中断的方式来通知驱动发送完毕。但是硬中断无论是有数据接收，还是对于发送完毕，触发的软中断都是 NET_RX_SOFTIRQ，而并不是 NET_TX_SOFTIRQ。
2. 对于读来说，都是要经过 NET_RX 软中断的，都走 ksoftirqd 内核进程。而对于发送来说，绝大部分工作都是在用户进程内核态处理了，只有系统态配额用尽才会发出 NET_TX，让软中断上。

**3、发送网络数据的时候都涉及到哪些内存拷贝操作？**

1. 第一次拷贝操作是内核申请完 skb 之后，这时候会**将用户传递进来的 buffer 里的数据内容都拷贝到 skb 中**。如果要发送的数据量比较大的话，这个拷贝操作开销还是不小的。
2. 第二次拷贝操作是从传输层进入网络层的时候，每一个 skb 都会被克隆一个新的副本出来。网络层以及下面的驱动、软中断等组件在发送完成的时候会将这个副本删除。传输层保存着原始的 skb，在当网络对方没有 ack 的时候，还可以重新发送，以**实现 TCP 中要求的可靠传输**。
3. 第三次拷贝不是必须的，只有当 **IP 层发现 skb 大于 MTU 时**才需要进行。会再申请额外的 skb，并将原来的 skb 拷贝为多个小的 skb。



### SCOKET编程的流程

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzM0LmpwZw?x-oss-process=image/format,png" alt="基于 TCP 协议的客户端和服务器工作" style="zoom:50%;" />

- 服务端和客户端初始化 `socket`，得到文件描述符；
- 服务端调用 `bind`，将绑定在 IP 地址和端口;
- 服务端调用 `listen`，进行监听；
- 服务端调用 `accept`，等待客户端连接；
- 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；
- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；
- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据的时候，就会读取到了 `EOF`，待处理完数据后，服务端调用 `close`，表示连接关闭。

监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作**监听 socket**，一个叫作**已完成连接 socket**。





## HTTP常见面试题

### HTTP基本概念

**1、HTTP是什么？能否详细解释HTTP？**

HTTP就是「超文本传输协议」，由协议、传输和超文本三部分组成，详细来说，HTTP 是一个在计算机世界里专门在**「两点」**之间**「传输」**文字、图片、音频、视频等**「超文本」**数据的**「约定和规范」**。属于应用层协议。



**2、HTTP常见的状态码有哪些？**

- [ ] 看着这个图把常见状态码含义讲清楚

<img src="https://s1.328888.xyz/2022/05/06/hSK60.webp" style="zoom: 50%;" />

按照状态码第一位来区分，可以分为五类：

1. `1xx`属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

2. `2xx`表示服务器**成功**处理了客户端的请求

   - 「**200 OK**」表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。
   - 「**204 No Content**」与 200 OK 基本相同，但响应头没有 body 数据。
   - 「**206 Partial Content**」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

3. `3xx`表示**重定向**，就是客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源

   - 「**301 Moved Permanently**」表示永久重定向，说明请求的资源已不存在，需改用新的 URL 访问。
   - 「**302 Found**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

   301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

   - 「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。

4. `4xx`表示**客户端错误**，就是客户端发送的**报文有误**，服务器无法处理

   - 「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。
   - 「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。
   - 「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

5. `5xx`表示**服务器错误**，客户端请求报文正确，但是**服务器处理时内部发生了错误**

   - 「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。
   - 「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。
   - 「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。
   - 「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。



**3、HTTP常见字段有哪些？**

1. ***Host字段***

   客户端发送请求时，用来指定服务器的域名。用于区分「同一台」服务器上的不同网站。

2. ***Content-Length 字段***

   告诉客户端，本次服务器回应的数据长度，后面的字节就属于下一个回应了。

3. ***Connection 字段***

   HTTP/1.1 版本的默认连接都是持久连接，但为了兼容老版本的 HTTP，需要指定 `Connection` 首部字段的值为 `Keep-Alive`。

4. ***Content-Type 字段***

   用于服务器回应时，告诉客户端，本次数据是什么格式。

   客户端请求的时候，可以使用 ***Accept 字段*** 声明自己可以接受哪些数据格式。

5. ***Content-Encoding 字段***

   说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式。

   客户端在请求时，用 ***Accept-Encoding 字段*** 说明自己可以接受哪些压缩方法。



#### Get和Post

**1、GET和POST有什么区别**

根据 RFC 规范，***GET*** 的语义是从服务器获取指定的资源，这个资源可以是静态的文本、页面、图片视频等，GET 请求的参数位置一般是写在 URL 中，并且URL 规定只能支持 ASCII，并且浏览器对URL的长度有限制，而HTTP本身对URL的长度没有限制；

***POST***  的语义是根据请求负荷（报文body）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中， body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。

1. ***GET*** 主要用于获取数据， ***POST*** 主要用于提交或修改数据
2. ***GET*** 有长度限制（2048字节），而 ***POST*** 没有
3. ***GET*** 的参数是显式的（在 URL 中，以 "?" 分割，"&" 连接），而 ***POST*** 是隐式的（在请求主体中）
4. ***GET*** 是明文传输，因为可以通过URL看到参数信息，而 ***POST*** 放在请求主体中，需要解包才能看见
5. ***GET*** 在浏览器中回退是无害的，而 ***POST*** 会再次提交请求
6. ***GET*** 会被浏览器主动缓存，而 ***POST*** 不会
7. ***GET*** 请求的参数数据类型只支持 ASCII 字符，而 ***POST*** 没有限制



**2、 GET 和 POST 方法都是安全和幂等的吗？**

**定义：**

- 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。
- 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。

**从RFC规范来看：**

- GET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。
- POST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。

但是具体还需要看开发者的实现，因为不是所有开发者都按照RFC规范来开发的。



#### ISO 七层模型中表示层和会话层的功能是什么？

1. 表示层：图像、视频的编码解码，以及数据的压缩和加密。
2. 会话层：建立会话，如 session 认证、断点续传。



#### Cookie 和 Session 的区别（And Token）

1. Cookie实际上是一**小段的文本信息**。客户端请求服务器，如果服务器需要记录该用户状态，就使用响应报文向客户端浏览器颁发一个Cookie。客户端会把Cookie保存起来。当浏览器再请求该网站时，浏览器把请求的网址连同该Cookie一同提交给服务器。服务器检查该Cookie，以此来辨认用户状态。服务器还可以根据需要修改Cookie的内容。信息保存的时间可以根据需要设置。
2. Session是另一种记录客户状态的机制，不同的是Cookie保存在客户端浏览器中，而Session保存在服务器上（形式是一个哈希表）。客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上。这就是Session。客户端浏览器再次访问时只需要从该Session中查找该客户的状态就可以了。
3. 区别：
   - **存放位置不同：** Cookie数据存放在客户端，Session数据放在服务器端
   - **安全性不同：** Cookie的安全性一般，他人可通过分析存放在本地的Cookie并进行Cookie欺骗。在安全性第一的前提下，选择Session更优。重要交互信息比如权限等就要放在Session中，一般的信息记录放Cookie中
   - **大小限制不同：** 单个Cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个Cookie，而Session原则上没有限制
   - Session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能考虑到减轻服务器性能方面，应当使用Cookie。
   - Session 的运行依赖Session ID，而 Session ID 是存在 Cookie 中的，也就是说，如果浏览器禁用了 Cookie，Session 也会失效（但是可以通过其它方式实现，比如在 url 中传递 Session ID，也就是地址重写）

> cookie 和 session 的局限

1. 服务端需要保存 session 信息，在高并发环境下会大量占用服务器空间
2. 对于集群环境，session 保存在服务器A上，但是下一次请求不一定发送到服务器A上，依然需要重新验证。
3. 对于非浏览器的客户端、手机移动端等不适用，因为 session 依赖于 cookie，而移动端没有 cookie。此外如果浏览器禁用了 cookie ，session 也会失效



> Token

当第一次收到客户端传过来的用户名和密码时，服务器认证通过后，通过加密算法生成一个字符串当做 token。当拿到后续请求中的 token，服务器再解析这个token，可以从中获取关键的信息，从而判断该token的有效性。

1. 客户端使用用户名和密码请求登录
2. 服务端收到请求，验证用户名和密码
3. 验证成功后，服务端会签发一个 token 令牌，再把这个token返回给客户端
4. 客户端收到 token 后可以把它存储起来，比如放到cookie中
5. 客户端每次向服务端请求资源时需要携带服务端签发的 token，可以在 cookie 或者 header 中携带
6. 服务端收到请求，然后去验证客户端请求里面带着的 token，如果验证成功，就向客户端返回请求数据



#### 如何解决分布式 session 的问题？

在互联网公司为了可以支撑更大的流量，后端往往需要**多台服务器**共同来支撑前端用户请求，那如果用户在 A 服务器登录了，第二次请求跑到服务 B 就会出现登录失效问题。

分布式 Session 一般会有以下几种解决方案：

1. 客户端存储：直接将信息存储在 cookie 中，cookie是存储在客户端上的一小段数据，客户端通过 http 协议和服务器进行 cookie 交互，通常用来存储一些不敏感信息
2. Nginx ip_hash 策略：服务端使用 Nginx 代理，每个请求按访问 IP 的 hash 分配，这样来自同一 IP 固定访问一个后台服务器，避免了在服务器 A 创建 Session，第二次分发到服务器 B 的现象。
3. Session 复制：任何一个服务器上的 Session 发生改变（增删改），该节点会把这个 Session 的所有内容序列化，然后广播给所有其它节点。
4. 共享 Session：服务端无状态话，将用户的 Session 等信息使用缓存中间件（如Redis）来统一管理，保障分发到每一个服务器的响应结果都一致。

**建议采用共享 Session 的方案。**



#### cookie 和 session 是如何配合的？

1. 用户第一次请求服务器的时候，服务器根据用户提交的相关信息，创建对应的 Session 
2. 请求返回时将此 Session 的唯一标识信息 SessionID 返回给浏览器
3. 浏览器接收到服务器返回的 SessionID 信息后，会将此信息存入到 Cookie 中，同时 Cookie 记录此 SessionID 属于哪个域名。
4. 当用户第二次访问服务器的时候，请求会自动判断此域名下是否存在 Cookie 信息，如果存在自动将 Cookie 信息也发送给服务端
5. 服务端会从 Cookie 中获取 SessionID，再根据 SessionID 查找对应的 Session 信息，如果没有找到说明用户没有登录或者登录失效，如果找到 Session 证明用户已经登录可执行后面操作。根据以上流程可知，SessionID 是连接 Cookie 和 Session 的一道桥梁，大部分系统也是根据此原理来验证用户登录状态。





#### 说一下 HTTP 常用头部字段

在HTTP/1.1中，请求头除了 ***Host*** 都是可选的。

- ***Host***：指定请求资源的主机和端口号。端口号默认80。

- ***Connection***：值为 keep-alive 和 close。keep-alive使客户端到服务器的连接持续有效，不需要每次重连，此功能为HTTP/1.1预设功能。

- ***Accept***：浏览器可接收的 MIME 类型。假设为 text/html 表示接收服务器回发的数据类型为 text/html，如果服务器无法返回这种类型，返回 406 错误。

- ***Cache-control***：缓存控制，Public内容可以被任何缓存所缓存，Private内容只能被缓存到私有缓存，non-cache指所有内容都不会被缓存。

- ***Cookie***：将存储在本地的Cookie值发送给服务器，实现无状态的HTTP协议的会话跟踪。

- ***Content-Length***：请求消息正文长度。



### HTTP特性

**1、HTTP1.1的优点和缺点？**

- **优点：**
  1. 形式简单：首先HTTP基本报文形式就是头部＋主体，然后头部也是键值对那种简单的形式
  2. 灵活且易于扩展：HTTP各类请求的方法、状态码、头部字段等都没有被固定死，允许开发人员自定义和扩充；同时HTTP工作在应用层，也就是OSI的第七层，它的下层可以随意变化，增加加扩展性。HTTPS就是在HTTP和TCP层之间加入了SSL/TLS安全传输层。
  3. 应用广泛和跨平台
- **缺点：**
  1. 无状态传输：当然这个也有好的部分，因为无状态传输，服务器不会记录HTTP的状态，从而不需要耗费资源去记录状态信息，减轻了服务器的负担。但是也会导致服务器不知道哪些请求是有关联的，每次都需要验证客户信息。现在主要用 ***Cookie*** 字段解决。
  2. 明文传输：导致所有信息都可以通过抓包获得。
  3. 不安全：通信使用明文（不加密），内容可能会被窃听；不验证通信方的身份，因此有可能遭遇伪装；无法证明报文的完整性，所以有可能已遭篡改；现在使用HTTPS的方式解决。



**2、HTTP/1.1的性能如何？**

- [ ] 与HTTP/1.0相比，加入了**长连接+管道网络**传输，性能提升。但是由于**队头阻塞**，还是存在性能问题

HTTP 协议是基于 **TCP/IP**，并且使用了「**请求 - 应答**」的通信模式，所以性能的关键就在这**两点**里。

- **长连接**

  通过长连接，减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。长连接指的是只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。当然，长时间没有数据交互，服务器还是会断开连接的。

- **管道网络传输**

  由于长连接的存在，使得在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以**减少整体的响应时间。**

- **队头阻塞**

  因为当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「**队头阻塞**」



### HTTPS和HTTP

**1、 HTTP 与 HTTPS 有哪些区别？**

- [ ] **回答流程：**协议本身->连接建立->端口号->数字证书

1. HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
2. HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
3. HTTP 的端口号是 80，HTTPS 的端口号是 443。
4. HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

由于HTTP简单快速的特性，当客户端向服务器端请求数据的时候，只需要传送请求方法和路径就可以取到结果，基于TCP，默认端口号为80，耗时可以简略计算为1RTT，传递的数据全部是明文传输，几乎没有安全性。 HTTPS是基于TLS的，而TLS又基于TCP，当客户端向服务器端请求数据的时候，服务器大概率会将客户端重定向到该服务器的443端口，进行新的TCP连接，此时服务器会返回一个证书文件，而不是响应报文体。此时客户端验证证书文件紧接创建对称密钥，之后重新和服务器建立TLS连接，当服务器返回ACK确认之后，连接正式建立，此时上方整个过程耗时为3RTT，并且之后和服务器的通信数据都是通过对称密钥加密过的，几乎无法破解。 
**HTTP和HTTPS的不同点总结如下：**

1. HTTP是基于TCP的，而HTTPS是基于TLS的
2. HTTP的往返时间为1RTT，而HTTPS的往返时间为3RTT
3. HTTP只需要创建一次TCP连接，而HTTPS需要创建两次TCP连接
4. HTTP的默认端口号为80，而HTTPS的默认端口号为443
5. HTTP的安全性很差，而HTTPS的安全性很强
6. HTTPS握手阶段耗费时间，几乎是HTTP的数倍，会延长页面的首次绘制时间和增加耗电
7. HTTPS的效率没有HTTP高，如果部分数据内容实际上并不需要加密，会平白浪费计算机资源
8. HTTPS的证书需要购买，功能越强大的证书价格更高
9. HTTPS的加密并不能阻止某些网络攻击，如黑客攻击、拒绝服务攻击等。



**2、HTTPS 解决了 HTTP 的哪些问题？**

- [ ] 回答流程：解决三大问题 -> 解释

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/19-HTTPS%E4%B8%8EHTTP.png" style="zoom:80%;" />

HTTPS通过：

- **混合加密**的方式保证了信息的机密性，解决了**窃听**的风险。
- **摘要算法**的方式来实现**完整性**，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。
- 将服务器公钥放入到**数字证书**中，解决了冒充的风险。

**混合加密：**

在通信建立前采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/20-%E6%B7%B7%E5%90%88%E5%8A%A0%E5%AF%86.png" style="zoom:80%;" />

- **非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，保证会话密钥的安全性。
- **对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。



**摘要算法：**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/21-%E6%A0%A1%E9%AA%8C%E5%AE%8C%E6%95%B4%E6%80%A7.png" style="zoom:80%;" />

用以保证数据没有被**篡改**，客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的「指纹」和当前算出的「指纹」做比较，若「指纹」相同，说明数据是完整的。



**数字证书：**

保证公钥不被篡改和信任度

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/22-%E6%95%B0%E5%AD%97%E8%AF%81%E4%B9%A6%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png" style="zoom:80%;" />

需要借助第三方权威机构 `CA` （数字证书认证机构），将**服务器公钥放在数字证书**（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。



**3、HTTPS 是如何建立连接的？其间交互了什么？**

SSL/TLS 协议基本流程：

1. 客户端向服务器索要并验证服务器的公钥。
2. 双方协商生产「会话秘钥」。
3. 双方采用「会话秘钥」进行加密通信。

前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/23-HTTPS%E5%B7%A5%E4%BD%9C%E6%B5%81%E7%A8%8B.png)

1. *ClientHello*

   首先，由客户端向服务器发起加密通信请求，也就是 `ClientHello` 请求。

   包括：

   - 客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本。
   - 客户端生产的随机数（`Client Random`），后面用于生成「会话秘钥」条件之一。
   - 客户端支持的密码套件列表，如 RSA 加密算法。

2. *SeverHello*

   服务器收到客户端请求后，向客户端发出响应，也就是 `SeverHello`。

   包括：

   - 确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。
   - 服务器生产的随机数（`Server Random`），也是后面用于生产「会话秘钥」条件之一。
   - 确认的密码套件列表，如 RSA 加密算法。
   - 服务器的数字证书。

3. *客户端回应*

   客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。

   如果证书没有问题，客户端会**从数字证书中取出服务器的公钥**，然后使用它加密报文，向服务器发送如下信息：

   - 一个随机数（`pre-master key`）。该随机数会被服务器公钥加密。
   - 加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
   - 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。

   **服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」**。

4. *服务器的最后回应*

   服务器收到客户端的第三个随机数（`pre-master key`）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。

   然后，向客户端发送最后的信息：

   - 加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。
   - 服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。

**接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。**



### HTTP/1.1、HTTP/2、HTTP/3 演变

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/27-HTTP3.png)

**1、HTTP/1.1 **

**改进（相比HTTP/1.0）：**

- 使用 **TCP 长连接**的方式改善了 HTTP/1.0 短连接造成的性能开销。
- 支持**管道（pipeline）网络传输**，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

**缺陷：**

- 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 `Body` 的部分；
- 发送冗长的首部。每次互相发送**相同的首部**造成的浪费较多；
- **队头阻塞**，服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据
- 没有请求优先级控制；
- 请求只能从客户端开始，服务器只能被动响应。



**2、HTTP/2**

**改进（相比HTTP/1.1）：**

- **头部压缩（HPack）**，在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。
- **二进制格式**，头信息和数据体都是二进制，并且统称为帧（frame）：**头信息帧（Headers Frame）和数据帧（Data Frame）**。比如HTTP/1.1中，状态码200用三个字符串表示，而在HTTP/2中用数字200表示。
- **数据流**，在 HTTP/2 中每个请求或相应的所有数据包，称为一个数据流（`Stream`）。每个数据流都标记着一个独一无二的编号（Stream ID），**不同 Stream 的帧是可以乱序发送的（因此可以并发不同的 Stream ）**，因为每个帧的头部会携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息。同时客户端可以指定数据流的**优先级**。
- **多路复用**，移除了 HTTP/1.1 中的串行请求，不需要排队等待，在**一个连接中并发多个请求或回应，而不用按照顺序一一对应**。
- **服务器推送**，服务不再是被动地响应，也可以**主动**向客户端发送消息。

**缺陷：**

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http3/tcp%E9%98%9F%E5%A4%B4%E9%98%BB%E5%A1%9E.gif)

- **TCP层的队头阻塞**

  HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的**所有的 HTTP 请求都必须等待这个丢了的包被重传回来**。



**3、HTTP/3**

**改进（相对于HTTP/2）：**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http3/quic%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png" style="zoom:80%;" />

- **无队头阻塞**

  基于 UDP 的 QUIC 协议，当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。

- **更快的连接建立**

  对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。而HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是**QUIC 内部包含了 TLS**，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS/1.3，因此仅需 **1 个 RTT** （QUIC三次握手）就可以「同时」完成建立连接与密钥协商。

- **连接迁移**

  基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接，那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接**。QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID**来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。



**SSL/TLS需要几次握手？**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/28-HTTP3%E4%BA%A4%E4%BA%92%E6%AC%A1%E6%95%B0.png" style="zoom:80%;" />

SSL/TLS 1.2需要四次握手，2个 RTT；SSL/TLS 1.3需要三次握手，1个 RTT

- **SSL/TLS 1.2**

  ![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/29-TLS1.2-%E5%9B%9B%E6%AC%A1%E6%8F%A1%E6%89%8B.png)

- **SSL/TLS 1.3**

  ![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/HTTP/30-TLS1.3.png)



### HTTP/1.1的优化



#### 如何避免发送HTTP请求（HTTP缓存技术）

**1、HTTP缓存有哪些实现方式？**

- [ ] 回答流程：HTTP缓存的定义->两种缓存方式的定义->反问是否需要阐述两种缓存方式之间的关系

**定义：**

HTTP缓存指的是对于一些具有重复性的 HTTP 请求，可以把这对「请求-响应」的数据都**缓存在本地**，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了。

<img src="https://img-blog.csdnimg.cn/d92026ce085b401c95cf02b7ce9b7fae.png" style="zoom:80%;" />

HTTP 缓存有两种实现方式，分别是**强制缓存和协商缓存**。

1. **强制缓存**

   强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。

   使用的字段为 ***Cache-Control字段*** 和 ***Expires 字段*** 

   - 浏览器第一次访问服务器资源时，服务器在返回资源的同时会在字段中设置过期时间
   - 浏览器在再次请求资源时，会先判断资源是否过期，没有的话就使用缓存，否则向服务器重新请求
   - 服务器再次收到请求后，会更新字段中的过期时间

2. **协商缓存**

   <img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/%E7%BC%93%E5%AD%98etag.png" style="zoom: 50%;" />

   协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存。

   协商缓存可以通过两种方式实现

   - 请求头部中的  ***If-Modified-Since 字段*** 与响应头部中的 ***Last-Modified字段***

     服务器收到请求后发现有 `If-Modified-Since` 则与被请求资源的最后修改时间进行对比（`Last-Modified`），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。

   - 请求头部中的 ***If-None-Match 字段***与响应头部中的 ***ETag 字段*** 

     当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头`If-None-Match `值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。

**注意：**协商缓存这两个字段都需要配合强制缓存中 Cache-control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。



#### 如何减少HTTP请求次数？

- [ ] 从三方面入手：减少重定向请求次数->合并请求->延迟发送请求

- ***减少重定向请求次数*；**

  ![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http1.1%E4%BC%98%E5%8C%96/%E4%BB%A3%E7%90%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%87%8D%E5%AE%9A%E5%90%91.png)

  一般源服务器的上一级还有代理服务器，因此客户端请求时，将**重定向的工作交由代理服务器完成，就能减少 HTTP 请求次数了**，并且当代理服务器知晓了重定向规则后，可以进一步减少消息传递次数

- ***合并请求*；**

  把多个访问小文件的请求合并成一个大的请求，虽然传输的总资源还是一样，但是减少请求，也就意味着**减少了重复发送的 HTTP 头部**。但是这样的合并请求会带来新的问题，**当大资源中的某一个小资源发生变化后，客户端必须重新下载整个完整的大资源文件**，这显然带来了额外的网络消耗。

- ***延迟发送请求*；**

  请求网页的时候，没必要把全部资源都获取到，而是只获取当前用户所看到的页面资源，当用户向下滑动页面的时候，再向服务器获取接下来的资源，这样就达到了延迟发送请求的效果。



#### 如何减少 HTTP 响应的数据大小？

- [ ] 压缩->两种压缩方式

对响应的资源进行**压缩**，这样就可以减少响应的数据大小，从而提高网络传输的效率。**压缩方式有无损压缩和有损压缩两种。**

- ***无损压缩***

  无损压缩是指资源经过压缩后，信息不被破坏，还能完全恢复到压缩前的原样，适合用在**文本文件、程序可执行文件、程序源代码**。这里指的是压缩算法，如`gzip`压缩算法。

  可以在请求头部中添加`Accept-Encoding: gzip, deflate, br`字段

  1. 去除多余的符号，如代码文件中的换行符/空格
  2. 利用统计模型，将常出现的数据用较短的二进制比特序列表示，将不常出现的数据用较长的二进制比特序列表示

- ***有损压缩***

  有损压缩主要将次要的数据舍弃，牺牲一些质量来减少数据量、提高压缩比，这种方法经常用于压缩多媒体数据，比如**音频、视频、图片**。这里主要指的是**编码格式**，图片的WebP/Png等

  可以通过 HTTP 请求头部中的 `Accept` 字段里的「 q 质量因子」，告诉服务器期望的资源质量。
  
  

### HTTP/2 相比 HTTP/1.1 提升在哪？

- [ ] 静动态表->Stream并发->主动推送

相比 HTTP/1 大大提高了传输效率、吞吐能力。

- 第一点，对于常见的 HTTP 头部通过**静态表和 Huffman 编码**的方式，将体积压缩了近一半，而且针对后续的请求头部，还可以建立**动态表**，将体积压缩近 90%，大大提高了编码效率，同时节约了带宽资源。

不过，动态表并非可以无限增大， 因为动态表是会占用内存的，动态表越大，内存也越大，容易影响服务器总体的并发能力，因此服务器需要限制 HTTP/2 连接时长或者请求次数。

- 第二点，**HTTP/2 实现了 Stream 并发**，多个 Stream 只需复用 1 个 TCP 连接，节约了 TCP 和 TLS 握手时间，以及减少了 TCP 慢启动阶段对流量的影响。不同的 Stream ID 才可以并发，即时乱序发送帧也没问题，但是同一个 Stream 里的帧必须严格有序。

另外，可以根据资源的渲染顺序来设置 Stream 的**优先级**，从而提高用户体验。

- 第三点，**服务器支持主动推送资源**，大大提升了消息的传输性能，服务器推送资源时，会先发送 PUSH_PROMISE 帧，告诉客户端接下来在哪个 Stream 发送资源，然后用偶数号 Stream 发送资源给客户端。

HTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在“队头阻塞”的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。

**HTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。**

详细过程见：[HTTP/2 牛逼在哪？](https://xiaolincoding.com/network/2_http/http2.html#_3-6-http-2-%E7%89%9B%E9%80%BC%E5%9C%A8%E5%93%AA)





### HTTP/3 相比 HTTP/2 提升在哪？



**HTTP/3 的提升基本在于基于UDP的QUIC协议：**

HTTP/2 虽然具有多个流并发传输的能力，但是传输层是 TCP 协议，于是存在以下缺陷：

- **队头阻塞**，HTTP/2 多个请求跑在一个 TCP 连接中，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据，从 HTTP 视角看，就是多个请求被阻塞了；
- **TCP 和 TLS 握手时延**，TCL 三次握手和 TLS 四次握手，共有 3-RTT 的时延；
- **连接迁移需要重新连接**，移动设备从 4G 网络环境切换到 WIFI 时，由于 TCP 是基于四元组来确认一条 TCP 连接的，那么网络环境变化后，就会导致 IP 地址或端口变化，于是 TCP 只能断开连接，然后再重新建立连接，切换网络环境的成本高；

HTTP/3 就将传输层从 TCP 替换成了 UDP，并在 UDP 协议上开发了 QUIC 协议，来保证数据的可靠传输。

**QUIC 协议的特点：**

- **无队头阻塞**，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，也不会有底层协议限制，某个流发生丢包了，只会影响该流，其他流不受影响；
- **建立连接速度快**，因为 QUIC 内部包含 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与 TLS 密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。
- **连接迁移**，QUIC 协议没有用四元组的方式来“绑定”连接，而是通过「连接 ID 」来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本；

另外 HTTP/3 的 QPACK 通过两个特殊的单向流来同步双方的动态表，解决了 HTTP/2 的 HPACK 队头阻塞问题。



**如何建立一个可靠的UDP连接？**

***QUIC 协议***

**1、在UDP中加入流序号和数据包序号**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http3/quic%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8.png" style="zoom: 67%;" />

每个数据包都有一个序号唯一标识。当某个流中的一个数据包丢失了，即使该流的其他数据包到达了，数据也无法被 HTTP/3 读取，直到 QUIC 重传丢失的报文，数据才会交给 HTTP/3。

而其他流的数据报文只要被完整接收，HTTP/3 就可以读取到数据。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。

**2、用QUIC 握手代替TCP三次握手**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/http3/0-rtt.gif" style="zoom:80%;" />

HTTP/3 在传输数据前虽然需要 QUIC 协议握手，这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。

QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。



**3、加入连接ID**

QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID**来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。

详细过程见：[HTTP/3 协议](https://xiaolincoding.com/network/2_http/http3.html#http-3-%E5%8D%8F%E8%AE%AE)



### QUIC 是如何实现可靠传输的？

#### 头部设计

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfegNsx0OLH9HjxgiaKardasZDR2CZttZ4jeU8LiaKmgTrJc5v9oVce8JXnHib8lpc8YiaJicicF9NA4E5A/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom:80%;" />

在 UDP 报文头部与 HTTP 消息之间，加入了 3 层头部：

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfegNsx0OLH9HjxgiaKardas8ByLO9u9cxkzn52bcZiaiazGCiaYMKsatD48yNMZWxXnOicwmdrY4RrRIw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 50%;" />

**1、Packet Header**

Packet Header 首次建立连接时和日常传输数据时使用的 Header 是不同的。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/J0g14CUwaZfegNsx0OLH9HjxgiaKardashwZGcmcC8aQCIK6rrgRjNBK4aZl7Y0ARdBGSW2R0jq1gJnWUPubupQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

- Long Packet Header 用于首次建立连接。
- Short Packet Header 用于日常传输数据。

QUIC 通过**三次握手**来建立连接的，主要目的是为了确定连接 ID。

**（1）连接 ID**

用于实现连接迁移，后续传输只需要通过连接ID就可以确认一条连接。

建立连接时，连接 ID 是由服务器根据客户端的 Source Connection ID 字段生成的，这样后续传输时，双方只需要固定住 Destination Connection ID（连接 ID ），从而实现**连接迁移**功能。所以，在日常传输数据的 Short Packet Header 不需要再传输 Source Connection ID 字段。



**（2）编号**

用以解决TCP重传的歧义问题和实现乱序确认，但是无法保证数据的有序性。

- **解决TCP中RTT计算不精确问题**

TCP 触发超时重传后，服务端返回相同的ACK，无法区分是对原始报文还是重传报文的应答，导致 RTT 计算不精确，也就导致 RTO（超时时间不精确），导致重传的概率事件增大

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/J0g14CUwaZfegNsx0OLH9HjxgiaKardasTFcRPezhEYfltiahy1p2bibInNhOm625fUeibAnmEsMtFQBjZpsge5IIQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

Short Packet Header 中的 Packet Number 是每个报文独一无二的编号，它是严格递增的，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/J0g14CUwaZfegNsx0OLH9HjxgiaKardas4Dvj7fttsvV51zKRIYkrSU2hrBwExiaMCC1299yDnPqpyaeIK1htzCg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

- **实现乱序确认**

防止因为丢包重传将当前窗口阻塞在原地，因为TCP 必须是顺序确认的，丢包时会导致窗口不滑动

QUIC 使用的 Packet Number 单调递增的设计，可以让数据包不再像TCP 那样必须有序确认，QUIC 支持乱序确认，当数据包Packet N 丢失后，只要有新的已接收数据包确认，当前窗口就会继续向右滑动。

待发送端超过一定时间没收到 Packet N 的确认报文后，会将需要重传的数据包放到待发送队列，重新编号比如数据包 Packet N+M 后重新发送给接收端，对重传数据包的处理跟发送新的数据包类似，这样就不会因为丢包重传将当前窗口阻塞在原地，从而解决了队头阻塞问题。



**2、QUIC Frame Header**

一个 Packet 报文中可以存放多个 QUIC Frame。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfegNsx0OLH9HjxgiaKardasFAPFV8LrrQENUKl2icqoyO5SLUglYn5YianQK48W38q2GoxzXh6zicAHA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 50%;" />

每一个 Frame 都有明确的类型，针对类型的不同，功能也不同，自然格式也不同。每个 Stream 可以认为就是一条 HTTP 请求，Stream 类型的 Frame 格式，如下：

<img src="https://mmbiz.qpic.cn/mmbiz_jpg/J0g14CUwaZfegNsx0OLH9HjxgiaKardasV1oeTvUNVNhoK1RQTO7LpGQQTb4vdvHLP7tUU8ib4I9CC539j2HMnew/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 50%;" />

- ***Stream ID*** 作用：多个并发传输的 HTTP 消息，通过不同的 Stream ID 加以区别；
- ***Offset*** 作用：类似于 TCP 协议中的 Seq 序号，**保证数据的顺序性和可靠性**；
- ***Length*** 作用：指明了 Frame 数据的长度。

由于Packet Header中的编号无法保证数据的有序性，在此处**通过 Stream ID + Offset 字段信息实现数据的有序性**，通过比较两个数据包的 Stream ID 与 Stream Offset ，如果都是一致，就说明这两个数据包的内容一致。

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/J0g14CUwaZfegNsx0OLH9HjxgiaKardaswQ4ib91zSCQ5FWQE5ia0Cm38Za8CeZW19d0Teib8X9iaMgbkucoXITzDYA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

总的来说，**QUIC 通过单向递增的 Packet Number，配合 Stream ID 与 Offset 字段信息，可以支持乱序确认而不影响数据包的正确组装**，摆脱了TCP 必须按顺序确认应答 ACK 的限制，解决了 TCP 因某个数据包重传而阻塞后续所有待发送数据包的问题。



#### 如何解决TCP的队头阻塞问题？

TCP 队头阻塞的问题要从两个角度看，一个是**发送窗口的队头阻塞**，另外一个是**接收窗口的队头阻塞**。

**1、发送窗口的队头阻塞**

TCP 发送出去的数据，都是需要按序确认的，只有在数据都被按顺序确认完后，发送窗口才会往前滑动。

- 发送方把发送窗口内的数据全部都发出去了，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据了。

![图片](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcHKlpxE3Eyibf87WLibypvRE7yp9no9Xib9EVicibMvicX0pVMetbd7DFrjVcN1I2FvT8VciaNXkKbOdIvA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- 当发送方收到对第 `32~36` 字节的 ACK 确认应答后，则**滑动窗口往右边移动 5 个字节，因为有 5 个字节的数据被应答确认**，接下来第 `52~56` 字节又变成了可用窗口，那么后续也就可以发送 `52~56` 这 5 个字节的数据了。

![图片](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcHKlpxE3Eyibf87WLibypvREoU3LwTicLLnCrH7MKdezgwcZ5JKknztGVKp5ZcOiaL23tQYmKuCUeqjA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- 在这个过程中，如果第 `32` 字节的ACK丢失，那么整个发送窗口还是不会前移



**2、接收窗口的队头阻塞**

接收方收到的数据范围必须在接收窗口范围内，如果收到超过接收窗口范围的数据，就会丢弃该数据，比如下图接收窗口的范围是 32 ～ 51 字节，如果收到第 52 字节以上数据都会被丢弃。

![图片](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZcHKlpxE3Eyibf87WLibypvREu2CFdn3mltnicJqTkcQMCiakNV28uwc9E2T3IKnI7HFwXoibqQTxBPZQw/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

当接收窗口收到的数据不是有序的，比如收到第 33～40 字节的数据，由于第 32 字节数据没有收到， 接收窗口无法向前滑动，那么即使先收到第 33～40 字节的数据，这些数据也无法被应用层读取的。只有当发送方重传了第 32 字节数据并且被接收方收到后，接收窗口才会往前滑动，然后应用层才能从内核读取第 32～40 字节的数据。



QUIC 借鉴了 HTTP/2 里的 Stream 的概念，在一条 QUIC 连接上并发发送多个 HTTP 请求 (Stream)，**每个 Stream 有一个独立的滑动窗口(Offset)**，一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口。

- 当一个Stream上的QUIC packet丢失，只会导致该stream阻塞等待重传，而不会影响其他的Stream

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/J0g14CUwaZfegNsx0OLH9HjxgiaKardasKlxgMBbtvCkwYLXZJ2rEnpLmibMTAY2e2yGCjAr83a1k446JRJprNIA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)



#### QUIC如何实现流量控制？

TCP 流量控制是通过让「接收方」告诉「发送方」，它（接收方）的接收窗口有多大，从而让「发送方」根据「接收方」的实际接收能力控制发送的数据量。

QUIC 实现了两种级别的流量控制，分别为 Stream 和 Connection 两种级别：

- **Stream 级别的流量控制**：每个 Stream 都有独立的滑动窗口，所以每个 Stream 都可以做流量控制，防止单个 Stream 消耗连接（Connection）的全部接收缓冲。
- **Connection 流量控制**：限制连接中所有 Stream 相加起来的总字节数，防止发送方超过连接的缓冲容量。

**1、Stream 级别的流量控制**

通过限制 stream 可以发送的数据量，防止单个 stream 消耗连接（connection）的全部缓冲区。与 TCP 不同，就算此前有 packet 没有接收到，它的滑动只取决于接收到的最大偏移字节数（highest received byte offset）。只要还有可用窗口，发送方可以继续发送数据。

**注意：若此时接收窗口已经满了，但是由于仍未收到队头丢失的数据，最大接收窗口并不会移动，导致该Stream阻塞。**当然该Stream的阻塞，不会影响其他Stream的接收

![图片](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfegNsx0OLH9HjxgiaKardasMO9r2VbRjHb9m3UF274dgsnPvOdxq0cjuh4gdbzXK6esLnpHInPSiaA/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1)

- 在握手时，接收方通过传输参数（transport parameters）设置 stream 的初始限制。
- 发送方根据这个值进行流量控制，大致过程跟 TCP 相似。
- 如果发送方达到限制，（可选）则可以发送 `STREAM_DATA_BLOCKED` 帧给接收方，以告示它有数据要发送，但被流量控制限制阻止。
- 接收方如果有更大的窗口值，可以发送 `MAX_STREAM_DATA` 帧通知发送方增加。
- 如果发送方违反流量控制的限制，接收方可以关闭连接并返回 `FLOW_CONTROL_ERROR` 错误。

**QUIC 协议中同一个 Stream 内，滑动窗口的移动仅取决于接收到的最大字节偏移（尽管期间可能有部分数据未被接收）**，而对于 TCP 而言，窗口滑动必须保证此前的 packet 都有序的接收到了，其中一个 packet 丢失就会导致窗口等待。



**2、Connection 流量控制**

限制 connection 中所有 streams 相加起来的总字节数，防止发送方超过 connection 的缓冲（buffer）容量。

- 在握手时，接收方通过传输参数（transport parameters）设置 connection 的初始限制。
- 发送方根据计算 connection 中所有 streams 的可用窗口，与这个连接窗口值对比进行流量控制。
- 如果发送方达到限制，（可选）则可以发送`STREAM_BLOCKED`帧给接收方，以告示它有数据要发送，但被流量控制限制阻止。
- 接收方如果有更大的窗口值，可以发送`MAX_DATA`帧通知发送方增加。
- 如果发送方违反流量控制的限制，接收方可以关闭连接并返回`FLOW_CONTROL_ERROR`错误。

![](https://pic2.zhimg.com/80/v2-40d554b9fe8205e8167961d8531a26b9_720w.jpg)

![](https://pic4.zhimg.com/80/v2-0d56fa6960f1646a066ca1e5218938ab_720w.jpg)



#### QUIC的拥堵控制

QUIC 协议当前默认使用了 TCP 的 Cubic 拥塞控制算法（慢开始、拥塞避免、快重传、快恢复策略等），同时也支持 CubicBytes、Reno、RenoBytes、BBR、PCC 等拥塞控制算法。

但是，QUIC属于应用层的协议，**可以针对不同的应用设置不同的拥塞控制算法**，灵活性更高。



#### 针对HTTP的优化

**1、携带TLS记录**

对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手（1RTT），再 TLS 握手（2RTT），所以需要 3RTT 的延迟才能传输数据，就算 Session 会话复用，也需要至少 2 个 RTT。

HTTP/3 在传输数据前虽然需要 QUIC 协议握手（1RTT），这个握手过程只需要 1RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。

<img src="https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZfegNsx0OLH9HjxgiaKardas9Y5MYCu2JNcO4A0zS9a9vq4XLLia393DBmOa1k9TuIrJIjqlD29zalg/640?wx_fmt=png&wxfrom=5&wx_lazy=1&wx_co=1" alt="图片" style="zoom: 33%;" />

**QUIC 内部包含了 TLS**，它在自己的帧会携带 TLS 里的“记录”，再加上 QUIC 使用的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，甚至在第二次连接的时候，应用数据包可以和 QUIC 握手信息（**连接信息 + TLS 信息【客户端支持的椭圆曲线，以及这些椭圆曲线对应的公钥】**）一起发送，达到 0-RTT 的效果。



- **TLS 1.3的握手流程**

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/tls1.2and1.3.png)

**TLS 1.3 把 Hello 和公钥交换这两个消息合并成了一个消息，于是这样就减少到只需 1 RTT 就能完成 TLS 握手**。（客户端在 Client Hello 消息里带上了支持的椭圆曲线，以及这些椭圆曲线对应的公钥，然后服务器再告诉客户端最终选择的公钥即可）







**2、迁移连接**

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。

那么**当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接**。

而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。

QUIC 协议没有用四元组的方式来“绑定”连接，而是通过**连接 ID**来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了**连接迁移**的功能。



### HTTPS的优化

#### 回答思路

- [ ] 硬件优化->软件优化->协议优化->证书优化->会话复用

1. 对于**硬件优化**的方向，因为 HTTPS 是属于计算密集型，应该选择计算力更强的 CPU，而且最好选择**支持 AES-NI 特性的 CPU**，这个特性可以在硬件级别优化 AES 对称加密算法，加快应用数据的加解密。

2. 对于**软件优化**的方向，如果可以，把软件升级成较新的版本，比如将 Linux 内核 2.X 升级成 4.X，将 openssl 1.0.1 升级到 1.1.1，因为新版本的软件不仅会提供新的特性，而且还会修复老版本的问题。

3. 对于**协议优化**的方向：

   - 密钥交换算法应该选择 **ECDHE 算法**，而不用 RSA 算法，因为 ECDHE 算法具备前向安全性，而且客户端可以在第三次握手之后，就发送加密应用数据，节省了 1 RTT。
   - 将 TSL1.2 升级 **TSL1.3**，因为 TSL1.3 的握手过程只需要 1 RTT，而且安全性更强。

4. 对于**证书优化**的方向：

   - 服务器应该选用 **ECDSA 证书**，而非 RSA 证书，因为在相同安全级别下，ECC 的密钥长度比 RSA 短很多，这样可以提高证书传输的效率；

   - 服务器应该开启 **OCSP Stapling** 功能，由服务器预先获得 OCSP 的响应，并把响应结果缓存起来，这样 TLS 握手的时候就不用再访问 CA 服务器，减少了网络通信的开销，提高了证书验证的效率；

5. 对于重连 HTTPS 时，我们可以使用一些技术让客户端和服务端使用上一次 HTTPS 连接使用的会话密钥，直接恢复会话，而不用再重新走完整的 TLS 握手过程。

6. 常见的**会话重用**技术有 Session ID 和 Session Ticket，用了会话重用技术，当再次重连 HTTPS 时，只需要 1 RTT 就可以恢复会话。对于 TLS1.3 使用 Pre-shared Key 会话重用技术，只需要 0 RTT 就可以恢复会话。

7. 这些会话重用技术虽然好用，但是存在一定的安全风险，它们不仅不具备前向安全，而且有重放攻击的风险，所以应当对会话密钥设定一个合理的过期时间。



HTTPS 相比 HTTP 协议多一个 TLS 协议握手过程，**目的是为了通过非对称加密握手协商或者交换出对称加密密钥**，这个过程最长可以花费掉 2 RTT，接着后续传输的应用数据都得使用对称加密密钥来加密/解密。

#### 分析性能损耗

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/tls%E6%80%A7%E8%83%BD%E6%8D%9F%E8%80%97.png" style="zoom: 80%;" />

产生性能消耗的两个环节：

- 第一个环节， TLS 协议握手过程；
- 第二个环节，握手后的对称加密报文传输。

对于第二环节，现在主流的对称加密算法 AES、ChaCha20 性能都是不错的，而且一些 CPU 厂商还针对它们做了硬件级别的优化，因此这个环节的性能消耗可以说非常地小。

而第一个环节，TLS 协议握手过程不仅增加了网络延时（最长可以花费掉 2 RTT），而且握手过程中的一些步骤也会产生性能损耗，比如：

- 对于 ECDHE 密钥协商算法，握手过程中会客户端和服务端都需要临时生成椭圆曲线公私钥；
- 客户端验证证书时，会访问 CA 获取 CRL 或者 OCSP，目的是验证服务器的证书是否有被吊销；
- 双方计算 Pre-Master，也就是对称加密密钥；



#### 硬件优化

**HTTPS 协议是计算密集型，而不是 I/O 密集型**

所以可以选择**支持 AES-NI 特性的 CPU**，因为这种款式的 CPU 能在指令级别优化了 AES 算法，这样便加速了数据的加解密传输过程。



#### 软件优化

软件的优化方向可以分层两种，一个是**软件升级**，一个是**协议优化**。

**1、软件升级**

将正在使用的软件升级到最新版本，因为最新版本不仅提供了最新的特性，也优化了以前软件的问题或性能。比如：

- 将 Linux 内核从 2.x 升级到 4.x；
- 将 OpenSSL 从 1.0.1 升级到 1.1.1；
- ...



**2、协议优化**

协议的优化就是对「密钥交换过程」进行优化。

**（1）密钥交换算法优化**

TLS 1.2 版本如果使用的是 RSA 密钥交换算法，那么需要 4 次握手，也就是要花费 **2 RTT**，才可以进行应用数据的传输，而且 RSA 密钥交换算法不具备前向安全性。**RSA 密钥交换算法的 TLS 握手过程，不仅慢，而且安全性也不高**。

- **选用 ECDHE 密钥交换**算法替换 RSA 算法，因为该算法由于支持「False Start」，它是“抢跑”的意思，客户端可以在 TLS 协议的第 3 次握手后，第 4 次握手前，发送加密的应用数据，以此将 **TLS 握手的消息往返由 2 RTT 减少到 1 RTT，而且安全性也高，具备前向安全性**。
- **选择 x25519 曲线**，该曲线是目前最快的椭圆曲线。
- **选用 AES_128_GCM**，它比 AES_256_GCM 快一些，因为密钥的长度短一些。

**（2） TLS 升级**

- 把 TLS 1.2 升级成 TLS 1.3，TLS 1.3 大幅度简化了握手的步骤，**完成 TLS 握手只要 1 RTT**，而且安全性更高。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/tls1.2and1.3.png)

在 TLS 1.2 的握手中，一般是需要 4 次握手，先要通过 Client Hello （第 1 次握手）和 Server Hello（第 2 次握手） 消息协商出后续使用的加密算法，再互相交换公钥（第 3 和 第 4 次握手），然后计算出最终的会话密钥。

**TLS 1.3 把 Hello 和公钥交换这两个消息合并成了一个消息，于是这样就减少到只需 1 RTT 就能完成 TLS 握手**。（客户端在 Client Hello 消息里带上了支持的椭圆曲线，以及这些椭圆曲线对应的公钥，然后服务器再告诉客户端最终选择的公钥即可）



#### 证书优化

为了验证的服务器的身份，服务器会在 TSL 握手过程中，把自己的证书发给客户端，以此证明自己身份是可信的。

对于证书的优化，可以有两个方向：

- 一个是**证书传输**，
- 一个是**证书验证**



**1、证书传输优化**

要让证书更便于传输，那必然是减少证书的大小，这样可以节约带宽，也能减少客户端的运算量。所以，**对于服务器的证书应该选择椭圆曲线（ECDSA）证书，而不是 RSA 证书，因为在相同安全强度下， ECC 密钥长度比 RSA 短的多**。



**2、证书验证优化**

客户端在验证证书时，是个复杂的过程，会走**证书链逐级验证**，验证的过程不仅需要**「用 CA 公钥解密证书」**以及**「用签名算法验证证书的完整性」**，而且为了知道证书是否被 CA 吊销，客户端有时还会再去访问 CA， 下载 CRL 或者 OCSP 数据，以此确认证书的有效性。

这个**访问过程是 HTTP 访问**，因此又会产生一系列网络通信的开销，如 DNS 查询、建立连接、收发数据等。

**使用CRL的缺点：**

需要先向CA或者CRL部门下载CRL，然后自己查询

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/crl.png)

- 第一个问题，由于 CRL 列表是由 CA 维护的，定期更新，如果一个证书刚被吊销后，客户端在更新 CRL 之前还是会信任这个证书，**实时性较差**；
- 第二个问题，**随着吊销证书的增多，列表会越来越大，下载的速度就会越慢**，下载完客户端还得遍历这么大的列表，那么就会导致客户端在校验证书这一环节的延时很大，进而拖慢了 HTTPS 连接。



**OCSP的缺点**

基本都是使用 OCSP ，名为在线证书状态协议（*Online Certificate Status Protocol*）来查询证书的有效性，它的工作方式是**向 CA 发送查询请求，让 CA 返回证书的有效状态**。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/ocsp.png)

OCSP 需要向 CA 查询，因此也是要发生网络请求，而且还得看 CA 服务器的“脸色”，如果网络状态不好，或者 CA 服务器繁忙，也会导致客户端在校验证书这一环节的延时变大。



**OCSP Stapling**

服务器向 CA 周期性地查询证书状态，获得一个带有时间戳和签名的响应结果并缓存它。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/opscp-stapling.png)

当有客户端发起连接请求时，服务器会把这个「响应结果」在 TLS 握手过程中发给客户端。由于有签名的存在，服务器无法篡改，因此客户端就能得知证书是否已被吊销了，这样客户端就不需要再去查询。



#### 会话复用

TLS 握手的目的就是为了协商出会话密钥，也就是对称加密密钥，**把首次 TLS 握手协商的对称加密密钥缓存起来**，待下次需要建立 HTTPS 连接时，直接「复用」这个密钥，可以减少 TLS 握手的性能损耗。

这种方式就是**会话复用**（*TLS session resumption*），会话复用分两种：

- 第一种叫 Session ID；
- 第二种叫 Session Ticket；



**1、Session ID**

Session ID 的工作原理是，**客户端和服务器首次 TLS 握手连接后，双方会在内存缓存会话密钥，并用唯一的 Session ID 来标识**，Session ID 和会话密钥相当于 key-value 的关系。

当客户端再次连接时，hello 消息里会带上 Session ID，服务器收到后就会从内存找，如果找到就直接用该会话密钥恢复会话状态，跳过其余的过程，只用一个消息往返就可以建立安全通信。当然为了安全性，内存中的会话密钥会**定期失效**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/sessionid.png"  />

但是它有两个缺点：

- 服务器必须保持每一个客户端的会话密钥，随着客户端的增多，**服务器的内存压力也会越大**。
- 现在网站服务一般是由多台服务器通过负载均衡提供服务的，**客户端再次连接不一定会命中上次访问过的服务器**，于是还要走完整的 TLS 握手过程；



**2、Session Ticket**

为了解决 Session ID 的问题，就出现了 Session Ticket，**服务器不再缓存每个客户端的会话密钥，而是把缓存的工作交给了客户端**，类似于 HTTP 的 Cookie。

客户端与服务器首次建立连接时，服务器会加密「会话密钥」作为 Ticket 发给客户端，交给客户端缓存该 Ticket。

客户端再次连接服务器时，客户端会发送 Ticket，服务器解密后就可以获取上一次的会话密钥，然后验证有效期，如果没问题，就可以恢复会话了，开始加密通信。

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/ticket.png)

对于集群服务器的话，**要确保每台服务器加密 「会话密钥」的密钥是一致的**，这样客户端携带 Ticket 访问任意一台服务器时，都能恢复会话。

Session ID 和 Session Ticket **都不具备前向安全性**，因为一旦加密「会话密钥」的密钥被破解或者服务器泄漏「会话密钥」，前面劫持的通信密文都会被破解。



**3、Pre-shared Key**

Session ID 和 Session Ticket 方式都需要在 1 RTT 才能恢复会话。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https%E4%BC%98%E5%8C%96/0-RTT.png" style="zoom: 50%;" />

而 TLS1.3 更为牛逼，对于重连 TLS1.3 只需要 **0 RTT**，原理和 Ticket 类似，只不过在重连时，客户端会把 Ticket 和 HTTP 请求一同发送给服务端，这种方式叫 **Pre-shared Key**。





### HTTPS握手过程解析

#### HTTPS RSA 握手解析

`RSA` 是最简单的密钥交换算法

##### TLS握手过程

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/tls%E6%8F%A1%E6%89%8B.png)

每一个「框」都是一个记录（*record*），记录是 TLS 收发数据的基本单位，类似于 TCP 里的 segment。多个记录可以组合成一个 TCP 包发送，所以**通常经过「四个消息」就可以完成 TLS 握手，也就是需要 2个 RTT 的时延**，然后就可以在安全的通信环境里发送 HTTP 报文，实现 HTTPS 协议。



##### RSA握手过程

![](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/https_rsa.png)

**1、第一次握手**

**共包含一条信息：「Client Hello」**

- 客户端首先会发一个「**Client Hello**」消息，字面意思我们也能理解到，这是跟服务器「打招呼」。
- 消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的**随机数（*Client Random*）**，这个随机数会被服务端保留，它是生成对称加密密钥的材料之一。

**2、第二次握手**

**共包含三条信息：「Server Hello」、「Server Certificate」、「Server Hello Done」**

- 当服务端收到客户端的「Client Hello」消息后，会确认 TLS 版本号是否支持，和从密码套件列表中选择一个密码套件，以及生成**随机数（*Server Random*）**。
- 接着，返回「**Server Hello**」消息，消息里面有服务器确认的 TLS 版本号，也给出了随机数（Server Random），然后从客户端的密码套件列表选择了一个合适的密码套件。
- 然后，服务端为了证明自己的身份，会发送「**Server Certificate**」给客户端，这个消息里含有数字证书。
- 随后，服务端发了「**Server Hello Done**」消息，目的是告诉客户端，我已经把该给你的东西都给你了，本次打招呼完毕。

**3、客户端验证证书**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E8%AF%81%E4%B9%A6%E7%9A%84%E6%A0%A1%E9%AA%8C.png" style="zoom: 50%;" />

**CA 签发证书**的过程，如上图左边部分：

- 首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值；
- 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名；
- 最后将 Certificate Signature 添加在文件证书上，形成数字证书；

**客户端校验服务端的数字证书**的过程，如上图右边部分：

- 首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1；
- 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2 ；
- 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。

**这里还涉及到证书链，需要从根证书开始逐级验证。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/https/%E7%94%A8%E6%88%B7%E4%BF%A1%E4%BB%BB.png" style="zoom: 50%;" />



**3、第三次握手**

**共包含三条信息：「Change Cipher Key Exchange」、「Change Cipher Spec」、「Encrypted Handshake Message（Finishd）」**

- 客户端验证完证书后，认为可信则继续往下走。接着，客户端就会生成一个新的**随机数 (*pre-master*)**，用服务器的 RSA 公钥加密该随机数，通过「**Change Cipher Key Exchange**」消息传给服务端。
- 服务端收到后，用 RSA 私钥解密，得到客户端发来的随机数 (pre-master)。
- 双方根据已经得到的三个随机数（***Client Random***、***Server Random***、***pre-master***），生成**会话密钥（Master Secret）**，它是对称密钥，用于对后续的 HTTP 请求/响应的数据加解密。
- 生成完会话密钥后，然后客户端发一个「**Change Cipher Spec**」，告诉服务端开始使用加密方式发送消息。
- 然后，客户端再发一个「**Encrypted Handshake Message（Finishd）**」消息，把之前所有发送的数据做个摘要，再用会话密钥（master secret）加密一下，让服务器做个验证，验证加密通信是否可用和之前握手信息是否有被中途篡改过。

**4、第四次握手**

服务器也是同样的操作，发「**Change Cipher Spec**」和「**Encrypted Handshake Message**」消息，如果双方都验证加密和解密没问题，那么握手正式完成。

最后，就用「会话密钥」加解密 HTTP 请求和响应了。



##### RSA 算法的缺陷

**使用 RSA 密钥协商算法的最大问题是不支持前向保密**。

因为客户端传递随机数（用于生成对称加密密钥的条件之一）给服务端时使用的是公钥加密的，服务端收到到后，会用私钥解密得到随机数。所以一旦服务端的私钥泄漏了，过去被第三方截获的所有 TLS 通讯密文都会被破解。

#### HTTPS ECDHE 握手解析

**不论RSA还是ECDHE，最终计算主密钥的公式都是相同的：**

$client\_random + server\_random + pre\_master = master\_secret$

前两个随机数完全明文，保密的关键在于 `pre-master`。

> RSA 与 ECDHE 加密算法的区别？

在RSA中，pre-master 是单纯的由客户端生成，通过服务器的公钥加密后发给服务器，服务器使用私钥解密拿到 pre-master。一旦服务器的私钥被破解，主密钥就会被攻击者算出，并且会导致过往的主密钥泄漏（RSA不具备“向前安全性”）。

在 ECDHE 中，服务器生成一个 “椭圆曲线的公钥” Server Params，对应公式中的A，使用私钥加密后将其发送给客户端；客户端也生成一个“椭圆曲线的公钥” Client Params，对应公式中的B，使用服务器的公钥加密后发给服务器；而私钥 a 和 b 由服务器和客户端分别保管。

> ECDHE 如何保证 pre-master 不泄漏

```mathematica
A = G ^ a % P
B = G ^ b % P
```

A 为公钥，a 为私钥

在客户端上： $$A ^ b \% P = {Server\_Params} ^ b \% P = pre\_master$$ 

在服务器上： $B ^ a \% P = {Client\_Params} ^ a \% P = pre\_master$



RSA 是比较传统的密钥交换算法，它不具备前向安全的性质，因此现在很少服务器使用的。而 ECDHE 算法具有前向安全，所以被广泛使用。

**ECDHE 相比 RSA 握手过程省去了一个消息往返的时间**，这个有点「抢跑」的意思，它被称为是「*TLS False Start*」，跟「*TCP Fast Open*」有点像，都是在还没连接完全建立前，就发送了应用数据，这样便提高了传输的效率。



##### 握手过程分析

**1、第一次握手**（Client）

**与RSA相同**

客户端首先会发一个「**Client Hello**」消息，消息里面有客户端使用的 TLS 版本号、支持的密码套件列表，以及生成的**随机数（*Client Random*）**。

**2、第二次握手**（Server）

**选择不同的密钥协商算法**

**共包含四条信息：「Server Hello」、「Server Certificate」、「Server Key Exchange」、「Server Hello Done」**

- 服务端收到客户端的「打招呼」，同样也要回礼，会返回「**Server Hello**」消息，消息面有服务器确认的 TLS 版本号，也给出了一个**随机数（*Server Random*）**，然后从客户端的密码套件列表选择了一个合适的密码套件。

- 接着，服务端为了证明自己的身份，发送「**Certificate**」消息，会把证书也发给客户端。

- 这一步就和 RSA 握手过程有很大到区别了，因为服务端选择了 ECDHE 密钥协商算法，所以会在发送完证书后，发送「**Server Key Exchange**」消息。

  主要就是选择椭圆曲线，然后计算公钥

- 随后，就是「**Server Hello Done**」消息，服务端跟客户端表明：“这些就是我提供的信息，打招呼完毕”。

**3、第三次握手（Client）**

客户端收到了服务端的证书后，自然要校验证书是否合法，如果证书合法，那么服务端到身份就是没问题的。校验证书的过程会走证书链逐级验证，确认证书的真实性，再用证书的公钥验证签名，这样就能确认服务端的身份了，确认无误后，就可以继续往下走。

- 客户端会生成一个随机数作为客户端椭圆曲线的私钥，然后再根据服务端前面给的信息，生成**客户端的椭圆曲线公钥**，然后用「**Client Key Exchange**」消息发给服务端。
- 算好会话密钥后，客户端会发一个「**Change Cipher Spec**」消息，告诉服务端后续改用对称算法加密通信。
- 接着，客户端会发「**Encrypted Handshake Message**」消息，把之前发送的数据做一个摘要，再用对称密钥加密一下，让服务端做个验证，验证下本次生成的对称密钥是否可以正常使用。
- **这部分可以提前发送加密的HTTP数据，不等待最后一次握手。**

**4、第四次握手（Server）**

最后，服务端也会有一个同样的操作，发「**Change Cipher Spec**」和「**Encrypted Handshake Message**」消息，如果双方都验证加密和解密没问题，那么握手正式完成。于是，就可以正常收发加密的 HTTP 请求和响应了。



#### RSA和ECDHE的区别

- RSA 密钥协商算法「不支持」前向保密，ECDHE 密钥协商算法「支持」前向保密；
- 使用了 RSA 密钥协商算法，TLS 完成四次握手后，才能进行应用数据传输，而对于 ECDHE 算法，客户端可以不用等服务端的最后一次 TLS 握手，就可以提前发出加密的 HTTP 数据，节省了一个消息的往返时间；
- 使用 ECDHE， 在 TLS 第 2 次握手中，会出现服务器端发出的「Server Key Exchange」消息，而 RSA 握手过程没有该消息；



### HTTPS 中 TLS 和 TCP 能够同时握手吗？

需要下面这两个条件同时满足才可以：

- **客户端和服务端都开启了 TCP Fast Open 功能，且 TLS 版本是 1.3；**
- **客户端和服务端已经完成过一次通信。**



#### TCP Fast Open

TCP Fast Open 是为了绕过 TCP 三次握手发送数据，在 Linux 3.7 内核版本之后，提供了 TCP Fast Open 功能，这个功能可以减少 TCP 连接建立的时延。

要使用 TCP Fast Open 功能，客户端和服务端都要同时支持才会生效。

开启了 TCP Fast Open 功能，**想要绕过 TCP 三次握手发送数据，得建立第二次以后的通信过程。**

**1、第一次连接**

<img src="https://img-blog.csdnimg.cn/img_convert/7cb0bd3cde30493fec9562cbdb549f83.png" alt="图片" style="zoom:67%;" />

TCP 的第一次和第二次握手是不能够携带数据的，而 TCP 的第三次握手是可以携带数据的，因为这时候客户端的 TCP 连接状态已经是 ESTABLISHED，表明客户端这一方已经完成了 TCP 连接建立。

- 客户端发送 SYN 报文，该报文包含 Fast Open 选项，且该选项的 Cookie 为空，这表明客户端请求 Fast Open Cookie；
- 支持 TCP Fast Open 的服务器生成 Cookie，并将其置于 SYN-ACK 报文中的 Fast Open 选项以发回客户端；
- 客户端收到 SYN-ACK 后，本地缓存 Fast Open 选项中的 Cookie。



**2、第二次连接**

一次客户端和服务端通信的时候，还是需要正常的三次握手流程。随后，客户端就有了 Cookie 这个东西，它可以用来向服务器 TCP 证明先前与客户端 IP 地址的三向握手已成功完成。

<img src="https://img-blog.csdnimg.cn/img_convert/fc452688b9351e0cabf60212dde3f21e.png" alt="图片" style="zoom: 67%;" />

- 客户端发送 SYN 报文，该报文可以携带「应用数据」以及此前记录的 Cookie；
- 支持 TCP Fast Open 的服务器会对收到 Cookie 进行校验：如果 Cookie 有效，服务器将在 SYN-ACK 报文中对 SYN 和「数据」进行确认，服务器随后将「应用数据」递送给对应的应用程序；如果 Cookie 无效，服务器将丢弃 SYN 报文中包含的「应用数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；
- **如果服务器接受了 SYN 报文中的「应用数据」，服务器可在握手完成之前发送「响应数据」，这就减少了握手带来的 1 个 RTT 的时间消耗**；
- 客户端将发送 ACK 确认服务器发回的 SYN 以及「应用数据」，但如果客户端在初始的 SYN 报文中发送的「应用数据」没有被确认，则客户端将重新发送「应用数据」；
- 此后的 TCP 连接的数据传输过程和非 TCP Fast Open 的正常情况一致。



#### TLS v1.3

TCP 连接的第三次握手是可以携带数据的，如果客户端在第三次握手发送了 TLSv1.3 第一次握手数据，是不是就表示「***HTTPS 中的 TLS 握手过程可以同时进行三次握手***」？。

不是的，因为服务端只有在收到客户端的 TCP 的第三次握手后，才能和客户端进行后续 TLSv1.3 握手。

TLSv1.3 还有个更厉害到地方在于**会话恢复**机制，在**重连 TLvS1.3 只需要 0-RTT**，用“pre_shared_key”和“early_data”扩展，在 TCP 连接后立即就建立安全连接发送加密消息，过程如下图：

<img src="https://img-blog.csdnimg.cn/img_convert/59539201f006d7dc0a06333617e5ea85.png" alt="图片" style="zoom:50%;" />



#### TCP Fast Open + TLSv1.3

如果 HTTPS 的 TLS 版本是 1.3，那么 TLS 过程只需要 1-RTT。

**因此如果「TCP Fast Open + TLSv1.3」情况下，在第二次以后的通信过程中，TLS 和 TCP 的握手过程是可以同时进行的。**

**如果基于 TCP Fast Open 场景下的 TLSv1.3 0-RTT 会话恢复过程，不仅 TLS 和 TCP 的握手过程是可以同时进行的，而且 HTTP 请求也可以在这期间内一同完成。**



## TCP常见面试题

### 什么是TCP？

TCP 是**面向连接的、可靠的、基于字节流**的传输层通信协议。

- **面向连接**：一定是「一对一」才能连接，不能像 UDP 协议可以一个主机同时向多个主机发送消息，也就是一对多是无法做到的；
- **可靠的**：无论的网络链路中出现了怎样的链路变化，TCP 都可以保证一个报文一定能够到达接收端；
- **字节流**：用户消息通过 TCP 协议传输时，消息可能会被操作系统「分组」成多个的 TCP 报文，如果接收方的程序如果不知道「消息的边界」，是无法读出一个有效的用户消息的。并且 TCP 报文是「有序的」，当「前一个」TCP 报文没有收到的时候，即使它先收到了后面的 TCP 报文，那么也不能扔给应用层去处理，同时对「重复」的 TCP 报文会自动丢弃。



### 如何唯一地确定一个TCP连接

TCP 四元组可以唯一的确定一个连接，四元组包括源地址、源端口、目标地址、目标端口



### 有一个IP的服务器，监听了一个端口，它的TCP最大连接数是多少？如何解决？

- [ ] 理论值->实际值

服务器通常固定在某个本地端口上监听，等待客户端的连接请求。

**1、理论值**

客户端 IP 和 端口是可变的，其理论值计算公式如下:

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzExLmpwZw?x-oss-process=image/format,png)

对 IPv4，客户端的 IP 数最多为 `2` 的 `32` 次方，客户端的端口数最多为 `2` 的 `16` 次方，也就是服务端单机最大 TCP 连接数，约为 `2` 的 `48` 次方。



**2、实际值**

服务端最大并发 TCP 连接数远不能达到理论上限，存在fd限制和内存限制

- 文件描述符限制，每个 TCP 连接都是一个文件，如果文件描述符被占满了，会发生 too many open files。Linux 对可打开的文件描述符的数量分别作了三个方面的限制：
  - **系统级**：当前系统可打开的最大数量，通过 cat /proc/sys/fs/file-max 查看；
  - **用户级**：指定用户可打开的最大数量，通过 cat /etc/security/limits.conf 查看；
  - **进程级**：单个进程可打开的最大数量，通过 cat /proc/sys/fs/nr_open 查看；
- **内存限制**，每个 TCP 连接都要占用一定内存，操作系统的内存是有限的，如果内存资源被占满后，会发生 OOM。



### UDP 和 TCP 有什么区别呢？分别的应用场景是？

```c++
// 答题
/*
  区别：
  1、连接：TCP是面向连接的传输层协议，在传输数据之前需要先建立连接，而UDP则不需要建立连接，直接传输数据即可。并且TCP是1对1的通信，而UDP可以1对1，1对多，多对多。
  2、可靠性：TCP是可靠交付数据的，数据可以无差错、不丢失、不重复到达；而UDP则尽力传输，但不保证可靠交付数据。
  3、TCP有拥塞控制和流量控制，TCP连接的传输速率会动态变化，而UDP则不会
  4、TCP的首部较长，不算选项字段的话有20字节，而UDP只有8字节（port*2 + 包长度 + 校验和）
  5、TCP是流式传输，无法区分包与包之间的边界，而UDP是以包为单位传输的
  6、分片方式不同，TCP保证自己数据包的长度不会大于MSS，避免TCP在IP层被分片，而UDP只能在IP层分片
*/
```

**1、TCP 和 UDP 区别：**

***1. 连接***

- TCP 是面向连接的传输层协议，传输数据前先要建立连接。
- UDP 是不需要连接，即刻传输数据。

***2. 服务对象***

- TCP 是一对一的两点服务，即一条连接只有两个端点。
- UDP 支持一对一、一对多、多对多的交互通信

***3. 可靠性***

- TCP 是可靠交付数据的，数据可以无差错、不丢失、不重复、按需到达。
- UDP 是尽最大努力交付，不保证可靠交付数据。

***4. 拥塞控制、流量控制***

- TCP 有拥塞控制和流量控制机制，保证数据传输的安全性。
- UDP 则没有，即使网络非常拥堵了，也不会影响 UDP 的发送速率。

***5. 首部开销***

- TCP 首部长度较长，会有一定的开销，首部在没有使用「选项」字段时是 `20` 个字节，如果使用了「选项」字段则会变长的。

  <img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzYuanBn?x-oss-process=image/format,png" alt="TCP 头格式" style="zoom: 40%;" />

- UDP 首部只有 8 个字节，并且是固定不变的，开销较小。

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzEyLmpwZw?x-oss-process=image/format,png" alt="UDP 头部格式" style="zoom:50%;" />

***6. 传输方式***

- TCP 是流式传输，没有边界，但保证顺序和可靠。
- UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序。

***7. 分片不同***

- TCP 的数据大小如果大于 MSS 大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装 TCP 数据包，如果中途丢失了一个分片，只需要传输丢失的这个分片。
- UDP 的数据大小如果大于 MTU 大小，则会在 IP 层进行分片，目标主机收到后，在 IP 层组装完数据，接着再传给传输层。



**2、TCP 和 UDP 应用场景：**

由于 TCP 是面向连接，能保证数据的可靠性交付，因此经常用于：

- `FTP` 文件传输；
- HTTP / HTTPS；

由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：

- 包总量较少的通信，如 `DNS` 、`SNMP` 等；
- 视频、音频等多媒体通信；
- 广播通信；



### 为什么 UDP 中有长度字段，而 TCP 中没有？

实际上，udp 中的长度字段是多余的，因为 UDP 包和 TCP 包的数据都可以通过 IP 长度来计算得到（就是 IP包 长度减去 IP 头部）



### udp 调用 connect 有什么用？

1. 让应用程序可以接收到底层的**错误信息**，因为 connect 是将 UDP 套接字与服务端的端口和 IP 地址建立映射关系，有了这个映射关系操作系统内核就可以将 ICMP 的不可达信息与 UDP 套接字进行关联，从而进一步将这个错误信息通知给应用程序。而不适用 connect 的话，OS 是无法通过 ICMP 信息找到应用程序的，自然就没有办法通知到应用了。
2. UDP 需要调用 connect 之后才能使用 `send()` 和 `recv()` ，否则只能使用 `sendto()` 和 `recvfrom()` 。
3. 客户端通过 connect 绑定服务端的地址和端口，对 UDP 有一定程度的**性能提升**。如果不使用 connect 的话，客户端每次发送报文都需要频繁连接断开套接字（**连接套接字→发送报文→断开套接字→连接套接字→发送报文→断开套接字 →………**），而使用 connect 后只需要连接断开一次套接字即可（**连接套接字→发送报文→发送报文→……→最后断开套接字**），连接套接字是需要一定开销的，比如需要查找路由表信息。所以，UDP 客户端程序通过 connect 可以获得一定的性能提升。





### TCP连接的建立（三次握手）

#### 三次握手的流程

TCP 三次握手，其实就是建立一个 TCP 连接，客户端与服务器交互需要 3 个数据包。握手的主要作用就是为了确认双方的接收和发送能力是否正常，初始序列号，交换窗口大小以及 MSS 等信息。

TCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而**建立连接是通过三次握手来进行的**。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/socket%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="socket 三次握手" style="zoom:50%;" />

- **服务端监听连接**

  一开始，客户端和服务端都处于 `CLOSED` 状态。先是服务端主动监听某个端口，处于 `LISTEN` 状态

- **客户端发起连接发送初始化序列号**

  <img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzE1LmpwZw?x-oss-process=image/format,png" alt="第一个报文—— SYN 报文" style="zoom: 50%;" />

  客户端会随机初始化序号（`client_isn`），将此序号置于 TCP 首部的「序号」字段中，同时把 `SYN` 标志位置为 `1` ，表示 `SYN` 报文。接着把第一个 SYN 报文发送给服务端，表示向服务端发起连接，该报文不包含应用层数据，之后客户端处于 `SYN-SENT` 状态。

- **服务端ACK并发送初始化序列号**

  <img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzE2LmpwZw?x-oss-process=image/format,png" alt="第二个报文 —— SYN + ACK 报文" style="zoom:50%;" />

  服务端收到客户端的 `SYN` 报文后，首先服务端也随机初始化自己的序号（`server_isn`），将此序号填入 TCP 首部的「序号」字段中，其次把 TCP 首部的「确认应答号」字段填入 `client_isn + 1`, 接着把 `SYN` 和 `ACK` 标志位置为 `1`。最后把该报文发给客户端，该报文也不包含应用层数据，之后服务端处于 `SYN-RCVD` 状态。

- **客户端ACK**

  <img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzE3LmpwZw?x-oss-process=image/format,png" alt="第三个报文 —— ACK 报文" style="zoom:50%;" />

  客户端收到服务端报文后，还要向服务端回应最后一个应答报文，首先该应答报文 TCP 首部 `ACK` 标志位置为 `1` ，其次「确认应答号」字段填入 `server_isn + 1` ，最后把报文发送给服务端，这次报文**可以携带客户到服务器的数据**，之后客户端处于 `ESTABLISHED` 状态。

- **连接建立完毕**

  服务器收到客户端的应答报文后，也进入 `ESTABLISHED` 状态。



#### SYN包什么时候会被丢弃（字节二面）

**反问：这里丢弃指的是服务端收不到客户端的 SYN 包吗？，还是收到了 SYN 包，但是操作系统将包丢弃了（2022.07.06-只要收到了SYN，操作系统不会丢弃，除非连接队列满了）**

**这样反问好一点：丢弃是指现在被操作系统丢弃还是在传输途中被丢弃？**

SYN 报文被丢弃的三种场景：

- 开启 `tcp_tw_recycle` 参数，**旧版本内核**，并且**在 NAT 环境下**，造成 SYN 报文被丢弃

  这部分，是因为开启了 TIME_WAIT 状态复用和快速回收。

  - net.ipv4.tcp_tw_reuse，如果开启该选项的话，客户端（连接发起方） 在调用 connect() 函数时，**内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用**，所以该选项只适用于连接发起方。
  - net.ipv4.tcp_tw_recycle，如果开启该选项的话，允许处于 TIME_WAIT 状态的连接被快速回收；

  开启了 recycle 和 timestamps 选项，就会开启一种叫 per-host 的 PAWS 机制。**per-host 是对「对端 IP 做 PAWS 检查」**，而非对「IP + 端口」四元组做 PAWS 检查。

  而对于使用 NAT 网关的网络中，客户端经过 NAT 后都是同一个 IP 地址。但是服务端对序号回绕的判断是判断时间戳，这个时间戳是根据客户端自身的CPU计算得出的，如果处于 TIME_WAIT 客户端 A 的连接被客户端 B 复用，而此时客户端B计算的时间戳比A小，那么B的SYN会无法通过服务端PAWS，导致SYN包被丢弃。

- TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢弃

  也就是 SYN Flood 攻击了，如果半连接队列满了，在没有激活 `tcp_syn_cookies` 的情况下，会丢弃 SYN 包；如果激活了 `tcp_syn_cookies` ，则只有在两个队列都满了的情况下才会出现 SYN 包被丢弃的情况。

- ARP 层缓存队列已满，导致数据包在链路层被丢弃



#### 已建立连接的TCP，收到SYN会发生什么？

```c++
// 答题
/*
 就是建立连接后，客户端宕机，没有断开与服务端的连接，服务端仍处于ESTABLISHED状态，此时客户端重启后恢复了，再次与服务端发起连接SYN。
 这个问题需要分情况讨论：（因为一个四元组确定一个TCP连接）
 1、端口号不相同
 	那就是不同的四元组，可以视为一个新的TCP连接，因此服务端会与服务端建立新的连接，对于之前的TCP连接，如果开启了保护机制，那么服务端可以确认历史连接已经死亡，主动断开。
 2、端口号相同
 	此时是相同的四元组，可以视为相同的TCP连接，因此服务端会收到客户端的SYN报文，然后回复一个ACK，只不过这个ACK的序列号是正确的序列号，而不是SYN的中初始化序列号加一，当客户端收到不是期望的序列号时，会回复RST，关闭连接。
*/
```

即此时服务端处于 ESTABLISH 状态，而客户端中途宕机了，服务端也没有数据发送，一直处于 ESTABLISH 状态。后面客户端恢复，重新向服务端发起连接，会发生什么？

这个场景中，客户端的IP、服务端IP、目的端口并没有变化，所以这个问题关键要看客户端发送的 SYN 报文中的源端口是否和上一次连接的源端口相同。

**1、客户端的 SYN 报文里的端口号与历史连接不相同**

如果客户端恢复后发送的 SYN 报文中的源端口号跟上一次连接的源端口号不一样，此时服务端会认为是新的连接要建立，于是就会通过三次握手来建立新的连接。

那旧连接里处于 establish 状态的服务端最后会怎么样呢？

如果服务端发送了数据包给客户端，由于客户端的连接已经被关闭了，此时客户的内核就会回 **RST 报文**，服务端收到后就会释放连接。

如果服务端一直没有发送数据包给客户端，在超过一段时间后， **TCP 保活机制** 就会启动，检测到客户端没有存活后，接着服务端就会释放掉该连接。



**2、客户端的 SYN 报文里的端口号与历史连接相同**

如果客户端恢复后，发送的 SYN 报文中的源端口号跟上一次连接的源端口号一样，也就是处于 ESTABLISH 状态的服务端收到了这个 SYN 报文。

<img src="https://img-blog.csdnimg.cn/ac087152e9d94fddb8468696c65b11b0.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP5p6XY29kaW5n,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:50%;" />

**处于 establish 状态的服务端如果收到了客户端的 SYN 报文（注意此时的 SYN 报文其实是乱序的，因为 SYN 报文的初始化序列号其实是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK。**

**接着，客户端收到这个 Challenge ACK，发现序列号并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接。**





#### 为什么是三次握手？不是两次、四次？

TCP 建立连接时，通过三次握手**能防止历史连接的建立，能减少双方不必要的资源开销，能帮助双方同步初始化序列号**。序列号能够保证数据包不重复、不丢弃和按序传输。

不使用「两次握手」和「四次握手」的原因：

- 「两次握手」：无法防止历史连接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号；
- 「四次握手」：三次握手就已经理论上最少可靠连接建立，所以不需要使用更多的通信次数。



**主要有三方面的原因：**

- **阻止重复历史连接的初始化（主要原因）**

  在两次握手的情况下，「被动发起方」没有**中间状态**给「主动发起方」来**阻止历史连接**，导致「被动发起方」可能建立一个历史连接，造成资源浪费。

  两次握手的情况，客户端连续发送多次 SYN 建立连接的报文，在**网络拥堵**情况下：

  - 一个「旧 SYN 报文」比「最新的 SYN 」 报文早到达了服务端；
  - 那么此时服务端就会回一个 `SYN + ACK` 报文给客户端；
  - 然后服务端开始就发送数据了，直到客户端收到前面的 `SYN + ACK` 报文，才给服务端发送 `RST` **浪费了服务端的资源**。



- **三次握手才可以同步双方的初始序列号**

  TCP 协议的通信双方， 都必须维护一个「序列号」， 序列号是可靠传输的一个关键因素，它的作用：

  - 接收方可以去除重复的数据；
  - 接收方可以根据数据包的序列号按序接收；
  - 可以标识发送出去的数据包中， 哪些是已经被对方收到的（通过 ACK 报文中的序列号知道）；

  <img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzIwLmpwZw?x-oss-process=image/format,png" alt="四次握手与三次握手" style="zoom:50%;" />

  四次握手其实也能够可靠的同步双方的初始化序号，但由于**第二步和第三步可以优化成一步**，所以就成了「三次握手」。

  而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方的初始序列号都能被确认接收。

  

- **三次握手才可以避免资源浪费**

  如果只有「两次握手」，当客户端的 `SYN` 请求连接在网络中阻塞，客户端没有接收到 `ACK` 报文，就会重新发送 `SYN` ，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送的建立连接的 `ACK` 确认信号，所以每收到一个 `SYN` 就只能先主动建立一个连接。造成资源浪费。



> 2022-06-13，可以从四个方面来回答

1. **三次握手才能阻止重复历史连接的初始化**

   客户端由于某种原因发送了两个不同序号的 `SYN` 包，旧的数据包有可能先到达服务器。如果是两次握手，服务器收到旧的 `SYN` 就会立刻建立连接，那么会造成网络异常。

   如果是三次握手，服务器需要回复 `SYN+ACK` 包，客户端会对比应答的序号，如果发现是旧的报文，就会给服务器发 `RST` 报文，直到正常的 `SYN` 到达服务器后才正常建立连接。

   所以三次握手才有足够的上下文信息来判断当前连接是否是历史连接。

2. **三次握手才能确认双方的收发能力**

   TCP 建立连接之前，需要确认客户端与服务器双方的收包和发包的能力。

   - 第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。
   - 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。此时服务器并不能确认客户端的接收能力是否正常。
   - 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。

3. **序列号可靠传输**

   如果是两次握手，服务端无法确定客户端是否已经接收到了自己发送的初始序列号，如果第二次握手报文丢失，那么客户端就无法知道服务端的初始序列号，那 TCP 的可靠性就无从谈起。

4. **安全问题**

   TCP 新建连接时，内核会为连接分配一系列的内存资源，如果采用两次握手，就建立连接，那会放大 DDOS 攻击的。







#### 为什么每次建立 TCP 连接时，初始化的序列号都要求不一样呢？

```c++
// 答题
/*
  1、防止历史报文被下一个相同四元组的连接接收
  	随机初始化序列化可以避免历史报文的序列号落在新连接的滑动窗口内
  2、安全性，防止黑客伪造相同的tcp报文，让对方接收
*/
```

主要原因有两个方面：

- **为了防止历史报文被下一个相同四元组的连接接收（主要方面）**

  假设每次建立连接，客户端和服务端的初始化序列号都是从 0 开始：

  <img src="https://img-blog.csdnimg.cn/img_convert/9cbee7c645dad8ee2a1ad5fd31008d3c.png" alt="img" style="zoom: 33%;" />

  - 客户端和服务端建立一个 TCP 连接，在客户端发送**数据包被网络阻塞**了，而此时服务端认为连接超时，会发送 RST 报文来断开连接。
  - 紧接着，客户端又与服务端建立了与上一个连接相同四元组的连接；
  - 在新连接建立完成后，上一个连接中被网络阻塞的数据包正好抵达了服务端，刚好该数据包的序列号正好是在服务端的接收窗口内，所以该数据包会被服务端正常接收，就会造成数据错乱。

  当然也不能完全避免，因为序列号会有回绕的问题（因为只有4个字节），所以需要用**时间戳选项**的机制来判断历史报文。

  > 那么如何解决序列号回绕导致收到历史报文的问题呢？

  为了解决这个问题，就需要有 TCP 时间戳。tcp_timestamps 参数是默认开启的，开启了 tcp_timestamps 参数，TCP 头部就会使用时间戳选项，它有两个好处，**一个是便于精确计算 RTT ，另一个是能防止序列号回绕（PAWS）**。

  防回绕序列号算法要求连接双方维护最近一次收到的数据包的时间戳（Recent TSval），每收到一个新数据包都会读取数据包中的时间戳值跟 Recent TSval 值做比较，**如果发现收到的数据包中时间戳不是递增的，则表示该数据包是过期的，就会直接丢弃这个数据包**。

  

  > 如果时间戳也回绕怎么办？

  因为时间戳也是32位的，所以也会有回绕的可能性。

  Linux 以**本地时钟计数**（jiffies）作为时间戳的值，不同的增长时间会有不同的问题。

  要解决时间戳回绕的问题，可以考虑以下解决方案：

  **1）增加时间戳的大小，由32 bit扩大到64bit**

  这样虽然可以在能够预见的未来解决时间戳回绕的问题，但会导致新旧协议兼容性问题，像现在的IPv4与IPv6一样

  **2）将一个与时钟频率无关的值作为时间戳，时钟频率可以增加但时间戳的增速不变**

  随着时钟频率的提高，TCP在相同时间内能够收发的包也会越来越多。如果时间戳的增速不变，则会有越来越多的报文使用相同的时间戳。这种趋势到达一定程度则时间戳就会失去意义，除非在可预见的未来这种情况不会发生。

  

- **为了安全性，防止黑客伪造的相同序列号的 TCP 报文被对方接收**

  如果每次的序列号一样，黑客就可以模仿客户端给服务端发送TCP报文



#### 初始序列号 ISN 是如何随机产生的？

- [ ] 时钟＋基于四元组的哈希算法

RFC793 提到初始化序列号 ISN 随机生成算法：ISN = M + F(localhost, localport, remotehost, remoteport)。

- `M` 是一个计时器，这个计时器每隔 4 微秒加 1。
- `F` 是一个 Hash 算法，根据源 IP、目的 IP、源端口、目的端口生成一个随机数值。要保证 Hash 算法不能被外部轻易推算得出，用 MD5 算法是一个比较好的选择。





#### 握手丢失会发生什么？

##### 第一次握手丢失

第一次握手中，客户端向服务端发送SYN报文，然后进入 `SYN_SENT` 状态。

如果一段时间内客户端仍收不到服务端的 `SYN-ACK` 报文（第二次握手），就会触发**「超时重传」**机制，重传 SYN 报文。

- 不同版本的操作系统可能超时时间不同，有的 1 秒的，也有 3 秒的，这个超时时间是写死在内核里的，如果想要更改则需要重新编译内核，比较麻烦。
- 在 Linux 里，客户端的 SYN 报文最大重传次数由 `tcp_syn_retries`内核参数控制，这个参数是可以自定义的，默认值一般是 5。
- 当第五次超时重传后（**每次超时的时间是上一次的 2 倍**），会继续等待 32 秒，如果服务端仍然没有回应 ACK，客户端就不再发送 SYN 包，然后断开 TCP 连接。



##### 第二次握手丢失

第二次握手中，服务端向客户端发送 SYN-ACK 报文，然后会进入 `SYN_RCVD` 状态。

当第二次握手丢失了，**客户端和服务端都会重传**：

- 客户端没有收到服务端的ACK，会触发超时重传，重传 SYN 报文，也就是第一次握手，最大重传次数由 `tcp_syn_retries`内核参数决定；
- 服务端没有收到客户端的ACK，会触发超时重传，重传 SYN-ACK 报文，也就是第二次握手，最大重传次数由 `tcp_synack_retries` 内核参数决定。



##### 第三次握手丢失

第三次握手中，客户端给服务端发送 ACK 报文，然后进入 `ESTABLISH` 状态。

如果服务端那一方迟迟收不到这个确认报文，就会触发超时重传机制，重传 SYN-ACK 报文，直到收到第三次握手，或者达到最大重传次数。

**ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文**



#### 什么是 SYN 攻击？如何避免 SYN 攻击？

**1、什么是 SYN 攻击？**

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzI4LmpwZw?x-oss-process=image/format,png" alt="受到 SYN 攻击" style="zoom:50%;" />

攻击者短时间伪造不同 IP 地址的 `SYN` 报文，服务端每接收到一个 `SYN` 报文，就进入`SYN_RCVD` 状态，但服务端发送出去的 `ACK + SYN` 报文，无法得到未知 IP 主机的 `ACK` 应答，久而久之就会**占满服务端的半连接队列**，使得服务器不能为正常用户服务。

**2、如何避免 SYN 攻击**

- **修改 Linux 内核参数**，控制队列大小和当队列满时做的处理（对新的SYN回复RST，丢弃连接）

- **开启 tcp_syncookies 功能**

  <img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzI5LmpwZw?x-oss-process=image/format,png" alt="tcp_syncookies 应对 SYN 攻击" style="zoom:50%;" />

  1. 当 「 SYN 队列」满之后，后续服务器收到 SYN 包，不进入「 SYN 队列」；
  2. 按照一定规则计算出一个 `cookie` 值，再以 SYN + ACK 中的「序列号」返回客户端，
  3. 服务端接收到客户端的应答报文时，服务器会检查这个 ACK 包的合法性（看 `ACK - 1` 是否符合前面的规则）。如果合法，直接放入到「Accept 队列」。
  4. 最后应用通过调用 `accpet()` socket 接口，从「Accept 队列」取出的连接。
  
- **减少SYN+ACK重传次数**

  当服务端受到 SYN 攻击时，就会有大量处于 SYN_REVC 状态的 TCP 连接，处于这个状态的 TCP 会重传 SYN+ACK ，当重传超过次数达到上限后，就会断开连接。

  那么针对 SYN 攻击的场景，我们可以减少 SYN+ACK 的重传次数，以加快处于 SYN_REVC 状态的 TCP 连接断开。



### TCP连接的断开（四次挥手）

#### 四次挥手的流程

<img src="https://pic3.zhimg.com/80/v2-629f51f6f535ebd7683f944707b21d1e_720w.jpg" alt="img" style="zoom:80%;" />

<img src="C:\Users\zhouxingxing\AppData\Roaming\Typora\typora-user-images\image-20220524172452581.png" alt="image-20220524172452581" style="zoom:50%;" />

- 客户端/服务端其中一方调用 `close()` ，发送`FIN`报文

  客户端打算关闭连接，此时会发送一个 TCP 首部 `FIN` 标志位被置为 `1` 的报文，也即 `FIN` 报文，之后客户端进入 `FIN_WAIT_1` 状态。（FIN 包不携带数据，但是）

- 服务端收到该报文后，就向客户端发送 `ACK` 应答报文，接着服务端进入 `CLOSED_WAIT` 状态。

- 客户端收到服务端的 `ACK` 应答报文后，之后进入 `FIN_WAIT_2` 状态。

- 服务器继续处理剩余的数据，并向客户端发送剩余数据的结果，完成后才发送`FIN`报文

  等待服务端处理完数据后，也向客户端发送 `FIN` 报文，之后服务端进入 `LAST_ACK` 状态。

- 客户端收到服务端的 `FIN` 报文后，回一个 `ACK` 应答报文，之后进入 `TIME_WAIT` 状态

- 服务器收到了 `ACK` 应答报文后，就进入了 `CLOSED` 状态，至此服务端已经完成连接的关闭。

- 客户端在经过 `2MSL` 一段时间后，自动进入 `CLOSED` 状态，至此客户端也完成连接的关闭。

**注意：FIN报文中依然可以携带数据**



#### 为什么需要挥手需要四次？

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务器收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，**等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接**。

服务端通常需要等待完成数据的发送和处理，所以服务端的 `ACK` 和 `FIN` 一般都会分开发送，从而比三次握手导致多了一次。



#### 挥手丢失会发生什么？

##### 第一次挥手丢失

- [ ] 超时重传 + 直接进入close

- **第一次挥手干什么？**

当客户端（主动关闭方）调用 close 函数后，就会向服务端发送 FIN 报文，试图与服务端断开连接，此时客户端的连接进入到 `FIN_WAIT_1` 状态。

正常情况下，如果能及时收到服务端（被动关闭方）的 ACK，则会很快变为 `FIN_WAIT2`状态。



- **第一次挥手丢失怎么办？**

如果第一次挥手丢失了，那么客户端迟迟收不到被动方的 ACK 的话，也就会**触发超时重传机制**，重传 FIN 报文，重发次数由 `tcp_orphan_retries` 参数控制。

当客户端重传 FIN 报文的次数超过 `tcp_orphan_retries` 后，就不再发送 FIN 报文**，直接进入到 `close` 状态。**



##### 第二次握手丢失

- **第二次挥手干什么？**

当服务端收到客户端的第一次挥手后，就会先回一个 ACK 确认报文，此时服务端的连接进入到 `CLOSE_WAIT` 状态。

- **丢失了怎么办？**

由于 ACK 报文是不会重传的，所以如果服务端的第二次挥手丢失了，**客户端就会触发超时重传机制，重传 FIN 报文**，直到收到服务端的第二次挥手，或者达到最大的重传次数。

- **需要注意的地方**

当**客户端收到第二次挥手**，也就是收到服务端发送的 ACK 报文后，客户端就会处于 `FIN_WAIT2` 状态，在这个状态需要等服务端发送第三次挥手，也就是服务端的 FIN 报文。

**对于 close 函数关闭的连接**，由于无法再发送和接收数据，所以`FIN_WAIT2` 状态不可以持续太久，而 `tcp_fin_timeout` 控制了这个状态下**连接的持续时长**，默认值是 60 秒。

**对于使用 shutdown 函数关闭的连接且指定只关闭发送方向**，而接收方向并没有关闭，那么意味着主动关闭方还是可以接收数据的。如果主动关闭方一直没收到第三次挥手，那么主动关闭方的连接将会一直处于 `FIN_WAIT2` 状态（`tcp_fin_timeout` 无法控制 shutdown 关闭的连接）。



##### 第三个挥手丢失

- **第三次挥手干什么？**

当服务端（被动关闭方）收到客户端（主动关闭方）的 FIN 报文后，内核会自动回复 ACK，同时连接处于 `CLOSE_WAIT` 状态，顾名思义，它表示等待应用进程调用 close 函数关闭连接。

服务端处于 `CLOSE_WAIT` 状态时，调用了 close 函数，内核就会发出 FIN 报文，同时连接进入 LAST_ACK 状态，等待客户端返回 ACK 来确认连接关闭。

- **丢失了怎么办？**

服务端就会重发 FIN 报文，重发次数仍然由 `tcp_orphan_retrie` 参数控制，这与客户端重发 FIN 报文的重传次数控制方式是一样的。



##### 第四个挥手丢失

- **第四次挥手干什么？**

当客户端收到服务端的第三次挥手的 FIN 报文后，就会回 ACK 报文，也就是第四次挥手，此时客户端连接进入 `TIME_WAIT` 状态。

在 Linux 系统，TIME_WAIT 状态会持续 2MSL 后才会进入关闭状态。

- **丢失了怎么办？**

由于 ACK 报文是不会重传的，所以如果客户端的第四次挥手丢失了，**客户端就会触发超时重传机制，重传 FIN 报文**，直到收到客户端的第四次挥手，或者达到最大的重传次数。



#### 为什么 TIME_WAIT 等待的时间是 2MSL？（微信二面）

**`TIME_WAIT ` 是主动关闭方接收到被动关闭方FIN时的状态**，`2MSL` 的时间是从**客户端接收到 FIN 后发送 ACK 开始计时的**。如果在 TIME-WAIT 时间内，因为客户端的 ACK 没有传输到服务端，客户端又接收到了服务端重发的 FIN 报文，那么 **2MSL 时间将重新计时**。

`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 `TTL` 字段（Time to live，生存时间值，一般为 64 ），是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数据报将被丢弃，同时发送 ICMP 报文通知源主机。

MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡。

**TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了**。

被动关闭方没有收到断开连接的最后的 ACK 报文，就会触发超时重发 `FIN` 报文，另一方接收到 FIN 后，会重发 ACK 给被动关闭方， 一来一去正好 2 个 MSL。 **2MSL时长** 这其实是相当于**至少允许报文丢失一次**。



#### 为什么需要TIME_WAIT状态（微信二面）

主动发起关闭连接的一方，才会有 `TIME-WAIT` 状态。

需要 TIME-WAIT 状态，主要是两个原因：

- **防止历史连接中的数据，被后面相同四元组的连接错误的接收；**

  该数据报文的序列号刚好在客户端接收窗口内，因此客户端会正常接收这个数据报文，但是这个数据报文是上一个连接残留下来的，这样就产生数据错乱等严重的问题。

  因此 TCP 设计了 `TIME_WAIT` 状态，状态会持续 `2MSL` 时长，**这个时间足以让两个方向上的数据包都被丢弃**，使得原来连接的数据包在网络中都自然消失，再出现的数据包一定都是新建立连接所产生的。

- **保证「被动关闭连接」的一方，能被正确的关闭；**

  如果客户端（主动关闭方）最后一次 ACK 报文（第四次挥手）在网络中丢失了，那么按照 TCP 可靠性原则，服务端（被动关闭方）会重发 FIN 报文。











#### TIME_WAIT 过多有什么危害？

- [ ] **内存资源 + 端口资源**



过多的 TIME-WAIT 状态主要的危害有两种：

- 第一是内存资源占用；
- 第二是对端口资源的占用，一个 TCP 连接至少消耗「发起连接方」的一个本地端口；

客户端（发起连接方）受端口资源限制：

- 客户端TIME_WAIT过多，就会导致端口资源被占用，因为端口就 65536 个，被占满就会导致无法创建新的连接。
- 在socket的TIME_WAIT状态结束之前，该socket所占用的本地端口号将一直无法释放。

服务端（被动连接方）受系统资源限制：

- 由于一个四元组表示 TCP 连接，理论上服务端可以建立很多连接，因为服务端只监听一个端口，不会因为 TCP 连接过多而导致端口资源受限。但是 TCP 连接过多，会占用系统资源，比如文件描述符、内存资源、CPU 资源、线程资源等。



#### 如何优化 TIME_WAIT？

- [ ] **TIME_WAIT 复用 + 跳过 TIME_WAIT**

- **打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项；**

  **tcp_tw_reuse 功能只能用客户端（连接发起方），因为开启了该功能，在调用 connect() 函数时，内核会随机找一个 time_wait 状态超过 1 秒的连接给新的连接复用。**在TCP头部的选项字段中加入时间戳

- **net.ipv4.tcp_max_tw_buckets**（TIME_WAIT 状态的最大数量）

- **程序中使用 SO_LINGER ，应用强制使用 RST 关闭。**

  如果`l_onoff`为非 0， 且`l_linger`值为 0，那么调用`close`后，会立该发送一个`RST`标志给对端，该 TCP 连接将跳过四次挥手，也就跳过了`TIME_WAIT`状态，直接关闭。



#### 如果已经建立了连接，但是客户端突然出现故障了怎么办？

```c
//答题
/*
  1、反问 -> 故障指的是？
  2、【对端程序崩溃等报文不可达】：有无保活机制？ 保活探测 ： 寄了；
     【对端正常工作】：保活机制
     【对端宕机后重启】：收到探测报文后回复RST（因为没有该TCP连接的信息了）
*/
```



- TCP 有一个机制是**保活机制**。这个机制的原理是这样的：

定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制会开始作用，每隔一个时间间隔，发送一个探测报文，该探测报文包含的数据非常少，如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。

在 Linux 内核可以有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔

应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 `SO_KEEPALIVE` 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。

- 如果开启了 TCP 保活，需要考虑以下几种情况：
  - 第一种，对端程序是正常工作的。当 TCP 保活的探测报文发送给对端, 对端会正常响应，这样 **TCP 保活时间会被重置**，等待下一个 TCP 保活时间的到来。
  - 第二种，对端程序崩溃并重启。当 TCP 保活的探测报文发送给对端后，对端是可以响应的，但由于没有该连接的有效信息，**会产生一个 RST 报文**，这样很快就会发现 TCP 连接已经被重置。
  - 第三种，是对端程序崩溃，或对端由于其他原因导致报文不可达。当 TCP 保活的探测报文发送给对端后，石沉大海，没有响应，连续几次，达到保活探测次数后，**TCP 会报告该 TCP 连接已经死亡**。

- linux的保护机制时间过长，可以在应用层实现一个心跳机制，来处理长连接的超时时间。



#### 如果已经建立了连接，但是服务端的进程崩溃会发生什么？

所有的进程在被终止（结束）时，Unix操作系统内核都会事先去关闭所有已经打开的 TCP 连接，即向客户端发生FIN标志报文，进行四次握手关闭连接。



#### 如果双方同时关闭连接，会发生什么？

由于 TCP 是全双工的协议，所以是会出现两方同时关闭连接的现象，也就是同时发送了 FIN 报文。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/38.jpg" alt="同时关闭" style="zoom:50%;" />

接下来，**双方在等待 ACK 报文的过程中，都等来了 FIN 报文。这是一种新情况，所以连接会进入一种叫做 CLOSING 的新状态，它替代了 FIN_WAIT2 状态**。接着，双方内核回复 ACK 确认对方发送通道的关闭后，进入 TIME_WAIT 状态，等待 2MSL 的时间后，连接自动关闭。



#### 不使用close/shutdown如何关闭一个TCP连接？

首先，直接 kill 掉进程是不行的，因为这样会导致该进程所有的连接都断开。

直接发送 RST 包的话有个问题，无法保证包的序列号落在对方的滑动窗口内。因此，可以先通过发送 SYN 包的方式，获取序列号和 ACK 号。（原理见[已建立连接的TCP，收到SYN会发生什么？](#已建立连接的TCP，收到SYN会发生什么？)）

<img src="https://img-blog.csdnimg.cn/95592346a9a747819cd27741a660213c.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP5p6XY29kaW5n,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:50%;" />

在 Linux 上有个叫 killcx 的工具，就是基于上面这样的方式实现的，它会主动发送 SYN 包获取 SEQ/ACK 号，然后利用 SEQ/ACK 号伪造两个 RST 报文分别发给客户端和服务端，这样双方的 TCP 连接都会被释放，这种方式活跃和非活跃的 TCP 连接都可以杀掉。



#### 四次挥手中收到乱序的 FIN 包会如何处理？（腾讯二面）

这个问题等价于「在 FIN_WAIT_2 状态下，是如何处理收到的乱序到 FIN 报文，然后 TCP 连接又是什么时候才进入到 TIME_WAIT 状态?」

**1、对于关闭了读方向的连接，则会回复 RST 报文**

**2、对于关闭了写方向的连接，则会将 FIN 报文 放入乱序队列**

<img src="https://img-blog.csdnimg.cn/4effcf2a9e7e4adeb892da98ee21694b.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA5bCP5p6XY29kaW5n,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:50%;" />

**在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，那么就被会加入到「乱序队列」，并不会进入到 TIME_WAIT 状态。**

等再次收到前面被网络延迟的数据包时，会判断乱序队列有没有数据，然后会检测乱序队列中是否有可用的数据，如果能在乱序队列中找到与当前报文的序列号保持的顺序的报文，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态。



#### 在TIME_WAIT状态的TCP连接，收到 SYN 后会发生什么？

问题等价于「**在 TCP 正常挥手过程中，处于 TIME_WAIT 状态的连接，收到相同四元组的 SYN 后会发生什么？**」

<img src="https://img-blog.csdnimg.cn/img_convert/74b53919396dcda634cfd5b5795cbf16.png" alt="图片" style="zoom:50%;" />

首先需要判断 SYN 的**「序列号和时间戳」**是否合法，

> 什么是「合法」的 SYN？

如果是短时间内，同一四元组的 SYN 序列号大概率是合法的，因为初始化序列号是通过时钟+基于四元组的哈希算法计算的。

**对于开启了 TCP 时间戳选项的连接**

- **合法 SYN**：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要**大**，**并且** SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要**大**。
- **非法 SYN**：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要**小**，**或者** SYN 的「时间戳」比服务端「最后收到的报文的时间戳」要**小**。

**对于没有开启 TCP 时间戳选项的连接**

- **合法 SYN**：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要**大**。
- **非法 SYN**：客户端的 SYN 的「序列号」比服务端「期望下一个收到的序列号」要**小**。



**1、收到合法 SYN**

<img src="https://img-blog.csdnimg.cn/img_convert/39d0d04adf72fe3d37623acff9ae2507.png" alt="图片" style="zoom:50%;" />

如果处于 TIME_WAIT 状态的连接收到「合法的 SYN 」后，**就会重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程**。



**2、收到非法的 SYN**

<img src="https://img-blog.csdnimg.cn/img_convert/642a6699c0234da3444e96805dddcc09.png" alt="图片" style="zoom:50%;" />

如果处于 TIME_WAIT 状态的连接收到「非法的 SYN 」后，就会**再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号（ack num），就回 RST 报文给服务端**。



#### 在 TIME_WAIT 状态，收到 RST 会断开连接吗？

- 如果 `net.ipv4.tcp_rfc1337` 参数为 0，则提前结束 TIME_WAIT 状态，释放连接。
- 如果 `net.ipv4.tcp_rfc1337` 参数为 1，则会丢掉该 RST 报文。

通过 RST 报文来释放连接是有风险的，因为 TIME_WAIT 有两个作用：

1. 防止历史连接中的数据被，后面相同四元组的连接错误的接收
2. 保证被动关闭连接的一方，能够正确的关闭

所以，我个人觉得将 `net.ipv4.tcp_rfc1337` 设置为 1 会比较安全。



#### TCP 连接，一端断电和进程崩溃有什么区别？（腾讯二面）

这个问题有四个条件：

- 没有开启 keepalive；
- **一直没有数据交互；**
- 进程崩溃；
- 主机崩溃；

 TCP keepalive 就是 **TCP 的保活机制**，定义一个时间段，在这个时间段内，如果没有任何连接相关的活动，TCP 保活机制就会开始作用，每隔一个时间间隔，发送一个探测报文（探测报文的数据量非常少），如果连续几个探测报文都没有得到响应，则认为当前的TCP 连接已经死亡，系统内核会将错误信息通知给上层应用程序。

应用程序若想使用 TCP 保活机制需要通过 socket 接口设置 `SO_KEEPALIVE` 选项才能够生效，如果没有设置，那么就无法使用 TCP 保活机制。

> 在没有开启 TCP keepalive，且双方一直没有数据交互的情况下，如果客户端的「主机崩溃」了，会发生什么。

客户端主机崩溃了，服务端是**无法感知到的**，在加上服务端没有开启 TCP keepalive，又没有数据交互的情况下，**服务端的 TCP 连接将会一直处于 ESTABLISHED 连接状态**，直到服务端重启进程。（如果此时客户端重新发起连接了呢？见[已建立连接的TCP，收到SYN会发生什么？](#已建立连接的TCP，收到SYN会发生什么？)）

所以，我们可以得知一个点，在没有使用 TCP 保活机制且双方不传输数据的情况下，一方的 TCP 连接处在 ESTABLISHED 状态，并不代表另一方的连接还一定正常。



> 那如果是「进程崩溃」的情况呢？

即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃，这个过程**操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手。**



> 再考虑「有数据传输」下的异常情况

- 第一种，客户端主机宕机，又迅速重启，会发生什么？
- 第二种，客户端主机宕机，一直没有重启，会发生什么？

**客户端主机宕机，又迅速重启**

1. **迅速重启后发起连接（SYN）**：见[已建立连接的TCP，收到SYN会发生什么？](#已建立连接的TCP，收到SYN会发生什么？)
2. **没有发起连接**：收到服务端超时重传的报文后回复 RST 
   - 客户端没有进程监听该目标端口号，OS回复 RST 
   - 客户端有进程监听该目标端口号，但是主机重启后，之前的socket已经丢失，内核在协议栈找不到socket，回复 RST 



**客户端主机宕机，一直没有重启**

服务端超时重传报文的次数达到一定阈值后，内核就会判定出该 TCP 有问题，然后通过 Socket 接口告诉应用程序该 TCP 连接出问题了，一般就是 ETIMEOUT 状态码。

**在重传报文且一直没有收到对方响应的情况时，先达到「最大重传次数」或者「最大超时时间」这两个的其中一个条件后，就会停止重传**。



#### 拔掉网线后，已经建立的TCP连接会怎么样

客户端拔掉网线后，并不会直接影响 TCP 连接状态（socket）。所以，拔掉网线后，TCP 连接是否还会存在，关键要看拔掉网线之后，有没有进行数据传输。

有数据传输的情况：

- 在客户端拔掉网线后，如果服务端发送了数据报文，那么在服务端重传次数没有达到最大值之前，客户端就插回了网线，那么双方原本的 TCP 连接还是能正常存在，就好像什么事情都没有发生。
- 在客户端拔掉网线后，如果服务端发送了数据报文，在客户端插回网线之前，服务端重传次数达到了最大值时，服务端就会断开 TCP 连接。等到客户端插回网线后，向服务端发送了数据，因为服务端已经断开了与客户端相同四元组的 TCP 连接，所以就会回 RST 报文，客户端收到后就会断开 TCP 连接。至此， 双方的 TCP 连接都断开了。

没有数据传输的情况：

- 如果双方都没有开启 **TCP keepalive** 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。
- 如果双方都开启了 **TCP keepalive** 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。



#### 如果双方同时断开连接，会发生什么？

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/38.jpg" alt="同时关闭" style="zoom:50%;" />

两方发送 FIN 报文时，都认为自己是主动方，所以都进入了 FIN_WAIT1 状态，FIN 报文的重发次数仍由 tcp_orphan_retries 参数控制。

接下来，**双方在等待 ACK 报文的过程中，都等来了 FIN 报文。这是一种新情况，所以连接会进入一种叫做 CLOSING 的新状态，它替代了 FIN_WAIT2 状态**。接着，双方内核回复 ACK 确认对方发送通道的关闭后，进入 TIME_WAIT 状态，等待 2MSL 的时间后，连接自动关闭。





#### 收到 RST 包就一定会断开连接吗？

不会，看下这个seq是否在合法**接收窗口**范围内。**如果不在范围内，这个RST包就会被丢弃。**防止黑客伪造RST包，进行RST攻击。



#### 什么情况会出现 RST 包

1.连接请求到达时，目的端口不存在。

2.向一个已经关闭的连接发送数据。

3.向一个已经崩溃的对端发送数据。

4.请求超时。 接收端在接收数据超时时，会发送RST包。

5.关闭 socket 时，直接丢弃接收缓冲区未读取的数据，并给对方发一个RST。

6.TCP收到了一个根本不存在的连接上的报文。

7.处理半打开连接时。一方关闭了连接，另一方却由于网络故障等原因没有收到结束报文，还维持着原来的连接，这种状态就叫做半打开连接。此时另一方往处于半打开状态的连接写数据的话，对方就会回应RST。



#### close 和 shutdown 的区别？

<img src="https://s1.328888.xyz/2022/05/26/lNh2A.png" alt="lNh2A.png" style="zoom: 15%;" />

`shutdown(fd, SHUT_RDWR)` 和 `close(fd)` 的差别：

- close 会关闭连接，并释放所有连接对应的资源，而 shutdown 并不会释放掉套接字和所有的资源。
- close 存在引用计数的概念，并不一定导致该套接字不可用；shutdown 则不管引用计数，直接使得该套接字不可用，如果有别的进程企图使用该套接字，将会受到影响。
- close 的引用计数导致不一定会发出 FIN 结束报文，而 shutdown 则总是会发出 FIN 结束报文，这在我们打算关闭连接通知对端的时候，是非常重要的。

**往已经close 的 TCP 连接里面写数据，会收到RST，产生 SIGPIPE信号 ，默认 SIGPIPE信号 的忽略行为就是退出程序，因此需要优雅关闭 TCP 连接需要忽略这个信号。**







### SOCKET编程

#### 握手过程中的内核是如何处理的？

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzM1LmpwZw?x-oss-process=image/format,png" alt=" SYN 队列 与 Accpet 队列 " style="zoom:50%;" />

Linux内核中会维护两个队列：

- 半连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态；
- 全连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态；

`int listen (int socketfd, int backlog)` 中：

在早期linux内核，backlog指的是SYN队列的长度，现在一般只ACCEPT队列的长度







#### ACCEPT发生在三次握手的哪一步？

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4/%E7%BD%91%E7%BB%9C/socket%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B.drawio.png" alt="socket 三次握手" style="zoom:50%;" />

**客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。**



#### 客户端调用 close 了，连接断开的流程是什么？

<img src="https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzM3LmpwZw?x-oss-process=image/format,png" alt="客户端调用 close 过程" style="zoom:50%;" />

- 客户端调用 `close`，表明客户端没有数据需要发送了，则此时会向服务端发送 FIN 报文，进入 FIN_WAIT_1 状态；
- 服务端接收到了 FIN 报文，TCP 协议栈会为 FIN 包插入一个文件结束符 `EOF` 到接收缓冲区中，应用程序可以通过 `read` 调用来感知这个 FIN 包。这个 `EOF` 会被**放在已排队等候的其他已接收的数据之后**，这就意味着服务端需要处理这种异常情况，因为 EOF 表示在该连接上再无额外数据到达。此时，服务端进入 CLOSE_WAIT 状态；
- 接着，当处理完数据后，自然就会读到 `EOF`，于是也调用 `close` 关闭它的套接字，这会使得服务端发出一个 FIN 包，之后处于 LAST_ACK 状态；
- 客户端接收到服务端的 FIN 包，并发送 ACK 确认包给服务端，此时客户端将进入 TIME_WAIT 状态；
- 服务端收到 ACK 确认包后，就进入了最后的 CLOSE 状态；
- 客户端经过 `2MSL` 时间之后，也进入 CLOSE 状态；



### TCP可靠传输的实现

TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的

- [ ] 通过序列号+确认应答
- [ ] 超时重传+快速重传+SACK方法+Duplicate SACK

#### 重传机制

##### 超时重传

**数据包丢失**和**ACK丢失**都会触发超时重传

重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据，也就是我们常说的**超时重传**。



超时重传时间以 `RTO` （Retransmission Timeout 超时重传时间）表示

> 超时时间 `RTO` 「较长或较短」时，会发生什么事情呢？

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/7.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="超时时间较长与较短" style="zoom: 50%;" />

- 当超时时间 **RTO 较大**时，重发就慢，丢了老半天才重发，没有效率，性能差；
- 当超时时间 **RTO 较小**时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。

因此，**超时重传时间 RTO 的值应略大于报文往返 RTT 的值，并且随RTT的变化动态调整**

- 需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个平滑 RTT 的值，而且这个值还是要不断变化的，因为网络状况不断地变化。
- 除了采样 RTT，还要采样 RTT 的波动范围，这样就避免如果 RTT 有一个大的波动的话，很难被发现的情况。



如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**

最大超时重传次数是由 `tcp_retries2` 指定，默认值是 15 次



##### 快速重传

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/10.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="快速重传机制" style="zoom:50%;" />

快速重传（Fast Retransmit）机制，不以时间为驱动，而是**以数据驱动重传**，用于解决超时重传时间过长的问题。

快速重传的工作方式是当收到**三个相同的 ACK 报文**时，会在定时器过期之前，重传丢失的报文段。

**但是并不知道重传丢失的包，还是后面所有的包**



##### SACK方法（选择性确认）

`SACK`（ Selective Acknowledgment 选择性确认）

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/11.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="选择性确认" style="zoom: 50%;" />

在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。

Linux 2.4 后默认打开



##### D-SACK

Duplicate SACK 又称 `D-SACK`，其主要**使用 SACK 来告诉「发送方」有哪些数据被重复接收了。**

1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
2. 可以知道是不是「发送方」的数据包被网络延迟了;
3. 可以知道网络中是不是把「发送方」的数据包给复制了;

Linux 2.4 后默认打开



#### 滑动窗口

**TCP的发送窗口由接收端通告窗口和拥塞窗口的较小值决定。**

一问一答的传输方式效率过低，数据包的**往返时间越长，通信的效率就越低**。于是引入发送窗口的概念，在这个窗口里面，**无需等待确认应答，而可以继续发送数据**。

窗口的实现实际上是**操作系统开辟的一个缓存空间**，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。

**发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。**

**1、发送方窗口**

![SND.WND、SND.UN、SND.NXT](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/19.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

- `SND.WND`：表示发送窗口的大小（大小是由接收方指定的）；
- `SND.UNA`：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节。
- `SND.NXT`：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节。

**可用窗口大小 = SND.WND -（SND.NXT - SND.UNA）**

**可用窗口大小 = 发送窗口大小 - 已发送但未收到ACK的窗口大小**



**2、接收方窗口**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/20.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="接收窗口" style="zoom:67%;" />

- `RCV.WND`：表示接收窗口的大小，它会通告给发送方。
- `RCV.NXT`：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节。
- 指向 #4 的第一个字节是个相对指针，它需要 `RCV.NXT` 指针加上 `RCV.WND` 大小的偏移量，就可以指向 #4 的第一个字节了。



> 接收窗口和发送窗口的大小是相等的吗？

并不是完全相等，接收窗口的大小是**约等于**发送窗口的大小的。

因为新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。



#### 流量控制

发送方不能无节制的发数据给接收方，要考虑接收方处理能力。

如果一直无节制的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。



##### 操作系统缓冲区与滑动窗口的关系

接收方接收数据后，需要应用层序读取数据后才会移动 `RCV.NXT`

并且操作系统在资源紧张时，会主动缩小窗口



##### 窗口关闭

TCP 通过让接收方指明希望从发送方接收的数据大小（窗口大小）来进行流量控制。

**如果窗口大小为 0 时，就会阻止发送方给接收方传递数据，直到窗口变为非 0 为止，这就是窗口关闭。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/24.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="窗口关闭潜在的危险" style="zoom:50%;" />

> TCP 是如何解决窗口关闭时，潜在的死锁现象呢？

TCP 为每个连接设有一个持续定时器，**只要 TCP 连接一方收到对方的零窗口通知，就启动持续计时器。**如果持续计时器超时，就会发送**窗口探测 ( Window probe ) 报文**，而对方在确认这个探测报文时，给出自己现在的接收窗口大小。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/25.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="窗口探测" style="zoom:50%;" />

- 如果接收窗口仍然为 0，那么收到这个报文的一方就会重新启动持续计时器；
- 如果接收窗口不是 0，那么死锁的局面就可以被打破了。

窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 `RST` 报文来中断连接。



##### 糊涂窗口综合症

如果接收方太忙了，来不及取走接收窗口里的数据，那么就会导致发送方的发送窗口越来越小。

到最后，**如果接收方腾出几个字节并告诉发送方现在有几个字节的窗口，而发送方会义无反顾地发送这几个字节，这就是糊涂窗口综合症**。

- 让接收方不通告小窗口给发送方
- 让发送方避免发送小数据

**1、让接收方不通告小窗口？**

接收方通常的策略如下:

当「窗口大小」小于 min( MSS，缓存空间/2 ) ，也就是小于 MSS 与 1/2 缓存大小中的最小值时，就会向发送方通告窗口为 `0`（**关闭窗口**），也就阻止了发送方再发数据过来。

等到接收方处理了一些数据后，窗口大小 >= MSS，或者接收方缓存空间有一半可以使用，就可以把窗口打开让发送方发送数据过来。



**2、让发送方避免发送小数据**

使用 Nagle 算法，该算法的思路是延时处理，它满足以下两个条件中的一条才可以发送数据：

- 要等到窗口大小 >= `MSS` 或是 数据大小 >= `MSS`
- 收到之前发送数据的 `ack` 回包

可以在 Socket 设置 `TCP_NODELAY` 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）



#### 拥塞控制

拥塞窗口 `cwnd` 变化的规则：

- 只要网络中没有出现拥塞，`cwnd` 就会增大；
- 但网络中出现了拥塞，`cwnd` 就减少；



> 怎么知道当前网络是否出现了拥塞呢？

只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**



拥塞控制主要有四个算法：慢启动、拥塞控制、拥塞发生、快速恢复



##### 拥塞控制和流量控制的区别

- 拥塞控制是作用于**网络**的，它是防止发送方过多的数据注入到网络中，避免出现网络负载过大的情况。
- 流量控制是作用于**发送方**的，它是控制发送方的发送速度从而使接收者来得及接收，防止分组丢失的。



##### 慢启动

TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，如果一开始就发大量的数据，容易造成网络拥堵。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/27.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="慢启动算法" style="zoom:50%;" />

慢启动的算法记住一个规则就行：**当发送方每收到一个 ACK，拥塞窗口 cwnd 的大小就会加 1。**

> 慢启动的上限是什么呢？

有一个叫慢启动门限 `ssthresh` （slow start threshold）状态变量。

- 当 `cwnd` < `ssthresh` 时，使用慢启动算法。
- 当 `cwnd` >= `ssthresh` 时，就会使用「拥塞避免算法」。

一般来说 `ssthresh` 的大小是 `65535` 字节。



##### 拥塞避免算法

进入拥塞避免算法后，它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/28.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="拥塞避免" style="zoom:50%;" />

拥塞避免算法就是将原本慢启动算法的**指数增长**变成了**线性增长**，还是增长阶段，但是增长速度缓慢了一些。



##### 拥塞发生

当网络出现拥塞，也就是会发生数据包重传，重传机制主要有两种：

- 超时重传
- 快速重传



**1、超时重传**

- [ ] **窗口设为1，慢启动上限为原来窗口的一半，慢启动**

当发生「超时重传」，使用拥塞发生算法。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/29.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="拥塞发送 —— 超时重传" style="zoom:50%;" />

这个时候，ssthresh 和 cwnd 的值会发生变化（**窗口设为1，慢启动上限为原来窗口的一半**）：

- `ssthresh` 设为 `cwnd/2`，
- `cwnd` 重置为 `1`

接着，就重新开始**慢启动**，慢启动是会突然减少数据流的。这种方式太激进了，反应也很强烈，**会造成网络卡顿**。



**2、快速重传**

- [ ] **窗口缩一半，慢启动上限变为原来的窗口大小，快速恢复**

当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下（**窗口缩一半，慢启动上限变为原来的窗口大小**）：

- `cwnd = cwnd/2` ，也就是设置为原来的一半;
- `ssthresh = cwnd` ；
- 进入快速恢复算法



##### 快速恢复

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost4@main/%E7%BD%91%E7%BB%9C/%E6%8B%A5%E5%A1%9E%E5%8F%91%E7%94%9F-%E5%BF%AB%E9%80%9F%E9%87%8D%E4%BC%A0.drawio.png?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0" alt="快速重传和快速恢复" style="zoom:50%;" />

进入快速恢复算法如下：

- 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）；
- 重传丢失的数据包；
- 如果再收到重复的 ACK，那么 cwnd 增加 1；
- 如果收到新数据的 ACK 后，把 cwnd 设置为第一步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进入拥塞避免状态；



### 如何优化TCP？



#### TCP三次握手的性能提升

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/24.jpg" alt="三次握手优化策略" style="zoom:50%;" />

客户端和服务端都可以针对三次握手优化性能。主动发起连接的客户端优化相对简单些，而服务端需要监听端口，属于被动连接方，其间保持许多的中间状态，优化方法相对复杂一些。



##### 客户端优化

> `SYN_SENT`状态的优化

**调节丢包重传的次数**`tcp_syn_retries`（SYN包或SYN+ACK包丢失），因为每次重传的超时时间是上一次的两倍，而默认需要重传5次，最终需要等一分钟左右。

三次握手建立连接的首要目的是「同步序列号」。

客户端作为主动发起连接方，首先它将发送 SYN 包，于是客户端的连接就会处于 `SYN_SENT` 状态。



##### 服务端优化

> 半连接队列溢出，导致连接被丢弃

1、增大半连接队列的大小（与全连接队列的长度和`tcp_max_syn_backlog`相关）

2、开启 syncookies 功能



> `SYN_RCV`状态的优化

**调节丢包重传的次数**`tcp_synack_retries`（SYN包或SYN+ACK包丢失），因为每次重传的超时时间是上一次的两倍，而默认需要重传5次，最终需要等一分钟左右。



> 全连接队列溢出，导致连接被丢弃或者中断（RST）

1、**增大全连接队列长度**（取决于 somaxconn 和 backlog 之间的最小值，前者是内核的全局参数，后者是该socket的局部参数）

2、**调节 accept 队列溢出的行为**

`tcp_abort_on_overflow`，默认是丢弃ACK，设为1可以让服务端回发一个RST，让客户端迅速断开连接。

通常情况下，应当把 `tcp_abort_on_overflow` 设置为 0，因为这样更有利于应对突发流量。



#### 绕过三次握手（TCP Fast Open）

三次握手建立连接造成的后果就是，HTTP 请求必须在一个 RTT（从客户端到服务器一个往返的时间）后才能发送。

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/22.jpg" alt="开启 TCP Fast Open 功能" style="zoom:50%;" />

**首次连接：**

1. 客户端发送 SYN 报文，该报文包含 Fast Open 选项，且该选项的 Cookie 为空，这表明客户端请求 Fast Open Cookie；
2. 支持 TCP Fast Open 的服务器生成 Cookie，并将其置于 SYN-ACK 数据包中的 Fast Open 选项以发回客户端；
3. 客户端收到 SYN-ACK 后，本地缓存 Fast Open 选项中的 Cookie。

**二次连接：**

1. 客户端发送 SYN 报文，该报文包含「数据」（对于非 TFO 的普通 TCP 握手过程，SYN 报文中不包含「数据」）以及此前记录的 Cookie；
2. 支持 TCP Fast Open 的服务器会对收到 Cookie 进行校验：如果 Cookie 有效，服务器将在 SYN-ACK 报文中对 SYN 和「数据」进行确认，服务器随后将「数据」递送至相应的应用程序；如果 Cookie 无效，服务器将丢弃 SYN 报文中包含的「数据」，且其随后发出的 SYN-ACK 报文将只确认 SYN 的对应序列号；
3. 如果服务器接受了 SYN 报文中的「数据」，服务器可在握手完成之前发送「数据」，**这就减少了握手带来的 1 个 RTT 的时间消耗**；
4. 客户端将发送 ACK 确认服务器发回的 SYN 以及「数据」，但如果客户端在初始的 SYN 报文中发送的「数据」没有被确认，则客户端将重新发送「数据」；
5. 此后的 TCP 连接的数据传输过程和非 TFO 的正常情况一致。



#### TCP四次挥手的性能提升

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/39.jpg" alt="四次挥手的优化策略" style="zoom:50%;" />





客户端和服务端双方都可以主动断开连接，**通常先关闭连接的一方称为主动方，后关闭连接的一方称为被动方。**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/25.jpg" alt="客户端主动关闭" style="zoom:50%;" />

可以看到，**四次挥手过程只涉及了两种报文，分别是 FIN 和 ACK**：

- FIN 就是结束连接的意思，谁发出 FIN 报文，就表示它将不会再发送任何数据，关闭这一方向上的传输通道；
- ACK 就是确认的意思，用来通知对方：你方的发送通道已经关闭；

四次挥手的过程:

- 当主动方关闭连接时，会发送 FIN 报文，此时发送方的 TCP 连接将从 ESTABLISHED 变成 FIN_WAIT1。
- 当被动方收到 FIN 报文后，内核会自动回复 ACK 报文，连接状态将从 ESTABLISHED 变成 CLOSE_WAIT，表示被动方在等待进程调用 close 函数关闭连接。
- 当主动方收到这个 ACK 后，连接状态由 FIN_WAIT1 变为 FIN_WAIT2，也就是表示**主动方的发送通道就关闭了**。
- 当被动方进入 CLOSE_WAIT 时，被动方还会继续处理数据，等到进程的 read 函数返回 0 后，应用程序就会调用 close 函数，进而触发内核发送 FIN 报文，此时被动方的连接状态变为 LAST_ACK。
- 当主动方收到这个 FIN 报文后，内核会回复 ACK 报文给被动方，同时主动方的连接状态由 FIN_WAIT2 变为 TIME_WAIT，**在 Linux 系统下大约等待 1 分钟后，TIME_WAIT 状态的连接才会彻底关闭**。
- 当被动方收到最后的 ACK 报文后，**被动方的连接就会关闭**。

你可以看到，每个方向都需要**一个 FIN 和一个 ACK**，因此通常被称为**四次挥手**。

这里一点需要注意是：**主动关闭连接的，才有 TIME_WAIT 状态。**



##### 主动方优化

关闭连接的方式通常有两种，分别是 RST 报文关闭和 FIN 报文关闭。

如果进程异常退出了，内核就会发送 RST 报文来关闭，它可以不走四次挥手流程，是一个暴力关闭连接的方式。

安全关闭连接的方式必须通过四次挥手，它由进程调用 `close` 和 `shutdown` 函数发起 FIN 报文（shutdown 参数须传入 SHUT_WR 或者 SHUT_RDWR 才会发送 FIN）。



> 调用 close 函数和 shutdown 函数有什么区别？

调用了 close 函数意味着完全断开连接，**完全断开不仅指无法传输数据，而且也不能发送数据。 此时，调用了 close 函数的一方的连接叫做「孤儿连接」，如果你用 netstat -p 命令，会发现连接对应的进程名为空。**

使用 close 函数关闭连接是不优雅的。于是，就出现了一种优雅关闭连接的 `shutdown` 函数，**它可以控制只关闭一个方向的连接**：



> `FIN_WAIT1`状态的优化

主动方发送 FIN 报文后，连接就处于 FIN_WAIT1 状态，正常情况下，如果能及时收到被动方的 ACK，则会很快变为 FIN_WAIT2 状态。

但是收不到被动方的 ACK时，**主动方会定时重发FIN报文**其中重发次数由 `tcp_orphan_retries` 参数控制

- 如果 FIN_WAIT1 状态连接很多，我们就需要考虑降低 tcp_orphan_retries 的值，当重传次数超过 tcp_orphan_retries 时，连接就会直接关闭掉。

为了避免FIN报文发不出去的情况（发送缓存区仍有数据没有发送，或者接收窗口为0），导致连接无法断开。

- **调整 tcp_max_orphans 参数，它定义了「孤儿连接」的最大数量**，当孤儿连接数量大于它，新增的孤儿连接将不再走四次挥手，而是直接发送 RST 复位报文强制关闭。



> `FIN_WAIT2`状态的优化

当主动方收到 ACK 报文后，会处于 FIN_WAIT2 状态，就表示主动方的发送通道已经关闭，接下来将等待对方发送 FIN 报文，关闭对方的发送通道。

- 对于用 `shutdown()` 关闭的连接

  连接可以一直处于 FIN_WAIT2 状态，因为它还有可能发送或接收数据，并且不受 **tcp_fin_timeout** 控制

- 对于用 `close()` 关闭的连接

  连接不能长时间处于 FIN_WAIT2 状态，因为它不能发送或接收数据，具体时间受 **tcp_fin_timeout** 控制，默认为60s



> `TIME_WAIT` 状态的优化

当收到被动方发来的 FIN 报文后，主动方会立刻回复 ACK，表示确认对方的发送通道已经关闭，接着就处于 TIME_WAIT 状态。在 Linux 系统，TIME_WAIT 状态会持续 60 秒后才会进入关闭状态。

TIME_WAIT 状态的连接，在主动方看来确实快已经关闭了。然后，被动方没有收到 ACK 报文前，还是处于 LAST_ACK 状态。如果这个 ACK 报文没有到达被动方，被动方就会重发 FIN 报文。重发次数仍然由前面介绍过的 `tcp_orphan_retries` 参数控制。

**为了避免TIME_WAIT状态的连接过多，可以调节以下参数：**

1.  `tcp_max_tw_buckets` 参数

   TIMEWAIT 状态连接的最大个数，当 TIME_WAIT 的连接数量超过该参数时，新关闭的连接就不再经历 TIME_WAIT 而直接关闭。tcp_max_tw_buckets 也不是越大越好，毕竟端口和系统资源都是有限的。

2.  `tcp_tw_reuse` 参数

   打开 `tcp_tw_reuse` 参数，复用处于 TIME_WAIT 状态的连接，**该参数是只用于客户端（建立连接的发起方），因为是在调用 connect() 时起作用的，而对于服务端（被动连接方）是没有用的。**

为什么需要这个状态，可以参考上文：[为什么需要TIME_WAIT状态](#为什么需要TIME_WAIT状态)



##### 被动方的优化

处于 CLOSE_WAIT 状态时，调用了 close 函数，内核就会发出 FIN 报文关闭发送通道，同时连接进入 LAST_ACK 状态，等待主动方返回 ACK 来确认连接关闭。

如果迟迟收不到这个 ACK，内核就会重发 FIN 报文，重发次数仍然由 tcp_orphan_retries 参数控制，这与主动方重发 FIN 报文的优化策略一致。



#### TCP 传输数据的性能提升

TCP 连接是由内核维护的，内核会为每个连接建立内存缓冲区：

- 如果连接的内存配置过小，就无法充分使用网络带宽，TCP 传输效率就会降低；
- 如果连接的内存配置过大，很容易把服务器资源耗尽，这样就会导致新连接无法建立；

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/49.jpg" alt="数据传输的优化策略" style="zoom:50%;" />

TCP 可靠性是通过 ACK 确认报文实现的，又依赖滑动窗口提升了发送速度也兼顾了接收方的处理能力。

可是，默认的滑动窗口最大值只有 64 KB，不满足当今的高速网络的要求，要想提升发送速度必须提升滑动窗口的上限，在 Linux 下是通过设置 `tcp_window_scaling` 为 1 做到的，此时最大值可高达 1GB。

滑动窗口定义了网络中飞行报文的最大字节数，当它超过带宽时延积时，网络过载，就会发生丢包。而当它小于带宽时延积时，就无法充分利用网络带宽。因此，滑动窗口的设置，必须参考带宽时延积。

内核缓冲区决定了滑动窗口的上限，缓冲区可分为：发送缓冲区 tcp_wmem 和接收缓冲区 tcp_rmem。

Linux 会对缓冲区动态调节，我们应该把缓冲区的上限设置为带宽时延积。发送缓冲区的调节功能是自动打开的，而接收缓冲区需要把 tcp_moderate_rcvbuf 设置为 1 来开启。其中，调节的依据是 TCP 内存范围 tcp_mem。

但需要注意的是，如果程序中的 socket 设置 SO_SNDBUF 和 SO_RCVBUF，则会关闭缓冲区的动态整功能，所以不建议在程序设置它俩，而是交给内核自动调整比较好。

有效配置这些参数后，既能够最大程度地保持并发性，也能让资源充裕时连接传输速度达到最大值。



##### 滑动窗口是如何影响传输速度的？

窗口字段只有 2 个字节，因此它最多能表达 65535 字节大小的窗口，也就是 64KB 大小。

这个窗口大小最大值，在当今高速网络下，很明显是不够用的。所以后续有了扩充窗口的方法：**在 TCP 选项字段定义了窗口扩大因子，用于扩大 TCP 通告窗口，其值大小是 2^14，这样就使 TCP 的窗口大小从 16 位扩大为 30 位（2^16 \* 2^ 14 = 2^30），所以此时窗口的最大值可以达到 1GB。**

Linux 中打开这一功能，需要把 tcp_window_scaling 配置设为 1（默认打开）；



##### 如何确定最大传输速度？

带宽描述的是网络传输能力，它与内核缓冲区的计量单位不同:

- 带宽是单位时间内的流量，表达是「速度」，比如常见的带宽 100 MB/s；
- 缓冲区单位是字节，当网络速度乘以时间才能得到字节数；

宽时延积，它决定网络中飞行报文的大小，它的计算方式：

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/44.jpg" alt="img" style="zoom:50%;" />

**由于发送缓冲区大小决定了发送窗口的上限，而发送窗口又决定了「已发送未确认」的飞行报文的上限。因此，发送缓冲区不能超过「带宽时延积」。**

发送缓冲区与带宽时延积的关系：

- 如果发送缓冲区「超过」带宽时延积，超出的部分就没办法有效的网络传输，同时导致网络过载，容易丢包；
- 如果发送缓冲区「小于」带宽时延积，就不能很好的发挥出网络的传输效率。

所以，发送缓冲区的大小最好是往带宽时延积靠近。



##### 怎么调整缓冲区大小

在 Linux 中发送缓冲区和接收缓冲都是可以用参数调节的。设置完后，Linux 会根据你设置的缓冲区进行**动态调节**。



> 调节发送缓冲区范围

发送缓冲区的范围通过 tcp_wmem 参数配置；

**发送缓冲区是自行调节的**，当发送方发送的数据被确认后，并且没有新的数据要发送，就会把发送缓冲区的内存释放掉。



> 调节接收缓存区范围

**接收缓冲区可以根据系统空闲内存的大小来调节接收窗口：**

- 如果系统的空闲内存很多，就可以自动把缓冲区增大一些，这样传给对方的接收窗口也会变大，因而提升发送方发送的传输数据数量；
- 反之，如果系统的内存很紧张，就会减少缓冲区，这虽然会降低传输效率，可以保证更多的并发连接正常工作；



发送缓冲区的调节功能是自动开启的，**而接收缓冲区则需要配置 tcp_moderate_rcvbuf 为 1 来开启调节功能**：



> 调节 TCP 内存范围

接收缓冲区调节时，怎么知道当前内存是否紧张或充分呢？这是通过 tcp_mem 配置完成的：

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%82%E6%95%B0/48.jpg)

- 当 TCP 内存小于第 1 个值时，不需要进行自动调节；
- 在第 1 和第 2 个值之间时，内核开始调节接收缓冲区的大小；
- 大于第 3 个值时，内核不再为 TCP 分配新内存，此时新连接是无法建立的；



> 根据实际场景调节的策略

在高并发服务器中，为了兼顾网速与大量的并发连接，**我们应当保证缓冲区的动态调整的最大值达到带宽时延积，而最小值保持默认的 4K 不变即可。而对于内存紧张的服务而言，调低默认值是提高并发的有效手段。**

同时，如果这是网络 IO 型服务器，那么，**调大 tcp_mem 的上限可以让 TCP 连接使用更多的系统内存，这有利于提升并发能力**。需要注意的是，tcp_wmem 和 tcp_rmem 的单位是字节，而 tcp_mem 的单位是页面大小。而且，**千万不要在 socket 上直接设置 SO_SNDBUF 或者 SO_RCVBUF，这样会关闭缓冲区的动态调整功能。**



### 为什么TCP是面向字节流的协议，而UDP是面向报文的协议？

见[如何理解 TCP 是面向字节流的协议](#如何理解 TCP 是面向字节流的协议)





### 既然 IP 层会分片，为什么 TCP 层还需要 MSS 呢？

![MTU 与 MSS](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9jZG4uanNkZWxpdnIubmV0L2doL3hpYW9saW5jb2Rlci9JbWFnZUhvc3QyLyVFOCVBRSVBMSVFNyVBRSU5NyVFNiU5QyVCQSVFNyVCRCU5MSVFNyVCQiU5Qy9UQ1AtJUU0JUI4JTg5JUU2JUFDJUExJUU2JThGJUExJUU2JTg5JThCJUU1JTkyJThDJUU1JTlCJTlCJUU2JUFDJUExJUU2JThDJUE1JUU2JTg5JThCLzIzLmpwZw?x-oss-process=image/format,png)

- `MTU`：一个网络包的最大长度，以太网中一般为 `1500` 字节；
- `MSS`：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度；

**如果仅使用IP层的分片的话，当一个 IP 分片丢失，整个 IP 报文的所有分片都得重传**，因为 IP 层本身没有超时重传机制，它由传输层的 TCP 来负责超时和重传。

经过 TCP 层分片后，如果一个 TCP 分片丢失后，**进行重发时也是以 MSS 为单位**，而不用重传所有的分片，大大增加了重传的效率。



### RST 和 502 的区别？

<img src="https://img-blog.csdnimg.cn/img_convert/42adc4fb1ba1a27ec63648c40811355a.png" alt="Image" style="zoom:50%;" />

`nginx`会作为客户端和服务端之间的"中间人角色"，负责**转发**请求和响应结果。但当服务端程序**崩溃**，比如出现**野指针或者OOM**的问题，那转发到服务器的请求，必然得不到响应，后端服务端还会返回一个`RST`给`nginx`。`nginx`在收到这个`RST`后会断开与服务端的连接，同时返回客户端一个`502`错误码。



### TCP中已有SO_KEEPALIVE选项，为什么还要在应用层加入心跳包机制?

SO_Keeplive 是实现在TCP协议栈（四层），应用层的心跳实现在第七层，本质没有任何区别，但应用层需要自己来定义心跳包格式。

在应用层实现的心跳机制实现更灵活，因为可以自定义配置比如消息类型，超时时间间隔，接收后的处理。超时时间间隔在 TCP 的保活机制中，默认是两个小时多一点，这个参数可以调节。



### TCP_QUICKACK 和 TCP_NODELAY 的区别？

- TCP_QUICKACK
  1. TCP_QUICKACK 的作用是用来关闭延迟确认机制，这个延迟确认是在通信双方一问一答的情况下生效的，延迟确认会把信息和应答包组合一起发送出去，来减小网络压力，当然这个等待时间是有限制的，一般为 200ms
- TCP_NODELAY
  1. 该选项用于控制关闭nagle算法。
  2. 如果包大于 MSS(Max Segment Size)或含有 FIN 则立即发送，否则放入缓冲区，等已经发送的包被确认后后再发送。即网络上只能有一个未确认的小包。可以降低网络小包数量，减少了ip头部在网络上的比重，提升网络性能。
  3. 保证当前连接任意时刻网络只有一个未被确认的小分组，保证网络不会过分拥塞。



## IP常见面试题

### 基本概念

#### 网络层（IP）和数据链路层（MAC）的关系是什么？

MAC 的作用则是实现**「直连」**的两个设备之间通信，而 IP 则负责在**「没有直连」**的两个网络之间进行通信传输。

在网络中数据包传输中，**源IP地址和目标IP地址在传输过程中是不会变化的，只有源 MAC 地址和目标 MAC 一直在变化。**



#### 路由器与三层交换机的区别

1. **转发依据不同**：路由器利用 IP 地址（网络地址）来确定数据转发的地址；而三层交换机是利用 MAC 地址（物理地址）来确定转发数据的地址。
2. **路由器的功能更广泛**：路由器中附带硬件防火墙、二层交换机技术等功能，而三层交换机的主要功能仍是数据交换。
3. **应用范围不同**：路由器适用于与任何网络之间的连接，如局域网和广域网之间的连接；而三层交换机主要功能是以太网数据交换，路由转发只是附加功能。
4. **路由功能实现不同**：路由器的路由功能由软件实现；而三层交换机的路由转换通过硬件实现，所以三层交换机的转发效率高于路由器。



#### 简述网关的作用是什么，同一网段的主机如何通信？

1. **网关的作用**：网关在**传输层**上以实现网络互连，是最复杂的网络互连设备，仅用于两个**高层协议不同的**网络互连。

2. **网内通信**，即通信双方都位处同一网段中，数据传输无需经过路由器(或三层交换机)，即可由本网段自主完成。

   假设发送主机的ARP表中并无目的主机对应的表项，则发送主机会以目的主机IP地址为内容，广播ARP请求以期获知目的主机MAC地址，并通过交换机(除到达端口之外的所有端口发送，即洪泛(Flooding)向全网段主机转发，而只有目的主机接收到此ARP请求后会将自己的MAC地址和IP地址装入ARP应答后将其回复给发送主机，发送主机接收到此ARP应答后，从中提取目的主机的MAC地址，并在其ARP表中建立目的主机的对应表项(IP地址到MAC地址的映射)，之后即可向目的主机发送数据，将待发送数据封装成帧，并通过二层设备(如交换机)转发至本网段内的目的主机，自此完成通信。



#### IP 地址分类的优缺点

- **优点**

**快速找出网络地址和主机号**

<img src="https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/IP/14.jpg" alt="IP 分类判断" style="zoom:50%;" />

不管是路由器还是主机解析到一个 IP 地址时候，我们判断其 IP 地址的首位是否为 0，为 0 则为 A 类地址，那么就能很快的找出网络地址和主机地址。

- **缺点**

1. **同一网络下没有地址层次**

   比如一个公司里用了 B 类地址，但是可能需要根据生产环境、测试环境、开发环境来划分地址层次，而这种 IP 分类是没有地址层次划分的功能，所以这就**缺少地址的灵活性**。

2. A、B、C类有个尴尬处境，就是**不能很好的与现实网络匹配**。

   - C 类地址能包含的最大主机数量实在太少了，只有 254 个，估计一个网吧都不够用。
   - 而 B 类地址能包含的最大主机数量又太多了，6 万多台机器放在一个网络下面，一般的企业基本达不到这个规模，闲着的地址就是浪费。

   这两个缺点，都可以在 `CIDR` 无分类地址解决。



#### 什么是静态路由和动态路由

1. **静态路由**是系统管理员设计和构建的路由表所规定的路由。适用于网关数量有限的场合，且网络拓朴结构不经常变化的网络。其缺点是不能动态地适用网络状况的变化，当网络状况变化后必须由网络管理员修改路由表。
2. **动态路由**是由路由选择协议而动态构建的，路由协议之间通过交换各自所拥有的路由信息实时更新路由表的内容。动态路由可以自动学习网络的拓朴结构，并更新路由表。其缺点是路由广播更新信息将占据大量的网络带宽。



#### 说一下路由协议

路由协议是路由器之间实现路由信息共享的一种机制，它允许**路由器之间相互交换和维护各自的路由表**。当一台路由器的路由表由于某种原因发生变化时，它需要及时地将这一变化通知与之相连接的其他路由器，以保证数据的正确传递。路由协议不承担网络上终端用户之间的数据传输任务。主要有距离向量路由协议（RIP, IGRP, EIGRP）和链路状态路由协议（OSPF, IS-IS）两类。



#### 本机如何干预 DNS 解析

通过修改本机 host 来干预域名解析，例如：在 /etc/hosts 文件中添加一句话

```
192.168.188.1 www.baidu.com
```

保存文件后再ping一下 www.baidu.com 就会连接到192.168.188.1了

每一行为一条记录，分成两部分，第一部分是IP，第二部分是域名。

- 一个IP后面可以跟多个域名，可以是几十个甚至上百个
- 每一行只能有一个IP，也就是说一个域名不能对应多个IP
- 如果有多行中出现相同的域名（对应的ip不一样），会按最前面的记录来解析



#### 什么是 DNS 劫持？

1. DNS劫持就是通过劫持了DNS服务器，通过某些手段取得某域名的解析记录控制权，进而修改此域名的解析结果，导致对该域名的访问由原IP地址转入到修改后的指定IP，其结果就是对特定的网址不能访问或访问的是假网址，从而实现窃取资料或者破坏原有正常服务的目的。DNS劫持通过篡改DNS服务器上的数据返回给用户一个错误的查询结果来实现的。
2. DNS劫持症状：在某些地区的用户在成功连接宽带后，首次打开任何页面都指向ISP提供的“电信互联星空”、“网通黄页广告”等内容页面。还有就是曾经出现过用户访问Google域名的时候出现了百度的网站。这些都属于DNS劫持。



#### 简述网关的作用是什么，同一网段的主机如何通信？

1. 网关即网络中的关卡，我们的互联网是一个一个的局域网、城域网、等连接起来的，在连接点上就是一个一个网络的关卡，即我们的网关，他是保证网络互连的，翻译和转换，使得不同的网络体系能够进行。

2. 网内通信，即通信双方都位处同一网段中，数据传输无需经过路由器(或三层交换机)，即可由本网段自主完成。

   假设发送主机的ARP表中并无目的主机对应的表项，则发送主机会以目的主机IP地址为内容，广播ARP请求以期获知目的主机MAC地址，并通过交换机(除到达端口之外的所有端口发送，即洪泛(Flooding))向全网段主机转发，而只有目的主机接收到此ARP请求后会将自己的MAC地址和IP地址装入ARP应答后将其回复给发送主机，发送主机接收到此ARP应答后，从中提取目的主机的MAC地址，并在其ARP表中建立目的主机的对应表项(IP地址到MAC地址的映射)，之后即可向目的主机发送数据，将待发送数据封装成帧，并通过二层设备(如交换机)转发至本网段内的目的主机，自此完成通信。







## 故障排查问题

#### 如果没有网络连接，应该从哪些方面去排除问题？（[字节架构一面](https://www.nowcoder.com/discuss/943380?source_id=discuss_experience_nctrack&channel=-1)）

1. **检查物理链路是否有问题**
   - 电脑本身的网卡有没有问题
   - 网线是否已经接上
   - 本机所连接的交换机是否有问题
2. **查看本机IP地址、路由、DNS的设置是否有问题**
   - 检查是否存在 IP 地址冲突的问题，用 `arping 192.168.9.120` 看下是否 ip 是否唯一
   - 检查路由设置，是否对特定的包进行了限制
   - 检查 DNS 是否有问题，用 `ping www.baidu.com` 看是否能够返回 ip 地址
3. **测试网关或路由器的通畅情况。先测网关然后再测路由器，一级一级地测试（确认局域网的通信正常）**
   - 主要就是 ping 了，先 ping 网关的 ip 地址，再 ping 路由器的 ip 地址
4. **测试DNS的通畅情况，可以直接ping网站地址**
   - 直接 ping 目标 ip，看是否能够 ping 通



#### 浏览器无法显示网页，如何排查？（[字节实习一面](https://blog.csdn.net/lemonbit/article/details/125270286)）

1. 首先确认是服务端的问题还是客户端的问题
   - 确认浏览器是否可以访问其他网站，如果不可以，说明客户端网络自身的问题，然后检查客户端网络配置（连接wifi正不正常，有没有插网线）
   - 如果可以正常其他网页，说明客户端网络是可以正常上网的。
2. 抓包确认 DNS 是否解析出了 IP 地址，如果没有解析出来，说明域名写错了。
3. 抓包确认有没有和服务端建立三次握手，如果能成功建立三次握手，并且发出了 HTTP 请求，但是就是没有显示页面，可以查看服务端返回的响应码：
   - 如果是404错误码，检查输入的url是否正确；
   - 如果是500，说明服务器此时有问题；
   - 如果是200，F12看看前端代码有问题导致浏览器没有渲染出页面。
4. 如果客户端网络是正常的，但是访问速度很慢，导致很久才显示出来。这时候要看客户端的网口流量是否太大的了，导致tcp发生丢包之类的问题。



## linux 查询相关



### 如何查询本机的内网ip和外网ip？

1. 内网ip：直接通过 `ifconfig` 查看所有设备的内网IP地址
2. 外网ip：通过





# 每天一遍的题

- [ ] 三次握手 + 四次握手 + 及其丢失的情况





















































































